The widespread use of simulation has transformed the training landscape with realistic and immersive depictions of a broad range of task environments. Training outcomes have been further enhanced through blending simulation with intelligent tutoring systems. A powerful and widely practiced learning resource, though, is under-represented in training-based simulation: first-person narrative accounts of experienced practitioners who encountered whatever specific challenges a learner is facing in a simulated exercise. Such accounts can be vivid, memorable, and credible. Making these stories available to learning environments when relevant and needed, though, is a non-trivial enterprise that requires infrastructure for collecting, semantically tagging, and distributing story content. This paper introduces Augmenting Next-Generation Learning Environments with Stories (ANGLES). We present an architecture for content collection, tagging and distribution. ANGLES enables content to be collected from practitioners recording personal experiences from commodity devices (tablets, smartphones) through a mobile app that contributors use to capture, describe and upload their stories. We also discuss the algorithms that automatically transcribe and semantically tag the collected content. Through standards-driven APIs, ANGLES provides on- demand content to learning environments as well as providing a direct browsing interface for interacting with a collection. This Stories-as-a-Service capability enables a broader community of contributors than is typical of contemporary video collections; employs knowledge-driven speech-to-text coupled with semantic analysis that automatically tags content; and provides on-demand content to learning environments through API calls. This paper demonstrates to the modeling and simulation community how emerging technologies can combine to make the power of stories accessible across learning environments. 