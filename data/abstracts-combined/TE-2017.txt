Much has been said in recent years about the need to involve and integrate more tools of technology into the learning process for todays digital learner. However, the majority of the focus has been on ease of use, whether making delivery of instruction different, or replicating hard copies of learning materials into digital ones. In the emerging era, the focus no longer needs to be solely on the ease of use. The shifted target should be on the adapted learner. No longer will the learner be on an island in a learning ecosystem that makes them feel uncomfortable. Instead the case should be made for creating, in the learner, a stakeholder in their pathway to success. This is done by exploring how to incorporate innovations in learning technology into the instructional design to allow an adaptive environment for the learner to excel in, by gaining deliberate practice in areas where they need it most, as well as increasing repetitions and sets towards achieving mastery in their area. This paper will demonstrate the case to shift emphasis to the benefits in learning efficiencies, increased adaptability, and personalization that innovations in learning technology can provide to the learner. Also, by identifying the gaps that still persist inside an organization that continues to move forward with modernization, but are subsequently leaving the learner behind, will illustrate the requirement for proper implementation with a learning outcome in mind, versus creating the false appearance of progress by providing a shiny new object. The Joint Staff (JS) J7 Environment Architecture Division (EAD) is developing modular simulation services known as the Joint Training Tools (JTT) to reside within the Joint Training Synthetic Environment (JTSE). The JTSE will be a cloud based, web-enabled, enterprise environment that will provide scalable, on-demand modular simulations services designed to provide operationally relevant training for globally integrated operations. Order of Battle (OOB) and force management are critical components of military planning. Most military simulations incorporate OOB, but do not include aspect of force management. JTSE JTT Joint Training Data Services (JTDS) has enhanced OOB data with Force Management Service (FMS) data that includes detailed Global Force Management Implementation Guidance (GFMIG) information. GFMIG informational enables force assignments reflecting real-world constraints and incorporates aspects of force management with respect to capabilities, ready to load information, assignment, apportionment, and allocation. FMS allows users to create exercise-specific apportionment of units. When a trainee requests a force for a task, the force is requested based upon capability as signified by the GFMIG categories or types. Specified troops are apportioned and ready to load information and other attributes are reviewed prior to allocation. This gives the trainee insight into the reality of planning a campaign or maneuver with realistic force constraints. This paper will describe FMS attributes and how they can be used to influence battlefield situations and training. Psychomotor skills are foundational to numerous competencies composing the U.S. Armys vision for 21st Century Soldier Competencies as expressed in the Army Learning Model (ALM). Training these kinds of skills is being addressed in part through the use of sophisticated intelligent tutoring systems (ITS) that tailor and adapt instruction during individual learning interactions. While ITS are an effective approach to training psychomotor skills, developing these systems remains a costly and time-consuming enterprise, despite the emergence of ITS authoring tools which remain limited in scope, capability, and generalizability across Army-relevant domains. We report on development of AI-supported authoring for militarily-relevant psychomotor tasks based on a fielded trainer in a psychomotor domain (marksmanship). We will present our approach to ITS authoring with an AI agent that encapsulates knowledge useful in guiding the authoring process, to include pedagogical knowledge tailored to instruction and assessment of psychomotor skills. Utilizing the Generalized Instructional Framework for Tutoring (GIFT) and its tools and methods for supporting and streamlining ITS development, we discuss how a more specialized ITS authoring tool can embed the authoring process in a dialogue between automated tool and training author. In this paper we present our findings that characterize distinctive elements of the psychomotor domain, including specific competencies and how they are learned and assessed, factors that tutoring systems in this domain of learning must accommodate. By focusing on a specific category of skill performance and not on a specific metaphor for instruction, we will illustrate how authoring tools can support development of simulation-based psychomotor skills training. Within the defense sector of the modeling & simulation industry, most simulation-based training systems are comprised of a mixture of heterogeneous technologies that are highly challenging and expensive to develop, maintain and network. Some systems consist of custom-developed solutions and/or exploit open source technologies. Others rely on commercial, off-the-shelf (COTS) and government off-the-shelf (GOTS) tools. The use of closed, proprietary technologies, data and tools can have great benefit, but adds complexity, cost and risk. Even though a variety of industry standards for communication protocols and datasets exist today for various components of simulation solutions, no formalized intra-organizational system of systems approach exists for simulation solution development. As such, simulation software developers are often forced to use ad-hoc development and non-standard methods to interface technologies, especially when working with proprietary components. These ad-hoc methods increase development time and add cost and risk that could be reduced if simulation systems were developed using a common set of industry standards and methods. Where organizations like the Simulation Interoperability Standards Organization (SISO) are helpful, major gaps remain. This paper discusses why the gaps occur and methods that have been used to eliminate them. The Joint Staff (JS) J7 is developing Joint Training Tools as modular simulation services to reside within the Joint Training Synthetic Environment (JTSE). The JTSE will be a web-enabled, enterprise environment that provides scalable, modular simulation services on-demand, and operationally relevant training. Terrain data and geospatial planning are important components of these environments for scenario development. Commercial online data sources, such as Google Earth, can be used during scenario planning and development. However, paper maps and/or PowerPoint generated slides are more often used during planning conferences to determine how geography will affect the training event or to identify key terrain features, avenues of approach, Lines of Communications (LOC), objective areas, and other mission needs. During the scenario development process, Modeling and Simulation (MANDS) planners provide terrain database developers with the initial simulation datasets requirement terrain builds. Specific details, such as the need for high fidelity imagery or 3D models are typically communicated later in the scenario development process. These details often come after MANDS planners have viewed the initial terrain database. Communication between the MANDS planners and the terrain data builders is extremely important because artifacts created during the scenario planning conferences are not always shared with the terrain database developers. This paper describes how the web-based Terrain Generation Service (TGS), developed as a part of the JTSE Joint Training tools, could support scenario development, and improve communication between an event planner and the terrain database development team by leveraging existing web-based global MANDS terrain repositories and geospatial data standards.      A 2015 analysis of published AR/AV research identified 22 reports that examined and reported empirical data concerning the effectiveness of Augmented Reality (AR) & Augmented Virtuality (AV) for education, training, and performance aiding. Current assessments focused on testing the technology itself (e.g., safety; specifications; capabilities) are numerous, impressive, and essential. However, assessments with objective, empirical data about AR/AV effectiveness for training and performance are comparatively rare. Most reports on effectiveness comparing AR/AV to alternatives suggest that AR/AV reduces time (effect size = 0.52 and errors (effect size = 0.81 in performing skilled tasks, increases the amount learned (effect size = 0.44), produces learning that is more resistant to decay (effect size = 0.71), is preferred to other approaches (effect size = 0.81), and increases immersion (flow) during learning (effect size = 0.67). Other findings of interest were reported from individual studies. However simulator sickness remains a problem. Recommendations from the analysis included: Increased emphasis on empirical assessment of AR/AV effectiveness compared to other systems; research on the development of systems using machine intelligence combined with AR/AV; research on adapting AR/AV to individual differences; exploiting the potential of AR/AV to enhance success in performing military operations in combat service support (e.g., maintenance and repair) activities; cost- effectiveness assessment AR/AV in both training and performance aiding; and continuing review of costs and advances in commercial AR/AV technology. Interactive virtual environments are useful tools for hands-on learning or rehearsing of procedural tasks. However, task training applications typically provide a constrained course of action for the learner, forcing them down a single specific solution path. We discuss an approach in which the virtual environment is semantically instrumented in order to allow for the tracking of and reasoning about open-ended learner activity therein. Our approach leverages ontology-based knowledge representation which allows for a structured and meaningful description of virtual objects and of the learner actions that may be performed upon them. This is facilitated by the association of specific ontological classes with geometric components of the objects which populate a training exercise. These classes, together with their attributes, relationships and rules, characterize the environment and user actions in a readily understandable manner. As a result, a training system is able to observe the learner activity, render an assessment of that activity, and provide meaningful feedback to the learner. We also present an authoring tool which allows content developers to semantically annotate three-dimensional models for such an environment. The Joint Staff (JS) J-7 is developing Joint Training Tools (JTT) as modular simulation services to reside within the Joint Training Synthetic Environment (JTSE). The JTSE will be a cloud-based, web-enabled, enterprise environment providing scalable, on-demand, and operationally relevant training for military forces. The user orientated JTT design will emphasize ease of use by making the underlying tools processes more transparent, and output displays more understandable. While battlefield outcomes cannot be predicted with accuracy, components influencing the outcome can be analyzed to determine possible outcomes. Campaign planning incorporates force analysis including deployment, missions, equipment, capabilities, and environmental factors to determine if a desired outcome is achievable in a given situation. JTSE JTT utilize force structure data organized by Global Force Management Implementation Guidance (GFMIG) codes and include combat powers based upon equipment, training, and other military factors influencing battlefield results. The Combat Adjudication Service (CAS) uses this information to forecast reasonable outcomes of combat engagements represented in training environments. CAS performs combat adjudications as actions during runtime during event execution or as a data collection service to aid the training audience when employing forces in a synthetic training event. This paper provides a generalized review of how data from force structure is blended with equipment and environmental factors to forecast potential battlefield outcomes. The Joint Staff (JS) Joint Training Directorate (J7) Environment Architecture Division (EAD) is developing modular simulation services known as the Joint Training Tools (JTT) to reside within the Joint Training Synthetic Environment (JTSE). JTT will be a cloud-based, web-enabled, enterprise environment that will provide scalable, modular simulation services on-demand, and operationally relevant training. Campaign planning is one of those modular simulation services. This iterative planning process incorporates situational analysis with respect to the enemy intent, enemy capability, and impacts of humanitarian assistance efforts for developing courses of action (COA)s that mitigate undesirable outcomes. This planning requires the integration of several standalone database services containing force structures and equipment information, geospatial databases and layers, and logistical supply consumption and movement databases. The Training Environment Manager (TEM) tool will support database integration by consuming, combining, and displaying data of interest. The Joint Exercise Design Tool (JEDT) will enable campaign plans creation by allowing users to review, adjudicate, or export user plans. Other JTT services will interoperate with TEM and JEDT according to Order of Battle (OOB), geospatial, or logistical needs. Simulation supported event designers will need less preparation time for making training situations more credible in terms of quality and realism, allowing for rapid integration of pre-existing data, and enabling dynamic access and update of data within real-time events. This paper will discuss how force structure, geospatial, and logistical information can help to achieve a Modeling and Simulation as a Service (MSaaS) environment. The ability to produce a rapid After Action Review (AAR) capability provides objective data for evaluation and expands learner experience. Current video feedback does not provide a complete picture of the tactical situation during training, nor is it immediately available for evaluation. Cameras may not be positioned properly or a critical event may be blocked from view. Individual positions relative to potential enemy fire are not recorded. Light Detection and Range (LiDAR) technology combined with position-tracking software provides an effective method to produce immediate AARs. Position-tracking software and LiDAR technology when fused with digital imaging technology can capture both tactical and clinical skills to provide a more comprehensive audio/visual AAR capability with automatic scoring of performance. This capability can be used in conjunction with the Medical Training Evaluation Systems (MTES) assessment checklists currently fielded at the U.S. Army Medical Simulation Training Centers (MSTC). The result is an immediate playback of performance correlated to assessment scores for training and evaluation. Preliminary field-testing showed that LiDAR is capable of directing multiple cameras to track important actions of learners during a field training exercise. The position-tracking software accurately detected the persons of interest during a training event and cameras tracked their actions for the duration of the exercise. The AAR system successfully integrated the LiDAR data, video feeds, and skill assessment checklist to provide a fully integrated AAR system that provided all collected data in a simple user interface. Students compared the system to watching post-game footage of sports events to improve their performance. Instructors were able to pinpoint correct and incorrect actions to further educate the class and found the system to be valuable addition to training.    For the last half century, there has been a dramatic increase in the use of modeling and simulation (MANDS) applications in training and education. MANDS can be leveraged to enhance conventional mechanisms for knowledge retention by bridging the gap between classroom theory and real-world application to better enable engaging, experiential participation in the learning process. This paper discusses the technical and experimental design of a game-based simulation environment for an existing road vehicle dynamics (RVD) university course. The basis of the simulation experiment is to provide an environment for learners to actively discover the interplay between two key vehicle parameters (i.e., vehicle weight distribution and roll-stiffness distribution) while driving upon an oval speedway. The goal of the learner, in real-time, is to optimize these parameters to maximize vehicle performance (i.e., to minimize lap time). Simultaneously, our objective as educators is to observe how simulator-measured experimental performance correlates to self-reported tendencies (e.g., driving style; learning style; video gaming preferences) relevant to driving and dynamics education. Our holistic goal is to determine if and to what degree MANDS-based instruction is better suited towards certain types of drivers or learners, which might inform how to maximize the effectiveness of the delivery of MANDS in future training and education curricula. While the MANDS environment and experimental protocol described here is intended primarily for education and training, it has extensibility to other applications (e.g., pilots for aircraft), and enables related applications in transportation and human factors research. The U.S. Army Aviation Combined Arms Training Strategy highlights the use of Training Aids, Devices, Simulations, and Simulators (TADSS) as key, low cost tools to prepare Army aviation forces for future combat. A prominent component of this strategy is an increasing reliance on games-for-training. Game-based systems are capable of supporting training and assessment of mission procedures and situational judgement tasks. However, little research exists on the capabilities of the specific types of game-based systems for supporting Army aviation collective training. The present study evaluated the effectiveness of the Virtual Battlespace 3 and Microsoft Flight Simulator game-based training environments for a set of collective air assault mission tasks. Study participants consisted of previously qualified Army aviators recruited from various U.S. Army Aviation Center of Excellence (USAACE) schoolhouses located at Fort Rucker, Alabama. An air assault mission scenario, consisting of a set of operationally demanding flight procedures, mission procedures, and cognitive-decision making tasks, formed the basis of the evaluation. Study metrics consisted of mission performance rubrics, a physiological measure of heart rate variability, and a variety of subjective measures. Results indicate that, when compared to each other, both game environments provide comparable opportunities for collective training, allowing training resource decisions to be made based on other factors. MYMIC Simulations and Orbital ATK developed an immersive virtual reality demonstration environment to potentially train personnel on rocket fuel mixing procedures because Orbital ATK needed an effective way to provide immersive, effective training on hazardous operations. MYMIC and Orbital ATK developed a concept prototype using a head-mounted display to deliver a fully immersive 3D training experience. The implementation integrates Oculus Rift and Unity 3D with an Xbox360 controller. Beta testing of the prototype was positive and constructive realism was experienced; trainees attempted to reach out and touch portrayed objects as well as dodge ones that were too close. The training incorporates a virtual instructor avatar that orients the trainee. Lessons learned as to the efficacy of using virtual reality for training scenarios and development challenges are discussed. The United States Army has a significant investment dedicated to the use of virtual environments for infantry soldier skills training. Although there is a pervasive attitude within the acquisition community that a training systems graphics quality is the strongest indicator of training quality and utility. A literature review of performance assessment of infantry soldiers who have been trained using simulation-based training technology reveals very little data exists to quantify the return on this investment and validate this assumption. Further, the Government Accounting Office in 2013 and 2016 calls for better assessment of costs and training performance to properly assess the systems. Beginning in 2014, researchers at the U.S. Army Research Laboratory and the University of Central Florida designed and executed a large-scale study that collected performance data from over 50 squads of dismounted infantry soldiers. Multiple training treatments were provided to the squads, including a baseline treatment where they were provided only traditional live training, only virtual, and a treatment that combines live and virtual. This paper will discuss a comparison of the mental effort of soldiers trained with virtual means to soldiers trained with traditional live means. Further, the analysis will include the Situational Training Exercise (STX) performance assessments of the soldiers to attempt to determine if there are any correlations between the differences in the mental effort of the training treatments. The design of training exercises within the U.S Army involves simulating the real-world operational environment (OE) to the greatest extent possible. The increasing availability of public information relevant to the OE represents both opportunities and challenges for training and exercise planners. In this paper we examine using open-source event data as intelligence content by providing a faceted search capability based on an OE ontology. Event data is useful for exercise design not only because it informs the OE, but because events are used to motivate training tasks when the exercise is actually conducted. The news articles used as sources for event-mining systems can contain a variety of useful references to OE elements, including enumerations of intentional acts (violence, protests, diplomacy), and actors (victims, perpetrators) in a given area, as well as intangible variables such as effects upon regional stability and the mood of the populace. Many of these parameters are parsed and coded by event mining systems such as the Global Database of Events, Languages and Tone (GDELT) and the Integrated Crises Early Warning System (ICEWS). Further, these systems use a common taxonomy for event coding. Our OE ontology allows these data sets to be searched using terms that are familiar to unit commanders by mapping the event codes to OE taxonomies and lexicons used by the Army. We apply our ontology to build a search application hosted in our OE Enterprise Repository, a data store built on the Defense Information Systems Agency (DISA) Big Data Platform.      A VMASC research team and numerous active duty clinicians collaborated to devise an instructional assist program and methodology designed as a serious computer based game and training platform for military health care professionals. The learner is guided by an avatar-preceptor through course content and multi-media enrichment  resources. She/he can present content through course completion using deliberative practice that progresses the learner to content mastery. In this case, the content is based on Team Strategies and Tools to Enhance Performance and Patient Safety (TeamSTEPPS), a patient safety and communications program in response to the DOD and national imperative to reduce preventable patient harm due to errors in care. Currently, this content is taught using a didactic approach, necessitating students and instructors leaving their workspace. Few measures of student program success exist due to administrative workload. We automated capture of content learning measures using validated instruments. We call this program the Course for Operationally Relevant Patient Safety or CORPS. The main research objective was to determine the efficacy of CORPS in teaching concepts of teamwork and communications in comparison to a control group that also uses TeamSTEPPS v. 2 content but instructs using a traditional didactic presentation. This study supports military medical deployment team needs and was conducted at a large military healthcare facility. Participating in the study were 320 learners. Results indicate the experimental group performance was as good as the control. There was a slight trending toward superior performance, but the process generated significant administrative time and cost savings. In three months, the course director reported actual time-savings of over 320 man hours that could be used for team simulation practice. At present, the Department of Patient Safety at the test site continues to use the CORPS prototype because of its effectiveness and demonstrated savings of time and cost.      Recently, we have developed a simulated environment for training surgical team members in judgement, decision- making, and technical ability. The Virtual Operating Room (VOR) is a fully immersive virtual environment that augments procedural task simulator training with a simulated OR context. The VOR is modeled on a standard OR and outfitted with both real and virtual equipment and a commercial medical simulator for laparoscopic cholecystectomy. Trainees communicate with virtual teammates using speech recognition software. One challenge with the VOR is developing a system for speech recognition that includes all reasonable surgical utterances while retaining flexibility between differences in user terminology. In the initial configuration, speech recognition rules were rigid and required operators to manually intervene for statements that went unrecognized. In the current configuration, we developed an extended state machine formalism that reduced the number of words needed to be detected in each utterance. The present paper compares previous results with the current version. Surgical residents were recruited to test system efficacy using free speech. Surgeons perceptions about speech recognition with the current version were more positive compared to older version: levels of dissatisfaction with the vocal control declined from 20% to zero. Additionally, a third of the surgeons reported feeling as though the simulation was realistic due to the ability to communicate with the system via speech. However, some additional recognition issues were revealed, including lag in system response times, confusion regarding system inquiries and appropriate responses, the need to provide verbal feedback for certain procedural steps, and unexpected user responses. Preliminary results suggest that communication efficacy in the current VOR has improved, but issues such as system response time and speech recognition accuracy still pose a challenge. 