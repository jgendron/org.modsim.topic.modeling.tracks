The purpose of this paper is to report how the implementation of a targeted micro-training program, based on monthly error trend reports, has resulted in significant reduction in performance errors. This training solution, designed to focus on specific performance errors, is based on the principles of micro-training and performance diagnostics as a methodology for addressing performance issues. This paper discusses how this new training program was designed using innovative concepts and implemented to meet a fast-paced, 30-day deployment and implementation schedule. The paper also discusses results metrics that provide evidence of the effectiveness of the training intervention in accordance to the Kirkpatrick Model of Evaluation. The results of the study demonstrates that the program positively impacted performance improvement for both the employee and the organization as a whole. The widespread use of simulation has transformed the training landscape with realistic and immersive depictions of a broad range of task environments. Training outcomes have been further enhanced through blending simulation with intelligent tutoring systems. A powerful and widely practiced learning resource, though, is under-represented in training-based simulation: first-person narrative accounts of experienced practitioners who encountered whatever specific challenges a learner is facing in a simulated exercise. Such accounts can be vivid, memorable, and credible. Making these stories available to learning environments when relevant and needed, though, is a non-trivial enterprise that requires infrastructure for collecting, semantically tagging, and distributing story content. This paper introduces Augmenting Next-Generation Learning Environments with Stories (ANGLES). We present an architecture for content collection, tagging and distribution. ANGLES enables content to be collected from practitioners recording personal experiences from commodity devices (tablets, smartphones) through a mobile app that contributors use to capture, describe and upload their stories. We also discuss the algorithms that automatically transcribe and semantically tag the collected content. Through standards-driven APIs, ANGLES provides on- demand content to learning environments as well as providing a direct browsing interface for interacting with a collection. This Stories-as-a-Service capability enables a broader community of contributors than is typical of contemporary video collections; employs knowledge-driven speech-to-text coupled with semantic analysis that automatically tags content; and provides on-demand content to learning environments through API calls. This paper demonstrates to the modeling and simulation community how emerging technologies can combine to make the power of stories accessible across learning environments. Critical thinking is widely accepted as a requisite skill for successful military leaders. Todays defense leaders must thwart sudden assaults with preemptive parries and innovative defensive tactics. This requires a level of critical thinking and meta-cognition that is not always found in educational processes today. Effectively enhancing that skill set via a range of training techniques has a well-documented history, but the current application of those techniques remains problematical for a number of reasons. The authors' past and current research is in the use of conversational on-line agents in a number of contexts and in the use of distributed computing and simulation. They assert these can be used to address problems in critical thinking training. These capabilities tender a solution to global application and continuous availability of this training for DoD personnel. The need for critical thinking is taken as a given. A brief survey of effective critical thinking pedagogies is followed by an analysis of which would be most effectively adapted to the distributed simulation/agent environment. Then this paper discusses both the distributed computing simulation capabilities that have been demonstrated and the emerging technologies enabling the delivery of engaging conversational agents. These agents are capable of carrying on a life-like verbal exchange with the users. Examples of where and how both the distributed computing and agent interfaces have proven effective are given, with analysis about the impact these capabilities would have on critical thinking training. A discussion is presented concerning the relative benefits of using animated agents vice using video clips of live personnel as the response vehicle for the conversation. The efficacy of using an active voice recognition-enabled dialogue instead of a text delivered didactic approach is discussed. The paper closes with a description of how such a system could effectively serve DoD personnel. The Commandants Planning Guidance for 2015 states, My intent is for Marines to encounter their initial ethical and tactical dilemmas in a simulated battlefield vice actual combat (USMC, 2015). Live training can never be completely replaced, but live training can be optimized or augmented, or both, by preparing in live, virtual, constructive (LVC) training events. However, enabling readiness through training depends on the capabilities of the simulators to enable training of operational tasks as required by training objectives. Typically, however, validation of simulator capabilities is conducted while in stand-alone configuration. Validating simulator capabilities while linked to other simulators in a distributed environment is only now being undertaken. This paper reports on an assessment and analysis methodology based on the systematic team assessment of readiness training (START) process to determine if the method utilized can inform potential validation efforts for future LVC distributed mission training environment (DMTE) exercises. The capabilities of three simulation systems, used in a LVC DMTE were first assessed in stand- alone configuration and then, after conduct of the DMTE exercise, assessed to determine the simulators capabilities while in distributed configuration. Then, the stand-alone and distributed configuration START results were compared and analyzed. While general findings of this effort are outside the focus of this paper, the salient take-away is the development of a methodology for identifying simulator capabilities and value-added training delivered in distributed, LVC configurations. A job-aid for validation of distributed systems in the form of a protocol, based on analysis, observations and subject matter expert input was developed and herein provided. This protocol will be employed during a follow-on effort. Accordingly, adjustments and revisions will be made and reported. Implications, downstream application, and potential impacts of this methodology upon validation and verification efforts, LVC simulator requirements, and recommended adjustments to the START process are also discussed. The Army depends on hundreds of space-reliant munitions and devices to conduct combat operations. This technology gives our forces a strategic advantage over the enemy in any scenario, whether it is through the use of precision-guided munitions (PGM) or battlefield situational awareness tools. Unfortunately, the adversary is well aware of our dependence upon these capabilities and has been developing the aptitude to challenge our unimpeded use of space- reliant assets by creating a denied, degraded, and disrupted space operational environment (D3SOE). The Army is currently under-trained to fight through a D3SOE, and particularly, higher echelons lack the ability to replicate a contested electromagnetic operational environment in training exercises at Mission Command Training Program (MCTP) and joint training events. To address this capability gap, the USASMDC/ARSTRAT along with Training and Doctrine Command (TRADOC)-NSC, Program Executive Office Simulation, Training, and Instrumentation (PEO STRI), and the greater Modeling and Simulation (MANDS) Community of Interest are developing a simulation solution to train soldiers how to fight through a contested space environment. Sponsored by the Army Modeling and Simulation Office, this effort addresses replicating Global Positioning System (GPS) jamming effects on PGMs. The effort degrades the accuracy of PGMs and affects the Common Operational Picture with respect to unit positions and movements. At the core of this effort is the United States Air Force (USAF) Distributed Mission Operations Center- Space (DMOC-S) developed GPS Environment Generator (GEG) that applies jamming effects to PGMs. The GEG provides precision degradation for various Army PGMs and space-reliant equipment, such as Excalibur, the Army Tactical Missile System, the Guided Multiple-Launch Rocket System, and the Defense Advanced GPS Receivers. The GEG would then provide this information to the Army Joint Land Component Constructive Training Capability (JLCCTC) that uses the information to determine the impacts on units. The resulting training capability will enhance our militarys proficiency in detecting, attributing, and mitigating electronic warfare (EW) effects, greatly enhancing survivability and mission success. For the last half century, there has been a dramatic increase in the use of problem solving applications in systems engineering. Problem solving can be leveraged to enhance conventional mechanisms for engineering design, bridging the gap between understanding system complexity and real-world operational work tasks to better enable system functional output. This paper discusses the technical and experimental design of a critical component in the F-1 rocket engine, the injector, responsible for combustion instability. A qualitative analysis of over 100 interviews accessed from NASA Oral History Project shows Apollo program engineers and scientists searching for the problem domain through controlled experimentation and empirical evidence of performance anomalies. Exploring the counterpart solution domain space, they were able to modify configuration of the design space. The case study provides a historical model of aggressive engineering and for learners to find the elusive problem domain that narrowly discerns system performance for what does not work from what works. As the complexity of training events continues to evolve, training program effectiveness and the capabilities of simulation systems to support and optimize training outcomes becomes an increasingly critical concern. Historically, these concerns have been addressed through the use of traditional training evaluations. However, traditional evaluation methodologies do not adequately capture the complete range of efficacy factors that exist in modern training simulations. This paper addresses this gap by outlining a training evaluation taxonomy that identifies two main training evaluation components: the human element and the systems element. The human element includes assessment of the training tasks, objectives, and overall instructional design that drives the training experience. The human element of training evaluation is often referred to as a training effectiveness evaluation (TEE) and frequently includes measures of trainee perceptions, behaviors, and performance. The systems element of training evaluation involves an assessment of the instructional interfaces, technologies, and environments used to support and facilitate the performance of training tasks and requirements. It includes a review of the technology configuration used to support training, an attribute analysis of the training system, and documentation of operability/interoperability issues. This systems evaluation, known as a technology capability assessment (TCA), identifies system capabilities and limitations for training specific learning objectives when used in either stand-alone or distributed training configurations. This taxonomy helps guide training evaluation efforts by focusing and aligning assessment activities with desired assessment outcomes to provide key information to stakeholders and decision makers on the efficacy of mission critical training systems. Instructional designers can have a profound impact on the bottom line of every corporate and industrial organization. Training Magazines 2016 Training Industry Report found that U.S.-based educational institutions and corporations with 100 or more employees spent $70.65 billion total training expenditures in 2016; flat from $7.6 billion in 2015. Training expenditures per learner in 2016 was $814, which is up from $702 in 2015 (Training Magazine, 2016). However, actual hours of training per employee decreased from 53.8 hours in 2015 to 43.8 hours in 2016 (Training Magazine, 2016). Implementing technology-based training programs is more expensive but decreases the amount of time needed to train the workforce. Instructional designers often rely on theoretical knowledge to account for allowances and limitations of technology in order to determine if the level of effort to implement is worth the risk of possibly developing ineffective training. It is a delicate balancing act that could potentially cost the organization a great deal of money if the instructional designer misinterprets the technology use case. As yet, research has failed to study both the competence and practice of instructional design in a fully immersive virtual reality (VR) environment (Tracey & Boling, 2014). This paper introduces a dissertation qualitative study that explores instructional design considerations when designing VR-based training. Using a modified Delphi research design, the results from this study will identify possible best practices that could be used by instructional designers when designing VR-based training in order to improve practice in the instructional design field. Although aviation mishaps are relatively rare, such incidents are devastating due to the high probability of injury or death and financial loss. Factors such as spatial disorientation and lack of situational awareness are known root causes of many aviation mishaps and generally lack effective training. This situation is exacerbated by the fact that current training for such factors is typically confined to traditional methods (e.g., lectures)which typically deemphasizes kinesthetic learning. To address this significant challenge, Aptima has developed a scenario authoring tool for experiencing realistic renditions of aviation mishaps caused by spatial disorientation. The MASTER system enables aviation instructors to create immersive mishap scenarios from realistic mishap data and intuitive creation tools while providing multiple methods for media export (e.g., 360-degree video, virtual reality [VR]). Some of the common causal mishap illusions demonstrated by the MASTER system include the following: false/fixed horizons, black holes, and the somatogravic illusion. This approach aims to enhance training efficacy by providing multiple methods of immersive mishap replay along with a dedicated plan for evaluating the effectiveness of various training media. In summary, the anticipated components of the MASTER system work to streamline scenario authoring by aviation instructors and provide optimized training for typical aviation mishap factors. Although more work is needed, our preliminary work indicate that rapid scenario authoring is feasible and that immersive training mediasuch as VR can potentially increase training efficacy. Success in todays global environment is often contingent on ones ability to effectively navigate culturally complex situations. This ability, referred to as cross-cultural competence (3C), is actually a constellation of abilities that enables individuals to adapt to a wide range of interpersonal contexts. Despite the importance of 3C, adequate measurement of 3C is lacking and often overly reliant on self-evaluation, which can be inherently biased or unreliable. As a result, other methods by which 3C can be more validly assessed are being explored. This project focuses on one such method, namely, a game-based assessment of perspective taking. Perspective taking, a critical sub-facet of 3C, is a social- emotional skill that enables individuals to consider anothers point of view. In cultural contexts, perspective taking is particularly important, as it not only facilitates awareness of how cultural norms influence behavior, but also allows for more accurate prediction of behavior in future situations. The simulation described here takes place on an alien planet and requires players to complete several quests in service of a larger game goal. Each of the quests require players to learn about the planets culture and use what theyve learned, along with their perspective taking skills, to achieve quest goals. Players skill levels are inferred from the decisions they make and the amount of feedback they require to successfully complete each quest. The presentation will focus on the theoretical foundation for the games development, as well as address the operationalization of the construct, game design, learning objectives, and scoring criteria. Virtual simulation lacks the variation and realism necessary to fully immerse trainees into a simulated world. As a result, trainees have a difficult time paying full attention and waste valuable training cycle time. As training budgets shift from live to virtual approaches, predictable artificial intelligence and unrealistic surroundings detract from training goals, and undermine training efficacy. To increase return on investment and better prepare soldiers, it is important to simulate a population that acts and communicates realistically. It is essential to shift away from traditional scripting approaches to adaptive techniques which can be reviewed, understood, and augmented by subject matter experts visually. This paper highlights how goal-directed, configurable, and reactive behavior templates address training gaps often ignored by existing training simulations. It details how a framework that allows for adaptive character goals creates more realistic and cost-effective, immersive experiences for trainees than scripted equivalents. With a goal-directed approach, details like how Non-Player Characters (NPCs) communicate, what NPCs recognize in the surrounding terrain, who an NPC knows, and how an NPC engages with players can contribute to the choices NPCs make. This paper explores how a cognitive architecture enables NPCs to make their own decisions throughout their day based on their role in a population and what they actually need to do. Each NPC is not hard-coded but instead observes others, perceives outcomes, reacts to changing situations, and chooses activities (e.g. working, eating) accordingly, thus adding a level of realism to training simulations that is unparalleled in traditional scripted training scenarios. From conception to implementation, the development of a well-designed training system requires effective communication and tactful compromise within a multidisciplinary team of instructional designers, user experience experts, software developers, stakeholders, and end users. The design process applies even to seemingly trivial design choices. In this paper, we describe the process implemented to design a mobile application to train financial literacy. Taking a user-centered design approach, the team worked with customers, subject matter experts, and end-users to gather contextual information and design requirements specific to the users needs. To strengthen the bond between the users and the tool, financial concepts were re-imagined in the voice of a relatable mentor, akin to a trustworthy and knowledgeable friend, named Green Pig. What started initially as a mechanism for mobile immersion quickly emerged as its own entity capable of taking on multiple guises. In this presentation, the journey of Green Pig is used as a metaphor for the evolution, de-evolution, and resolution of the mobile-app design process. The goal for this paper is to provide a description of the iterative development process to understand the barriers that challenged success, how they were overcome, and what it takes to be established in todays overcrowded world of training systems and mobile applications. Anatomical structures can be displayed for educational or training purposes through several different visualization technologies. However, these technologies differ regarding their usability and display of spatial information. The present research compared three visualization technologies in the learning of gross human brain anatomy. Participants, aged 18-28 (N = 90, Mdn = 18, IQR = 1), were assigned to one of three conditions: (1) a PowerPoint condition, where 2D brain images with monocular depth cues were presented on a computer screen, (2) a Physical Model condition, involving a plastic 3D brain model that could be disassembled into eight parts, and (3) a Virtual Reality condition, where 3D brain models were presented using HTC Vive technology. The visualization technologies were evaluated on how well they enabled identification and spatial learning of selected brain structures, on overall usability, and on the amount of study time participants used with the technology. Participants were given a computerized test assessing their knowledge of the brain structures before and after studying with the technology. Participants in the PowerPoint condition used significantly less study time and completed questions on brain structure identification and spatial relationships faster than participants in the Physical Model and Virtual Reality conditions. There were no significant differences in identification/spatial anatomy accuracy, confidence, or technology usability. These findings provide insight into the relative costs and benefits of different 3D visualization technologies for learning gross anatomy. Future research should investigate other measures of effectiveness and learner reactions regarding the use of 3D visualization technologies in anatomical training. 