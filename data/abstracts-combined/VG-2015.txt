Decision making often requires an understanding of where we are, where we want to go, and the options for traversing this distance. Where augmented reality enhances a view of where we are and virtual reality creates a view of where we want to go, Mixed Reality serves the user who needs to see both. The United States Marine Corps is embarking on this new reality to enhance their trade space analysis tool known as FACT  Framework for Assessing Cost and Technology. With the upgrade to Mixed Reality in FACT, users view new designs (where we want to go) overlaid on existing systems (where we are) to best understand design options and implications. This paper details the development process and reviews potential future applications of Mixed Reality.  The popular Frank-Wolfe (FW) algorithm for solving the network equilibrium problems has been well- documented in the literature. Other (more efficient) variations of the FW algorithm (such as Conjugate FW, Bi- Conjugate FW algorithms) have also been extensively studied by the research communities. In this paper, the basic FW algorithm is re-visited, with the ultimate goal of developing a useful, user-friendly, and attractive Java computer animation for effectively teaching this basic/important (transportation network equilibrium) algorithm. Since the shortest path (SP) algorithm (such as the well-known Dijkstra algorithm) is a basic building block within the FW algorithm, the readers are assumed to have a working knowledge about Dijkstra SP algorithm. The final product from this work will help both the students and their instructor not only to master this technical subject, but also to provide a valuable tool for obtaining the solutions for homework assignments, class examinations, self-assessment studies, and other coursework. Engineering educators who have adopted flipped class-room instruction can also utilize the developed JAVA animation software for students to self-learn these algorithms at their own time (and at their preferable locations), and use valuable class-meeting time for more challenging (real-life) problems discussions. The training and simulation industry has been taking cues from the game industry for quite some time now. So whats the next step? Mobile devices are everywhere, and whether it is a Bring Your Own Device scenario or the device is government-furnished, updating content and new content retrieval continue to be issues. Managing users and controlling permission to content are easily accomplished through the implementation of current gaming technology. This presentation will share with you the effort that is currently being put forth to standardize a mobile application library with a delivery system that works like the mobile apps we use every day, providing downloadable content with a touch when users need it most. As long as users have a connection, they can download updated knowledge and training as easily as they can download new levels of Candy Crush. The greying and ultimate retirement of the current generation of energy (both exploration and power plant operators, but especially nuclear) operators present many challenges: a loss of experience, incomplete knowledge transfer, and the necessity to maintain demanding safety and operating standards. A study conducted by the International Atomic Energy Agency in 2004 (1) regarding the state of the worldwide nuclear industry workforce noted that the first generation of operators (those who commissioned most of the nuclear plants) had retired, but that the next group would be retiring in the next 10 years. The ten year period has now transpired. In 2011, the Nuclear Energy Institute (2) forecast a need for up to 25,000 workers by 2015. This need was to meet the predicted loss of approximately 38% of the workforce within 5 years. Further, the article quoted Angel Garcia from Southern California Edison Co, who stated, finding applicants with the right skill sets can be even harder. With fewer potential new hires available from the nuclear Navy, there arent a whole lot of people lined up for jobs that have the skills we need. (3) If the nuclear Navy cannot supply the numbers of operators required to staff the nuclear plants, then other accession sources are required. There is a significant difference in the education and training of operators from the alternative sources, since a great deal of the knowledge gained is theoretical in nature, or might be gained from operations in similar environments, such as conventional power plants. The issue then becomes how to transfer the required knowledge to this group of potential workers. According to research originally performed by Ed Dole and proven by the National Training Laboratory Institute, learners only retain 5% of information taught (and approximately 10  20% of that either read or obtained using audio visual or video methods) as opposed to nearly 75% using the practice by doing approach. (4) The Next Generation of the Nuclear Workforce is comprised of millennials who are comfortable with technology and spend a large portion of their time with screen media. (5) The millennials who are the predominant part of the next generation of operators have had access to computers throughout their lives and are confident gamers. Virtual Environments (VE) now offer many advantages in presentation, realism, assessment, and robustness heretofore unattainable. Game Engines (GE) combine the fascination of gaming with the necessary theory and skills required for the Energy Industry workforce. Until very recently, the ability to perform significant tasks outside the actual power plant has been either extremely expensive (full scale mock ups) or technically unachievable using gaming technology. The visual capabilities lacked realism, and the other aspects of operations such as aural, haptic and olfactory were simply not possible. Eye-tracking has traditionally been used as a means of measuring eye scanning behavior while reading, interacting with Graphical User Interfaces (GUIs) or in providing a user interface for assistive devices for individuals who may not be able to use more standard input mechanisms. As the technology matures there is extensive interest in using eye-tracking as a control mechanism, either augmenting or completely replacing an existing user interface device. Use of eye-tracking technology has the potential of increasing the control bandwidth between a user and a device, something that can be a critical advantage in complex interfaces. At the same time low accuracy or poorly designed interfaces could have a negative effect on ease of use. Thus, it is important to gain an understanding of how eye- tracking accuracy can affect the performance of different control tasks under various control approaches. In this paper preliminary results are presented on eye-tracking accuracy in a simple GUI button selection task with and without cursor feedback. This research is a precursor to a larger study that investigates eye-tracking as a means of controlling a tele-operated robot in a simulated search and the results will be used to optimize the design of discrete selection events in the GUI for robot control. The purpose of this paper is to present a virtual integrated training environment (VITE) under development by ODU and EVMS for use with manikin-based medical training, in manner that exploits computer communication to the manikin. Current medical training uses a self-contained commercial manikin in an ordinary classroom lacking other medical equipment. This system includes tablet-based simulators that represent real medical equipment that is able to directly interact with the manikin. A previous capstone design class also developed a virtual environment with manikin-based training [2]. That group was able to develop virtual devices but was not able to get the devices to communicate with the manikin and vice versa. VITE will establish a communication network that integrates the functionality of the manikin with its surrounding environment. The manikin will function with devices that are able to send and receive information. The paper begins with a physical description of the overall system. Then, the system architecture and system components are detailed. The paper concludes with a functionality description of the prototype devices. A prototype system is currently being developed for Eastern Virginia Medical School as part of a MANDSE Capstone Design Course at Old Dominion University. Military Operations Other Than War, from humanitarian assistance to counterinsurgency support, require actionable cultural intelligence  information that provides understanding of the behavior of a general population and its friendly, neutral, and hostile sub-groups, plus ways to recognize and predict changes in that behavior over time. Cultural intelligence is made actionable through integration with tactical data via the Intelligence Preparation of the Battlespace (IPB) process. Cultural intelligence development and application are poorly supported by existing intelligence systems. This paper explains how a cognitive engineering methodology was used to understand this problem from the analysts perspective and to develop human-centered technology solutions. Domain and semantic analyses were used to identify the concepts and relationships central to creating and applying cultural intelligence. Cognitive work analysis was then applied to the processes and workflows used in cultural intelligence and its integration into IPB at the infantry battalion (and below), where the problem is most acute. User-centered design methods were employed to create and refine user interface, automation, and novel workflow solutions. The paper also describes how the analysis demonstrated requirements for: flexible tools and interfaces allowing ad hoc creation and communication of intermediate products for rapid, collaborative evolution multiple combinable visualizations that support temporal, geo-spatial, and social network-based analysis Lastly, the paper delineates how the requirements translated into the goal of creating shareable, user-constructed products termed "mashups," which enable users to tailor and annotate visualizations for customized, mission- oriented intelligence products. Request for Information (RFI) workflows allow saved mashups and underlying data sets to be restored for live processing, ongoing analyses, and exploration of multiple hypotheses. Automated analyses of data-intensive social media sources were created to meet needs for instantaneous assessment of area atmospherics. These features are integrated into the CultureMap system, which was built upon CHI Systems 4D- Viz framework for creating Command and Control (C2) applications, and has proceeded through establishment of face and construct validity with domain experts. Because the number one preventable cause of death on the battlefield is due to extreme blood- loss from extremity wounds, a low-cost, scalable training solution to prepare every Solider in the use of tourniquets has the potential to save numerous lives on the battlefield. In response to this need, the HapMed system was developed to provide scalable, easy-to-use tourniquet application training to combat medics. HapMed address complex training challenges using a blended training solution encompassing information, demonstration, hands-on practice, and feedback. The purpose of the paper is to provide overall background on HapMed design requirements, illustrate recent advances to the system including a mobile controller application, and to describe the recent lessons learned through feedback garnered from HapMed end-users utilizing it in classroom combat lifesaver courses last year. HapMed provides a practical example of utilizing a blended design strategy to augment simulation-based training with games. The population of small maritime vessels within and around the United States greatly outnumbers the number of law enforcement vessels available to police them. Lawrence Livermore National Laboratory developed the Maritime Simulation Model (MSM) under an interagency agreement with the Department of Homeland Security (DHS) to understand concepts of operations used by law enforcement to encounter small vessel maritime traffic. MSM was implemented as an agent based model in Repast Simphony with limited behaviors and physics. DHS wanted to enhance the physics and behaviors without a significant rewrite or redevelopment of the original code. Under contract with DHS, Engility Corporation migrated MSM into the Defense Threat Reduction Agencys federated modeling and simulation architecture to improve physics, enhance artificial intelligence, and federate with other detection models. Improving the fidelity of simulations required overcoming hardware resource limitations, terrain correlation issues, and assumptions made based on how agents behave in one model framework versus another. The use of video game elements in non-gaming systems, or gamification, has the potential to transform data analysis. Our study focused on creating a web-based videogame that models two physical test buildings, each of which contains hundreds of sensors. After the application renders the models, the player can walk through the environments and interact with the virtual representations of the sensors inside. Rather than querying a database with textual commands and spreadsheets of data, the user can (virtually) walk up to a sensor and view its data graphically. The recent progress in gaming hardware, game design, and data processing can be leveraged for data science. The net result is a more engaging and intuitive platform for data analysis that has the potential to provide additional insight for complex experiments. Training sonar operators for Anti-Submarine Warfare (ASW) in complex environments is challenging. Performance deficiencies are the product of errors in both analysis and employment. Experts use mental models to interpret displays and reason about the underlying scenario in order to perform analysis under uncertain conditions and achieve more optimal tactical-system employment. To accelerate the development of this expertise and improve the retention of proficiency, ARiA is developing the Environment for Surface ASW Interactive Learning (E-SAILTM). E-SAILTM enables operators to visualize the environmental and tactical scenario that resulted in the received sonar signals while allowing them to directly manipulate that scenario and observe the outcome of the manipulation. Here we discuss the theoretical basis for the E-SAILTM learning approach and overview development of the visualization environment and graphical user interface that deploys on tactical hardware and interfaces with tactical displays, tactical decision aids, embedded simulation-based training (SBT), and environmental databases through a high- performance asynchronous messaging library and software-independent interface specification. Training humans to recognize cyberspace operations and respond rapidly and effectively is imperative, because mistakes have immediate consequences. The ever-evolving complexity of the combined cyber / kinetic battlefield drives a need to simulate engagements in high fidelity where each domain affects the other. We present a new simulation approach that integrates real and simulated cyberspace operations, wired and wireless virtual networks, live and virtual equipment and applications, and traditional kinetic warfare training simulators into a full, instrumented, synthetic cyber warfare training environment. The system allows trainee performance centered on awareness, reaction time and correct action (at all levels), along with ability to work through a degraded cyberspace environment and complete a mission, to be monitored and evaluated. We include an example of how cyberspace operations, and human misunderstanding of the operations, can seriously affect a mission outcome. 