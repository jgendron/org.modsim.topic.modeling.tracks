This article presents an IoT (Internet of Things) prototype integrated to a virtual designed environment to allow monitoring and control of electrical substations. The prototype system was developed and tested using an ESP-8266 module, NodeMCU and sensor systems. The main components of the proposed system are: a network of Wi-Fi sensors, a MQTT broker service that acts as a broker connecting sensors as clouds, and a virtual environment developed for the control and monitoring of electrical substations. The use of a wireless network for data collection within a substation presents some advantages comparing with routed networks while the inclusion of a sensor network allows a provision of complementary resources such as monitoring and control of processes inherent in the substation. Many defense organizations report pressure to replace or augment scarce, expensive, and schedule-constrained professionals who are needed to counsel personnel. One method that has demonstrable capability and has found utility is the use of conversational, computer-directed agents. These can respond within appropriate times to a predetermined list of germane questions. These agents can be either animated or live (via a large number of video clips). Early research and development has focused on laboriously generating question lists, paraphrases, recording scripts, utterances, transcriptions, video edits, validations, tests, and updates. The administrative burden of all of this has begun to overshadow the scientific and technical research effort. As this virtual human capability becomes more acceptable and widely implemented, the skills of Systems Engineering are seen as potential facilitators for optimizing the production process. This paper addresses preliminary experience with enhancing an on-going project via Systems Engineering. These approaches should make the adoption of these agents more practical and economical. The authors discuss the use of the V-Model and other Systems Engineering tools in a way that should enable other researchers to understand what can be expected of such an approach to computer-moderated virtual humans and agents. These management tools and techniques provide a real opportunity in the DoD to manifest the early success- es demonstrated in research settings. Optimizing just the transcription phase would save significant amounts of implementation time. The National Aeronautics and Space Administration (NASA) is conducting research into the utilization of real-time human characterization models for the prediction and mitigation of flight crew Spatial Disorientation (SD) through customized alerting solutions. Despite rapidly evolving flight deck technologies over the past fifty years, reported occurrences of flight crew SD have not decreased. Under the Technologies for Aircraft State Awareness sub-project, NASA researchers have partnered with experts in the field of flight crew SD research from academia and private industry to develop a human software model for the real-time prediction of flight crew SD. Using a combination of a human-vestibular system model, aircraft dynamics, and physiological sensors, a characterization model was developed to estimate the discrepancy between perceived aircraft state (via eye tracking and other devices) for comparison against state data from the avionics system in order to detect flight crew SD. The Cost Effective Devices for Alerting Research (CEDAR) study seeks to build upon this work using the human SD software model to trigger salient alerting solutions which have been customized to meet the current attentional demands of the flight crew. This research is intended to develop a proof-of-concept for real-time SD mitigation which could eventually be utilized to improve safety in future air transport operations. This paper will discuss the details of how the proposed system will function, including the current state of this research and directions for future work. In response to an increasingly complex and uncertain operational environment, the United States Military requires innovative technologies to enable adaptable, full-spectrum operational training. Live, Virtual, Constructive, and Gaming (LVC&G) environments offer desirable solutions to a myriad of training challenges and support safe, multi- faceted training to improve readiness at the point-of-need. LVC&G offers high return on investment from saving assets for actual operations, lessening overall logistical costs and planning timetables, increasing flexibility and training dynamics, and reducing preventable mishaps during range training. However, often the adaptability and scalability offered by traditional solutions are hampered by closed, stovepipe software applications. In this paper, we will review the use of commercial gaming technology as a development tool and software runtime to address some of these obstacles. Specifically, we will analyze the use of Unity, a commercial game engine, for multi-domain image generation in scalable LVC&G military exercises at the individual, unit, leadership, and international levels. Operation Blended Warrior (OBW), an annual LVC&G event, will be reviewed to highlight the current state of the industry and technical challenges associated with integrating non-traditional gaming technologies into full-scale exercises. Key interoperability and scalability issues including asset reusability and standards-based communication protocols, typically absent in commercial game engines, will be discussed. This paper will offer Industry and Government forward-leaning suggestions to best position both to understand and leverage disruptive commercial gaming technologies in combination with simulation middleware to engineer innovative capabilities to modernize training for operational readiness. Unmanned surface vehicles (USVs) have become a key technology for payload delivery, remote sensing, and surveillance. Most development involves converting existing manned vehicles to unmanned, but several vessels are specifically designed for unmanned operation. One such vessel is the Wave Adaptive Modular Vessel (WAM-V), manufactured by Marine Advanced Research. To maintain flexibility, the WAM-V leaves the design of the propulsion system to the user. This paper describes the use of simulation to optimize the mechanical design of a WAM-V propulsion system. Given the wide availability of marine propulsion approaches and design options, it is impractical to experiment with physical prototypes. Simulation-based optimization is the most viable approach for optimizing system performance. The paper describes the initial analysis and use of simulation to finalize the propulsion system design. This is an interesting engineering case study because it combines multiple levels and types of simulation for system optimization based on multiple constraints. Structural health monitoring (SHM) has the capacity to reduce failure by detecting damage during service life, by periodic, automated monitoring. Guided Wave (GW) Ultrasound is a common SHM approach for aerospace structures. Modelling the physics of GW SHM systems provides a route for understanding system dependencies, capabilities and limitations as damage evolves during service life. Such a toolset can strengthen the understanding of the connection between GW SHM results and the true material state. The most useful modelling tools are those that provide versatile solutions with respect to the simulated component geometry and computational grid connectivity. This work details a versatile application programming interface (API) for the elastodynamic finite integration technique for modelling GW SHM of metals. The custom code implementation, EFIT-CompCell, allows for the modelling of diverse geometries by automatically balancing the message passing interface parallelization layout. The user provides the basic parameters of the simulation and the software automatically performs an initial balancing based on anticipated computational loads, and establishes the CPU communication patterns for any geometry. This work describes the programming philosophy and code structure used to create EFIT-CompCell and compares its performance and capacity to simulation tools that are more specialized for specific architectures. Results are presented for a simulation of GW SHM of an aluminum fuselage section being tested by the FAA. The simulation consists of 733M voxels which took approximately 70 hours to complete 25000 time steps using 40 Intel Xeon E5-4650v2 Ivy Bridge processor cores. Branches of the military are wasting time and money by duplicating efforts for proprietary scripted training systems. Training simulations offer tremendous promise in reducing costs and increasing realism but fail to achieve either aim. Efforts to create intelligent agents have been undertaken, but often are constrained to one simulation environment, leading to limited success. Standardization has failed, due to the fact that competing companies cling to their own solution as the best and only way. The Multi-level Universal Specification for Intelligent Characters (MUSIC) provides a standard that participating simulation systems (PSS) can adopt to gain access to intelligent characters that can act within their environment. MUSIC will not require each participating cognitive system (PCS) to code in any particular programming language, but will provide rules of when and how to display situations to trainees within a standalone or federated simulation. Each simulation, regardless of its fidelity, will be able to leverage aspects of MUSIC to enhance training. By specifying things like Levels of Detail (LoD), simulations can automatically adjust based on the current training need and their capabilities. For instance, a Semi-Automated Forces (SAF) system or a birds eye view simulation of a village may only need to show basic details, whereas first person 3D simulations might require an elaborate set of animations. This paper discusses the benefits of multiple levels of detail and explores different examples of how MUSIC can be deployed as a foundation for adaptable and scalable training solution that focuses finite investment dollars and maximizes returns. This paper addresses optimization of language model databases for use in range of chatbots, e.g. virtual conversational mentors. The proliferation and practical use of chatbots depends on the ability of users to conversationally retrieve information or activate events. These conversations ideally help the user efficiently access a broad set of computational functions accurately and in as few turns as possible. However, there is a concomitant pressure to reduce size, increase speed, and enable offline capabilities. Such offline and online dialog capabilities are particularly vital for DoD applications, which are increasingly being developed to produce intelligent agents that help explain complex data and operate in low-resource environments (e.g., no reliable internet). Unfortunately, not only is natural language processing a computationally expensive task, but language models are often heavyweight, with large storage space footprints and challenges for keeping data in-memory that affect search and retrieval times. A chatbot must be able to understand and respond to a variety of unique user inputs and do so within the limits of conversationally tolerable latencies. The difficulty comes in trying to balance an effective chat agent while optimizing storage for peak performance. This paper applies and analyzes two methods for reducing language models, using the Google News Word2vec model as an example. These methods were implemented with the goal to support natural a language dialog system without the storage overhead of the significantly larger comprehensive models. Two metrics were applied to reduce the language model: word frequency and relevance to the domain- specific information that the agent can discuss. We will document and analyze similar efforts, set forth potential approaches, discuss solutions within our environment, quantify impacts of the implementation of these approaches, outline future applications, and suggest topics for further research. The paper closes with ways in which others can adopt this approach to their own efforts. Models and simulations (MANDS) are often developed to meet specific needs and unique requirements for a particular situation. Once the MANDS is implemented for a specific case and questions are answered, the MANDS may go dormant until a similar need arises again at a later time, perhaps months to years later. Possible modification of the MANDS may be required, and issues may arise if the MANDS is not well documented, captured, or available. This can severely limit the useful life of the MANDS and hinder future development or enhancements. This situation occurred with an MANDS tool that had been developed to determine the impact to space system performance due to the presence of molecular contaminant films accumulating on key spacecraft surfaces. The challenges and issues encountered when resurrecting, executing, and modernizing the tool will be presented as a case study. To stay ahead of tomorrows challenges, resources to create MANDS tools must be utilized efficiently. Lessons learned from this case study will aid MANDS developers and users in planning for proper maintenance, transfer, and capture of key MANDS tools and knowledge to avoid increased cost, increased development time, and wasted resources for projects relying on MANDS. Virtual SATCOM is wireless communication at SATCOM speed on a HF Skywave channel without a physical satellite. Why: DOD needs a SATCOM alternative to mitigate the space vehicle vulnerability. The ionosphere is an underutilized channel that can mitigate the risk. Our modeling has shown the ionosphere can be harnessed to communicate at long range (3000 km) and high speeds (>12 Mbps). Compared to SATCOM, current HF protocols are too slow. We are developing a Virtual SATCOM system. It is a high bandwidth HF communications channel that can match SATCOM throughput at a reduced cost and vulnerability. RF waves in the HF band (3-30 MHz) transmitted into the ionosphere are refracted (bent) back to earth thousands of kilometers down range. However, the ionosphere is an inhomogeneous, anisotropic, non-linear time-varying environment. Modern communications techniques can adjust to the dynamic environments. One area of our research is to provide evidence that this concept will work in the dynamic ionosphere environment. We needed a precision modeling tool of the ionosphere plasma with an iterative ray tracing simulation capability that shows channel paths from transmitter to receiver. We are using a tool called PHaRLAP to model the environment. PHaRLAP is an over the horizon radar (OTHR) program developed by the Australian Defense Science and Technology Group to analyze OTHR systems. We have modified the program to support wideband communications research. Our simulations show that an HF agile communication system can significantly improve throughput. The model ingests data from the International Reference Ionosphere to calculate the plasma grid. Our system will be able to service mobile users (e.g., maritime, expeditionary and aviation) using steerable beamforming apertures with ultra-wide bandwidth signals (3MHz). This is exciting research that can reduce cost and increase access to long range high data rate wireless communications. 