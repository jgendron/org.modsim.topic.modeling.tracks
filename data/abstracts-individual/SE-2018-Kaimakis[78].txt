This paper addresses optimization of language model databases for use in range of chatbots, e.g. virtual conversational mentors. The proliferation and practical use of chatbots depends on the ability of users to conversationally retrieve information or activate events. These conversations ideally help the user efficiently access a broad set of computational functions accurately and in as few turns as possible. However, there is a concomitant pressure to reduce size, increase speed, and enable offline capabilities. Such offline and online dialog capabilities are particularly vital for DoD applications, which are increasingly being developed to produce intelligent agents that help explain complex data and operate in low-resource environments (e.g., no reliable internet). Unfortunately, not only is natural language processing a computationally expensive task, but language models are often heavyweight, with large storage space footprints and challenges for keeping data in-memory that affect search and retrieval times. A chatbot must be able to understand and respond to a variety of unique user inputs and do so within the limits of conversationally tolerable latencies. The difficulty comes in trying to balance an effective chat agent while optimizing storage for peak performance. This paper applies and analyzes two methods for reducing language models, using the Google News Word2vec model as an example. These methods were implemented with the goal to support natural a language dialog system without the storage overhead of the significantly larger comprehensive models. Two metrics were applied to reduce the language model: word frequency and relevance to the domain- specific information that the agent can discuss. We will document and analyze similar efforts, set forth potential approaches, discuss solutions within our environment, quantify impacts of the implementation of these approaches, outline future applications, and suggest topics for further research. The paper closes with ways in which others can adopt this approach to their own efforts. 