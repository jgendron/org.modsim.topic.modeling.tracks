ABSTRACT
Transforming e-Learning into o-Learning
The Power of Organic Learning without the Bells and Whistles
David Fautua, Ph.D.
Joint Staff J7, Joint Training Suffolk, VA david.t.fautua.civ@mail.mil
Sae Schatz, Ph.D.
Independent Consultant Orlando, FL sae.schatz@gmail.com
Online courseware can support effective training and education; however, e-learning is sometimes lackluster. Courses may bore learners; topics might seem shallow, or students’ content retention may fall below par. Increasing the interactivity of online courseware can boost engagement and learning; however, “increased interactivity” is sometimes just a euphemism for “more technological bells and whistles.” The challenge is further complicated when customers, such as trainers across the joint military enterprise, are either unaware of the full capacity of web-based learning tools or uncertain of how to maximize their utility. Thus, while employing state-of-the-art technology is admirable, what is most needed is a fresh way to use those technologies in more innovative and effective ways, to create tailored training experiences, and to facilitate organic learning (i.e., localized, tailorable). In other words, trainers need support leveraging the considerable e-learning capabilities that already exist, as well as making them personally meaningful and integrating them with other training experiences.
In this paper, we examine how to close the gaps mentioned above. We first describe the power of developing organically centered training supported by e-learning technologies. Some of these technologies include tailored online course content and small group scenario trainers, both with embedded metrics to assess individual and team competencies respectively. We then describe how new and different uses of existing e-learning technologies can help joint trainers create rich learning environments designed to best support the needs of their units. In our own work, we have implemented instructional tactics such as situational judgment tests, card sorting using multiple- choice radio buttons, and story-based learning, and we are currently working on methods to capture e-learning content for team-centered part-task training. Finally, we close this paper by describing our next steps, including the andragogical principles we are exploring in our ongoing work to support training for the Chairman’s six Desired Leadership Attributes in technologically supported training environments.
ABOUT THE AUTHORS
David T. Fautua, Ph.D., is Chief, Individual Training & Learning, Joint Training, J7 Joint Staff. He formerly served as U.S. Joint Forces Command Academic Chair, held an appointment as visiting associate professor at the Joint Forces Staff College, and was special assistant to two NATO Supreme Allied Commanders. Most recently, he served as the principal investigator for the NTSA-award winning Border Hunter research project.
Sae Schatz, Ph.D., is an applied human–systems researcher, professional facilitator, and cognitive scientist. Her work focuses on human–systems integration (HSI), with an emphasis on human cognition and learning, instructional technologies, adaptive systems, human performance assessment, and modeling and simulation (M&S). Frequently, her work seeks to enhance individual’s higher-order cognitive skills (i.e., the mental, emotional, and relational skills associated with “cognitive readiness”). In addition to her research, Dr. Schatz mentors graduate students, teaches in the M&S graduate program at the University of Central Florida (UCF), and facilitates professional seminars for business and government clients.
2015 Paper No. 027 Page 1 of 9
MODSIM World 2015

Transforming e-Learning into o-Learning
The Power of Organic Learning without the Bells and Whistles
David Fautua, Ph.D.
Joint Staff J7, Joint Training Suffolk, VA david.t.fautua.civ@mail.mil
INTRODUCTION
Sae Schatz, Ph.D.
Independent Consultant Orlando, FL sae.schatz@gmail.com
MODSIM World 2015
       In 2014, Activision’s Call of Duty: Advanced Warfare outsold all other video games in the U.S. (Kain, 2015). CoD: Advanced Warfare features advanced gameplay mechanisms, voice acting by Kevin Spacey, and award-winning visual effects (IGN, n.d.). The success of CoD and similar commercial game franchises seems to imply that heavy investments in technical embellishments draw customers, and it may even appear to suggest that current generations have come to expect (and are disappointed when they don’t receive) this level of sensory stimulation.
However, another top-earner of 2014 was Microsoft’s Minecraft, a game that involves roaming around a 3D sandbox and interacting with textured cubes. The game lacks a formal narrative or given player objectives; instead, players can participate in a number of different ways, from collaboratively hunting monsters to making crafts and building individual cities. Minecraft, which features 1980s-era graphics and a notable dearth of voice actors (either famous or mundane), was released gradually and iteratively. Each new version increased the game’s content and its players’ ability to creatively experiment with the world. The user community is also encouraged to create mods and further tailor the game in inventive ways. In short, Minecraft—now the best-selling PC game to date (Tee Hunter, 2014)—triumphed, arguably as well as CoD: Advanced Warfare, by championing players’ creativity and involvement, and without relying on “technological bells and whistles.”
 Parable of the 8-Bit Sandbox...
 Training developers have heard the research and know the general advice: “Content is king.” But when surrounded by the latest gadgets at tradeshows or immersed in this season’s next IMAX blockbuster, it can become difficult to ignore the pull of sleek graphics and surround sound. Instructional technologies, however, rarely have the luxury of incorporating the latest technological gimmicks, and military online learning content, in particular, typically falls on the “late majority” side of the innovation curve.
Coincidently, military online learning is generally ranked as “middle of the road” by personnel taking the courses. (This is according to our own past empirical research. Roughly 200 joint personnel rated their experiences with typical military e-learning courses, which ranked slightly below average on a 5-point scale; see Fautua et al., 2012.) A natural tendency is to believe that leveraging the latest technology innovations might help increase interactivity of these courses and, in turn, student engagement, learning, and positive regard.
More broadly, the nature of joint training is currently being redefined by the Combatant Commands (CCMDs) and other joint force commands (JFC). Large collective exercises are not only viewed as increasingly too expensive but also underwhelming in terms of developing individual and team competencies across the various staff working groups that bear the brunt of the planning requirements. These are the boards, bureaus, centers, cells and working groups (B2C2WG) that represent integrated staff groups who perform the mission analysis planning and produce the course-of-action options for senior decision-makers. While Joint trainers are well aware that online learning technologies may provide alternative training options (that are less costly yet highly effective), they are uncertain as to how to leverage the right tools in the right way. Thus their requests for assistance (i.e. web-enabled blended learning capabilities) are often received as requests for more “bells and whistles” or worst, as an “unstated” demand signal.
Certainly, increasing the interactivity of online courseware can boost engagement and learning; however, “increased interactivity” is sometimes just a euphemism for “more technological bells and whistles.” While employing state-of-
2015 Paper No. 027 Page 2 of 9

the-art technology is admirable, we need to find those technological innovations that truly support learning goals and then pair them with the instructional framework needed to reap the most value from our investments.
In this paper, we examine several real-world examples from current military training that use inventive instructional strategies and tactics to enhance engagement and learning. For example, these include blended-learning processes, inclusion of formative (in addition to summative) assessments, facilitation of tailored organic e-learning, and the rendering of table-top staff events or functionally-centric staff training into web-based small group scenario/part task trainers (i.e. targeting for lethal or non-lethal planning). To achieve these goals, we have implemented instructional tactics such as situational judgment tests, card sorting using multiple-choice radio buttons, and story-based learning, and we are currently working on methods to capture and render the organic e-learning content into small group scenario/part task trainers. Finally, we close this paper by describing our next steps, including the andragogical principles we are exploring in our ongoing work to support training for the Chairman’s six Desired Leadership Attributes in technologically supported training environments.
THE CONTEXT
Training Demands
Across the DoD, the Services and Joint Staff share several similar learning challenges, including shrinking training budgets, the need to better develop their “human dimension,” and the push to use more distributed/mobile learning technologies. (For examples, refer to the Army’s efforts to advance the Human Dimension [U.S. Army Combined Arms Center, 2014], Marine Corps’ Small Unit Decision Making initiative [SUDM, 2011], and Chairman, Joint Chief of Staff’s (CJCS) six “Desired Leader Attributes” [CJCS, 2013]).
Over the last few years, our own work has emphasized these themes within the context of the joint training for staff at Combatant Commands and their components. Combatant Commands are constantly evolving and re-evaluating their joint exercise programs to meet their ever-changing mission requirements in an uncertain operating environment. They are placing more emphasis on nuanced training, such as where the commander’s intent (rather than static exercise objectives produced by staffs) purposefully drives large collective training events, or where ad hoc small battle staffs (formally, boards-bureaus-centers-cells-working groups, or B2C2WGs) have to come together to work through complex problem-based training. The trend is toward a more realistic approach to training conditions that approximates the many stressors, challenges, and ambiguities of the real operational world.
This evolution parallels the CJCS’s recently published emphasis on six Desired Leader Attributes that centered on cognitive readiness type skills (e.g., anticipation, adaptability, critical thinking). However, to our knowledge, these attributes have not been explicitly integrated into joint training, yet.
These trends mark the need to ensure that Joint Force Command staffs possess a clear understanding not only of their commander’s intent, but also his or her mode of thinking, habits of problem-solving, and approach to design, in order to operate more adaptively, be more able to anticipate change (and articulate friction points), and be more able to problem-solve and conceptualize and create solutions despite the ambiguity of their conditions. Combatant Commands therefore require an organic capability (and know-how with a new body of language, process and framework for cognitive training). Said another way, Combatant Commands need training that exercises the human dimension, is tailored to their unique missions and processes, and which can support training at multiple scales (i.e., individuals, small groups and large collective exercises).
MODSIM World 2015
      (1) The ability to understand the environment and the effect of all instruments of national power
(2) The ability to anticipate and adapt to surprise and uncertainty.
(3) The ability to recognize change and lead transitions.
(4) The ability to operate on intent through trust, empowerment, and understanding (Mission Command).
(5) The ability to make ethical decisions based on the shared values of the Profession of Arms.
(6) The ability to think critically and strategically in applying joint warfighting principles and concepts to joint operations.
  Desired Leader Attributes (CJCS, 2013):
 2015 Paper No. 027 Page 3 of 9

Blended Learning–Training System
We have previously written about the Blended Learning–Training System (BLTS), a concept, set of processes, and content repository designed to support blended learning within the Joint Training System (see Figure 1, below, and for more information refer to Fautua et al., 2014). To briefly review, this system complements the Joint Training System (see U.S. Joint Staff doctrinal publications CJCS Guide 3501 and CJCSM 3500.03D), which, similar to the well-known ADDIE model of instructional design (Branson et al., 1975), defines deliberate processes for designing, planning, executing, evaluating, and assessing joint training. The technology that supports part of the BLTS resides on Joint Knowledge Online (JKO), and the courseware component uses the standard JKO Learning Management System.
Joint Blended Learning Concept Processes and Documentation Instructional Content
Figure 1. The BLTS comprises (1) the blended learning concept, (2) a set of processes, and (3) a repository of instructional materials for supporting blended learning within the joint training enterprise (web-based examples shown)
FOUR TECHNIQUES TO ENHANCE E-LEARNING
The sections below outline four solutions we are exploring within the context (i.e., training demands and BLTS) mentioned above. Our goal with these is to deliver engaging and authentic training. By engaging, we mean that the participants feel motivated to actively participate (versus simply “clicking through” the training). By authentic, we mean that the training has real-world value—not only in abstract terms but to each learner’s own, personal context. To achieve this definition of “authentic,” we need to create training that can be tailored to each training audience subgroup. Of course, no matter how diverse the training audience, each instance of the training must still adhere to certain doctrinal principles and core messages.
Each of the following ideas is a low-cost way to attempt to build “o-learning” (i.e., organic learning, that authentic and tailored content). For the sake of efficiency and management, each of the tailorable solutions builds upon an e- learning foundation, and that e-learning core is developed by the Joint Staff J7 (Joint Training) for consistency. We have partially implemented three of the following ideas, and we are currently testing out the last.
1. Use creative formative assessments with open-ended solutions
When first conceptualizing the BLTS, part of our goal was to deliver training that helped foster participants’ higher- order thinking skills. We needed to develop material that encouraged thinking and interaction with the content, but we had limited resources available to create new interactive content. Instead, we needed to use standard HTML 4.0 features, including text, graphics, radio buttons, checkboxes, and drop-down menus. Pages could also include textboxes and text areas; however, entries into those could not be scored with any sophistication. Given our restrictions, we decided to incorporate formative assessments into each e-learning course to help encourage students’ thinking.
Formative assessments are often called “assessments for learning,” in contrast summative assessments, which are “assessments of learning.” In other words, formative assessments enhance the effectiveness of a course, while summative assessments generally support grading. Formative assessments can help gauge students’ progress,
MODSIM World 2015
        2015 Paper No. 027 Page 4 of 9

modify teaching and learning activities, and improve learner achievement (Shute, 2007). These assessments are typically less formal than summative tests, and the actual scores earned on formative assessments need not be officially recorded, since performance on formative tests is used to provide feedback rather than track student outcomes. When used appropriately, inclusion of formative assessments can improve students’ learning outcomes by 20–40 percentile points (Ainsworth, 2006).
Many self-direct e-learning courses only measure lower-level KSAs and their associated mental processes, such as knowledge acquisition, comprehension, and basic application (Bloom, 1956). For instance, tests may simply measure, and likely only motivate, recognition (e.g., select the right vocabulary word from a short list of multiple choice options), recall (e.g., given a short definition, determine whether it is true or false), or basic procedural application (e.g., correctly number the order of steps associated with a given task). We wanted to encourage participants to think a little more deeply about the content.
Researchers have developed a variety of approaches for better assessing higher-order thinking; these include the use of Behaviorally Anchored Rating Scales (BARS), rubrics, concept maps, card sorting tests, situational judgment tests (SJTs), metacognitive prompts, and self/team-correction. Unfortunately, such assessments usually require expert human graders, and even if they could be automatically scored by a computer, the JKO Learning Management System did not support such algorithms. Hence, one challenge for the BLTS was to utilize assessments that address higher-order thinking while only using components that could be implemented by the online system.
We outlined these criteria for the assessments:
 Encourage students to engage in analysis, synthesis, evaluation, and metacognition
 Items may not always include “right” answers; instead list better and worse options (shades of gray)
 Distractor items on questions (i.e., the incorrect options) should correlate to known gaps/misconceptions
 If incorrect options are selected, the specific underlying gaps or misconception should be remediated
(versus simply restating the correct answer in a different way, which is also useful but not sufficient)
For the early BLTS courseware, we used standard HTML forms to build the formative assessments (see Figure 2):
 Concept maps turned into multiple choice tests (radio buttons) or drop-down lists (combo boxes)
 Situational Judgment Tests as multiple choice quizzes or ungraded short answers
 Card sorting using radio buttons in columns adjacent to each item
 Open-ended (i.e., textboxes or text areas) metacognitive prompts that were not graded, but instead used to facilitate formative (self-)assessment and provided as input to the observer/trainers
Example Concept Map Question Example Situational Judgment Test Question
Figure 2. Screen captures of some formative assessments from the BLTS
MODSIM World 2015
        2015 Paper No. 027 Page 5 of 9

How is it o-learning? Individual members of the training audience have the opportunity to insert their own responses and have discussions with on-site observer/trainers about their answers. The questions are uniform, but the specific details of the responses may vary by functional area and component.
Did it work? The four varieties of assessment questions (mentioned above) were implemented in the BLTS courses, and have been completed by several hundred staff members. The HTML-form technology and instructional design of the questions, by themselves, appear successful (given only anecdotal feedback at this time). However, the context surrounding their delivery needs—and continues to be—refined. Personnel responsiveness to the items varies. Some learners treat the questions thoughtfully, while others enter random content in order to move forward. Also, the questions and the responses they elicit could be refined to aid diagnosis and subsequent tailoring of the live training.
2. Put an instructor in the loop
The online content delivered through the BLTS augments existing staff exercises. Similar to the “flipped classroom” concept, it allows personnel to complete their general, process-oriented training flexibly, prior to attendance at the exercise. Then, once gathered at the training event, the observer/trainers can focus on remediation or more nuanced instructional topics.
Getting the “blending” right continues to be an ongoing process. For the training audience, they need to know that their performance in the online courses matters. They need to see that someone will review their progress and ungraded formative assessment inputs, and they need to understand how their interactions with the online courseware affect the delivery of the exercise. Without this clearly articulating this from the beginning, it is difficult to encourage their full interaction with the training or formative assessments. For the observer/trainers, they needed to receive meaningful reports from the online system that clearly guided their next steps (e.g., training audience remediation) and that did not require significant time to review.
Creating a compelling message for the training audience, and delivering timely and actionable reports to the observer/trainers continues to present difficulties. These challenges are being gradually overcome through incremental improvements to messaging and to refinements to the report format and presentation to the observer/trainers.
How is it o-learning? The flipped classroom approach allows the common, doctrinal content to be taught by the automated system, thus freeing up—and encouraging—the local trainers to deliver more tailored, mission-specific additions. Further, by arming those training personnel with performance outcomes and demographic data taken from the online system, they can better align their offerings to the unique context and mission of each training audience.
Did it work? We eventually developed an effective blended learning process; however, it took three years to establish all of the moving parts, and we continue to refine it. Blended learning at this scale requires the support and coordination of many diverse stakeholders. Ultimately, though, the system has measurably enhanced training outcomes (see Fautua et al., 2014) and, anecdotally, achieved efficiency savings as well.
3. Package multimedia assess for later use (including live training)
The BLTS courseware (like many online courses) often includes multimedia videos, either fictionalized stories inspired by real-life events or historic accounts. The movies include highly descriptive, probing narratives and/or relevant real-world stories, which describe the challenges and context of topics like cyber operations, forming a Joint Task Force, and planning for lethal and non-lethal targeting. To remain impactful and compelling, e-learning technicians attempt to keep the videos to the movie industry standard of 2.5 minutes.
In addition to using these assets online, in-residence academics and/or tutorials can be enhanced by including these videos. In a plenary setting, instructors can use the videos to stimulate interest, quickly place complex topics into context, and to generate probing questions that enable trainers to kindle a constructivist learning approach and avoid the “sage on the stage” legacy approach.
2015 Paper No. 027 Page 6 of 9
MODSIM World 2015

How is it o-learning? This idea is straightforward: Create some of the online multimedia objects in a way that enables their reuse. For instance, make sure they can stand alone (like “trailers”) and make them accessible to observer/trainers and other local training personnel at Combatant Commands and their components. Give people tasked with training at the local level the tools they need to quickly and easily deliver high-quality training that aligns with the general e-learning content and large-scale exercises.
Did it work? Anecdotally, we have received positive feedback from Commandant Commander trainers who appreciate the access to training content that they can reuse for sustainment and on-boarding training in addition to the major training events with direct JSJ7 involvement. However, it is too soon to determine if they effectively support the desired balance of standardization and local-tailoring.
4. Make it easy to repackage or insert local content into standardized e-learning
Utilizing existing e-Learning tools in new and innovative ways can help create effective o-Learning environments. For instance, instructional system designers can essentialize an organization’s planning processes for key functional areas into online course content, complete with embedded metrics (e.g., processes for conducting foreign humanitarian assistance/disaster relief or targeting processes to produce lethal and non-lethal courses of action). The same can also be done to render other internal documents like operational concept plans (CONPLANS) or concepts of operations (CONOPS). The point here is to enhance the training authenticity by using the organization’s own products as part of the training materials.
Trainers can also leverage e-Learning tools to enable an organic learning environment by rendering problem-based scenarios into small group/part task trainers that reflects an organization’s culture, norms and common understanding of the challenges. In this way, authentic challenges are not learned through abstract scenarios but rather from probable settings and where the learning experience is connected, where knowledge is constructed by individual or small staff groups from existing knowledge within the organization’s network (Frissen, 2009).
 The case of Southern Command provides an instructive example on how a suite of instructional eLearning tools are being leveraged to enable an “o-Learning” training environment. Planners from the J5 (future planning cell) and J3 (future operations cell) wanted an organic training tool to rehearse simultaneous but different time-horizon planning processes between an integrated cell of future planners (conditions for 72 hours ahead) and an integrated cell of future operations (little-to-no-notice warning), to practice jumping into a crisis action planning process from a dead start (see Figure 3).
One of those techniques is to help trainers and teachers to capture peak learning experiences from the organization’s own in-residence training (for individuals and small groups) and then render those experiences into tailored instructional e-learning tools that organizations can reuse and enhance over time.
Figure 3. Organic Training Plan Example
How is it o-learning? This idea promises to yield the largest opportunities for o-learning. Enabling local trainers to not only capture their functionally based staff training, that are often no more than PowerPoint-driven micro exercises but also to render the entire environment onto a web-based blended learning training package (BLTP) that the staffs can reuse as often as desired to sustain their training or to bring individual augmentees quickly up-to- speed. These BLTPs could include a complete rendering of the training scenario into a team-based part task trainer that would already have embedded organizational planning processes, Concept of Operations documents, and tailored course content, all with embedded metrics. The Future Plans and Future Ops described above can rehearse as often as desired their requirements to transition a long-lead plan to the current operations cell. In the same way, the various integrated working groups associated with a Joint Fires planning mission could rehearse complicated targeting planning that for simultaneous lethal and non-lethal considerations. Building these BLTS from the bottom up, insert an organization’s own products into standardized training materials means that those generic training scenarios would become instantly more relevant to the local training audiences. Even adding just one or two command-specific documents changes the overall favor of a prepackaged scenario to one that is organizationally
2015 Paper No. 027 Page 7 of 9
MODSIM World 2015

“mission-focused.” Further, having the flexibility to “mix and match” off-the-shelf training offerings to create a unique, compose solution (like the SOUTHCOM example), provides necessary flexibility to the Combatant Commands and their components.
Did it work? We are currently testing out these ideas, but initial progress has been positive.
CONCLUSION
This paper highlighted a handful of in-progress ideas. These concepts build upon principles of instructional design, in an attempt to increase learner engagement and the authenticity of the content. Less formally, we want to use low (or no) cost methods to make the standardized training meaningful to each set of participants. Essentially, organic training incorporates the best from blended learning (active learning) methods where learning is pulled by the learner, and not pushed from systems outside of the organization’s culture.
ACKNOWLEDGEMENTS
The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Joint Staff or the U.S. Government.
REFERENCES
Ainsworth, L., & Viegut, D. (Eds.). (2006). Common formative assessments: How to connect standards-based in- struction and assessment. Corwin Press.
Bloom, B.S. (Ed.). (1956) Taxonomy of educational objectives: The classification of educational goals. Handbook I: Cognitive domain. New York: Longman.
Branson, R. K., Rayner, G. T., Cox, J. L., Furman, J. P., King, F. J., & Hannum, W. H. (1975). Interservice procedures for instructional systems development (NTIS No. ADA 019 486 through ADA 019 490). Ft. Monroe, VA: U.S. Army Training and Doctrine Command.
Chairman of the Joint Chiefs of Staff (2013, Oct 10). 2014-2017 Chairman’s Joint Training Guidance (CJCS Notice 3500.01). Washington, DC: Joint Chiefs of Staff.
Fautua, D. T., Schatz, S., Reitz, E., & Bockelman, P. (2014). Institutionalizing blended learning into joint training: A case study and 10 recommendations. In Proceedings of the Interservice/Industry Training, Simulation and Education Conference (I/ITSEC), Orlando, FL.
Fautua, D., Schatz, S., Taylor, A., Reitz, E., Bartlett, K., & Killilea, J. (2012). Continuum of eLearning: 2012 Project Summary Report (Technical Report) Orlando, FL: DSCI MESH Solutions.
IGN (n.d.). Best Graphics - Technology. Retrieved from http://www.ign.com/lists/best-of-games- achievement/technology/call-of-duty-advanced-warfare
Kain, E. (2015, Jan. 19). The Top Ten Best-Selling Video Games of 2014. Forbes.com. Retrieved: http://www.forbes.com/sites/erikkain/2015/01/19/the-top-ten-best-selling-video-games-of-2014/
Norm Frissen, Rethinking e-Learning Research: Foundations, Methods and Practices (Peter Lang Publishing, 2009: NY), pp. 1-4.
Shute, V. J. (2007). Focus on Formative Feedback (RR-07-11).
Small Unit Decision Making (2011). US Marine Corps Small Unit Decision Making January 2011 workshop report. Quantico, VA: USMC Training and Education Command.
Tee Hunter (2014, Sept.). Top 10 Best Selling PC Games. TeeHunter.com. Retrieved http://teehunter.com/2014/09/top-10-best-selling-pc-games/
U.S. Army Combined Arms Center (2014). The Human Dimension White Paper: A Framework for Optimizing Human Performance. Retrieved February 4, 2015 from http://usacac.army.mil/sites/default/files/documents/cact/HumanDimensionWhitePaper.pdf
2015 Paper No. 027 Page 8 of 9
MODSIM World 2015

U.S. Joint Staff (2012, August 15). Joint Training Manual for the Armed Forces of the United States (CJCSM 3500.03D). Washington, DC: Joint Chiefs of Staff.
U.S. Joint Staff (2012, June 8). The Joint Training System: A guide for senior leaders (CJCS Guide 3501). Washington, DC: Joint Chiefs of Staff.
2015 Paper No. 027 Page 9 of 9
MODSIM World 2015
