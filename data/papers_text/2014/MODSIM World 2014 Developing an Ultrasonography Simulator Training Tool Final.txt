Developing an Ultrasonography Simulator Training Tool: From Platform to Interface to Graphics
William T. Richards, MS ; Hector M Garcia, MS ; John A. Sokolowski, PhD ; Catherine M. Banks, PhD Virginia Modeling, Analysis, and Simulation Center. Old Dominion University
Norfolk, Virginia USA
wxrichar@odu.edu, hgarcia@odu.edu, jsokolow@odu.edu, cmbanks@odu.edu
ABSTRACT
This paper presents the development of an Ultrasonography Simulator Training Tool. Ultrasonography is a user-dependent technology requiring Operator motor skills for appropriate probe manipulation and cognitive skills to capture images, acquire situational awareness, and interpret pathology. Three challenges arise in developing a cost-effective simulator training tool that provides physical (hardware) and cognitive (software-visualization) learning experiences: 1) ability to place pathology on a body-like shape (mannequin) without attaching sensors to the surface, 2) ability to track and register pathology and the probe using Commercial Off the Shelf gaming devices, and 3) engaging gaming development software for simulating echo patterns of ultrasound beams from animated 3D surface data in real-time and display a realistic 2D dynamic ultrasound image. With medical collaboration this project produces a prototype real-time, dynamic ultrasound simulator trainer specific for cardiac interrogation. It accommodates extendable dedicated teaching components with additional 3d anatomical data and teaching materials for instructor observation capability.
ABOUT THE AUTHORS
William Richards. MS, is a VMASC senior project scientist having worked on military simulation projects and parallel processing tasks. He also is developing software for a variety of medical projects including, disease modeling, virtual reality rehabilitation, the ―personal digital assistant‖ autism communication projects and ultrasound simulation training tool.
Hector M. Garcia, MS, is a VMASC senior project scientist. Areas of expertise include Visualization, Virtual Environments and Virtual Reality, integrating state of the art visualization systems with modeling and simulation applications. He has developed simulations for medical training such as the Virtual Operating Room, the Virtual Pathology Stethoscope and the Wound Debridement Simulator. He also holds patents for R&D efforts in Virtual Environments for use in the areas of Training, Education, and Scientific Visualization.
Catherine M. Banks, PhD, is Research Associate Professor at the Virginia Modeling, Analysis, and Simulation Center (VMASC) at Old Dominion University. She is currently working on the development of a medical immersive simulation training tool for a specific application and a simulation program to analyze the impact of the obesity epidemic on the medical community. Her research also includes modeling states and their varied histories of revolution and insurgency, political economy and state volatility, and human behavior/ human modeling with applications in both the social sciences and the health sciences.
John Sokolowski, PhD, is the Executive Director of the Virginia Modeling, Analysis and Simulation Center and Associate Professor of Modeling, Simulation, and Visualization Engineering, both at Old Dominion University. His research interests include human behavior modeling, decision system modeling, multi-agent system simulation, and modeling and simulation representation of social systems. He has published four books on modeling and simulation and is the author of numerous journal articles and conference papers.
Note – this technology is Patent Pending
MODSIM World 2014
 2014 Paper No. nnnn Page 1 of 7

Developing an Ultrasonography Simulator Training Tool: From Platform to Interface to Graphics
William T. Richards, MS ; Hector M Garcia, MS ; John A. Sokolowski, PhD ; Catherine M. Banks, PhD Virginia Modeling, Analysis, and Simulation Center. Old Dominion University
Norfolk, Virginia USA
wxrichar@odu.edu, hgarcia@odu.edu, jsokolow@odu.edu, cmbanks@odu.edu
INTRODUCTION
Old Dominion University’s Virginia Modeling, Analysis, and Simulation Center (VMASC) research faculty, with direction from physicians at medical teaching hospitals, are developing an ultrasonography simulator training tool from the bottom-up: from integrating the hardware and software components to crafting the editing capability for uploading teaching modules and testing assessments. This R&D is significant as there is a solid endorsement for using modeling and simulation (M&S) for medical education and training—the sheer need for a larger body of health-care professionals who are educated in an effective manner leads that discussion. Specifically, medical teaching faculty expert in the use of ultrasonography have alerted the developer community (VMASC) that a tool meeting their requirements for training and assessment in ultrasonography does not exist in a form they prefer.
Ultrasonography (US) is an ultrasound-based diagnostic imaging technique used for visualizing subcutaneous body structures including tendons, muscles, joints, vessels and internal organs for possible pathology or lesions. As such, portable ultrasound devices are utilized across all sub-fields of medicine. Experts in the use of US and education in US recognize this point-of-care medicine is defining the future of patient-physician interaction with pathologies assessed upon examination. US is user-dependent; thus ensuring clinician capability and appropriate usage with US devices is necessary. To fully exploit the technology, medical practitioners must have sufficient pathology-specific training to facilitate cognitive and mechanical proficiency. According to experts in this field, the curriculum and training for US is lacking because it does not accommodate the dual nature of US expertise – cognitive and mechanical skills-sets (Levitov, 2009). Medical students today do not always recognize pathology when they see it, and/or they understand pathology with cognitive skills, but not with the ultrasound image they have captured. There are also cases whereby students are lacking the dexterity and mechanical skills needed for the capture of images. Most curriculums require cognitive examinations wherein the image is provided and the student must simply associate the name of the pathology with the supplied image. Technically, students are given instruction and hands- on training for image capture, but they do not always recognize the pathology they have retrieved via the captured ultrasound image due to the fact that they do not have the cognitive skill to do so or because the image is not well- retrieved or a combination of both these handicaps (Levitov, 2009). In the United States the standard of 20-30 most common pathologies must be obtained and recognized by the student. A gold standard of 150 procedures / images exists, but even then the student may be incompetent (Levitov, 2011). Moreover, current assessments are one-sided examinations of cognitive skills (e.g., students view a pre-supplied image and associate the pathology with the image).
As such, a simulation training tool for ultrasonography is needed to provide additional and incisive exercises to medical students, residents, fellows, and clinicians whose practice involves comprehensive and problem-specific physical examination of the patient. This training can benefit students and clinical practitioners by teaching them to: 1) capture images (drawn from a comprehensive digital library of simulated 3D pathologies, 2) develop of a care plan, and 3) debrief to communicate clinical skill. In short, this tool will augment current standards of ultrasonography education through immersive simulation training that includes an educator-selected library of 3D pathological cases which the students must capture, recognize, and discuss as part integrating advanced ultrasound principles for patient care.
Note – this technology is Patent Pending
MODSIM World 2014
 2014 Paper No. nnnn Page 2 of 7

METHODS
Current ultrasound technology engages a general-purpose sonographic machine for most imaging purposes. All ultrasound procedures are done using a US sensor (aka transducer) on the surface of the body. The sensor contains multiple acoustic transducers to send pulses of sound into a material. Whenever a sound wave encounters a material with a different density (acoustical impedance), part of the sound wave is reflected back to the sensor and is detected as an echo. The time it takes for the echo to travel back to the sensor is measured and used to calculate the depth of the tissue interface causing an echo which results in an image. Unquestionably, US technology is very sophisticated and well-developed. Our objective is to take the existing US technology and reconfigure it into an ultrasonography simulator training tool. As such, our simulator must: 1) provide the images in real-time; 2) ensure handling training so that the students can manipulate the sensor to capture images; 3) have a reasonable degree of technical difficulty associated with the training sensor for capturing images; 4) accommodate a digital library of simulated 3D pathologies. These specifications require a mixed-reality environment that obliges students to interrogate the patient (a mannequin or standardized patient) with an optimized hardware and software interface.
To ensure the goal of this effort (production of a real-time dynamic US simulator training tool with realistic effects) the development will include three key elements that will integrate with one another: 1) a graphical user interface (GUI); 2) the hardware interfaces that the student will physically manipulate (such as dials and probes); 3) the simulated 2D US real-time imagery which will be displayed based on the 3D pathology of the simulated patient and the position of the sensor.
Interface Design
The GUI will be a windows-based program allowing the student to start the program, select a patient case-study, and initialize the sensor. The GUI will read the data coming off the hardware dials, buttons, and sensors providing the student with the appropriate responses to their manipulation of the sensor and controls.
We have developed a working 3D model of a human heart and placed it in a virtual space allowing the tool to function with either a mannequin or standardized-patient. The main program of the simulator will be GUI-based software allowing us to connect modular software components to it as needed. The GUI will communicate with the hardware devices attached to it and track the location and orientation of the sensor and the patient.
Hardware Design – Platform
Once the student has selected a patient, he or she will need to select the correct sensor to be used based on the patient’s pathology. The student will have to manipulate the sensor into the correct position on the mannequin or standardized patient to see the generated images. If an incorrect sensor is used, the simulator will not show the appropriate image for making an accurate diagnosis. As some of the sensors are meant to be inserted into the patient’s body, the simulator will have to include a mannequin that can accept a sensor in the correct locations. In addition to the sensor, the student will have to manipulate some dials and buttons to alter the field of view and strength of the transducers as would be the case on an actual Ultrasound Scanner. These buttons and dials can be interfaced with the GUI using a standard off-the-shelf USB input/output (IO) board.
Figure 1. Kinect X Y Z tracking
MODSIM World 2014
 2014 Paper No. nnnn Page 3 of 7

Hardware Design – Sensor
Developing the sensor and tracking its movement is the most critical part of the simulator design, and it will require a 6DOF magnetic tracking gaming device to track the orientation of the sensor. In addition one Microsoft Kinect® will be used to provide visual tracking of the patient.
Technically, the accuracy of the sensor’s location and orientation with respect to the virtual model and the mannequin or standardized-patient is required to have a high level of fidelity in order for it to be effective. This means that the more accurately the sensor and the location of the mannequin or patient can be monitored, the higher fidelity the virtual image can potentially display. However, the accuracy of the sensor’s relative position is not the only factor in ensuring the validity of the technical aspects of this simulator. The virtual model must also show deformation of internal organs as the sensor is pressed up against the patient’s body (Gerovichev, 2004). This will be accomplished with the integration of custom hardware and the software platform.
Figure 2. Orientation of mannequin
Simulator Design
The real-world nature of this training tool is premised on using simulated 3D surface models of pathologies that occur in reality of practice, and then simulating those pathologies in a virtual environment to display the correct simulated Ultrasound image in real-time. To accomplish this we simulate the internal anatomy of the organs to be visualized via ultrasound. These simulated organs are represented as 3D anatomical models and placed virtually in the same location as the real organ would be. The use of a 3D model is important because this allows the student to retrieve continuous simulated ultrasound imagery of the working 3D organ as they move the sensor, significantly increasing the level of realism of the training experience.
The position and orientation of the sensor is obtained from a 6 DOF electromagnetic gaming controller and used to update the sensor location in our software. By updating the sensor position we are able to display a simulated ultrasound image that corresponds to the location of the training sensor. This simulated ultrasound view is updated in real-time and changes dynamically in response to the sensor location. The simulation is capable of representing the variety of ultrasound sensors, such as high-frequency linear array sensors or low-frequency curved array sensors. The positioning of the 3D anatomy is achieved automatically by using the hardware previously described. The simulator is capable of detecting the mannequin or standardized patient used for the training and its dimensions. Using this information the software is able to position the 3D model of our simulated heart in an appropriate location, which then allows the student to use the simulated sensor as he or she would normally do on a live patient.
MODSIM World 2014
 2014 Paper No. nnnn Page 4 of 7

MODSIM World 2014
 Figure 3. 3D heart model
The simulator also provides a visual guided mode in which the student can be presented with visual cues right next to the simulated ultrasound image. This method guides the students to locating and positioning the ultrasound sensor in the appropriate region of the human anatomy and various structures. The visualization of the simulated ultrasonography training system can work on both mannequins and standardized-patients in providing a simulated view of the ultrasound.
Validation – Technical and Empirical
This will be conducted by M&S engineers via a side-by-side comparison of our simulator tool to the real-world ultrasonography equipment with a view to three functions: 1) determining that the sensor and transducers are registering the proper distance, size, and depth with measurable accuracy to 1/16th inch; 2) that the quality of the simulation matches images that would be produced by an actual ultrasound device; 3) that the latency of positional data is insignificant relative to the motion of the operator’s hand and speed of image retrieval. Empirical validation will be done by medical subject matter experts who will beta test the three primary functions through engaging the tool as would a student and an educator.
Figure 4. Position and orientation data of heart model
RESULTS
This tool adheres to the precision of ultrasound technology in a reconstructed form for teaching and training purposes. Most ultrasonography simulators use pre-recorded sonograph images which are displayed when the sensor is displayed in various positions. This approach is deficient in that the student is limited in sensor placement and number of sensor positions; thus the student’s manipulation skills are not fully honed. More recent
  2014 Paper No. nnnn Page 5 of 7

ultrasonography simulations (Sun and McKenzie, 2011; Matyal et al., 2011) use 3D dynamic models of the internal organs of the patient to generate the sonograph. This approach has the advantage of being able to provide an image no matter the angle or rotation of the ultrasound sensor, but the weakness of this 3D approach is its lack of fidelity; there is a lack of realism of the sonograph images especially the representation of surrounding tissue to the organ of interest and the incorporation of realistic ultrasound effects. These deficiencies limit the usefulness of these ultrasonography simulations as training tools.
Our proposed project will produce an ultrasonography simulation using the 3D dynamic model approach that includes realistic effects within the sonography, thus increasing its usefulness and commercial viability. Our prototype thus far shows that this training tool provides
 highly interactive, diagnostic training tool
 user-friendly simulation technology
 ultrasonography information-based
 (real) patient image-based, with images occurring in reality of practice
 image capture engaging different transducers and their varying capabilities
 reasonable degree of technical difficulty for handling experience
 the trainee with images in real-time via a simulated platform
 inconsistent and inaccurate image extraction as a teaching experience
 retrieved and actual patient outcome as realized in the case study image
 a training competency verification tool
Importantly, this tool is being developed with educator input from the conceptual design to final product validation. It will possess a dedicated teaching component that is extendable with additional anatomical imagery and teaching materials. There will be an instructor observation capability of student self-positioning when interrogating a patient so the instructor can assess student body language. Significantly, and as required by medical educators, this tool must be cost-effective. Competing companies are constrained to limited production due to the cost prohibitive-ness of their products. This tool uses off-the-shelf hardware to facilitate scalable delivery (can be used on pc) and as such training can be done in a self-guided format.
DISCUSSION
The development of an ultrasonography simulator training tool requires multi-disciplinary expertise from both user and developer as involved stakeholders. Of the subject matter experts integral to this effort are first, the medical educators, physicians who have made the case for student training opportunities with specific case studies to ensure US users are proficient in capturing, interpreting, and understanding the pathologies of ultrasound images. Their contribution to this effort is ongoing to ensure that the tool meet their educational requirements in the form of US mechanical and cognitive experiential learning. Upon completion of tool development, medical educators will craft their specific teaching modules and assessment examinations for upload to the tool.
The second sets of experts in this effort are the computer science and visualization engineers who worked closely to integrate the hardware - software components of the tool’s platform, devices, and imagery. Additionally, the computer software editing capability for data (anatomical graphics) upload and teaching modules will make this device an extendable, modifiable training tool.
This US Simulator Training Tool also focuses on advancing patient safety, this time by providing an effective means for US training. As such, the training tool addresses a significant economic challenge – the cost of health-care. Ultrasound is unquestionably a valued means of patient examination and its capability should be exploited to the fullest. Cost effective US training will ensure that happening. The medical community at-large is also concerned with future needs for trained health-care professionals with a projected demand for 52,000 additional primary care physicians by 2025 (Los Angeles Times, 2012). This US simulator training tool can no doubt play a role in meeting that demand.
2014 Paper No. nnnn Page 6 of 7
MODSIM World 2014

REFERENCES
Gerovichev, O. (2004). The effect of visual and haptic feedback on computer-assisted needle insertion. Computer Aided Surgery, 6(9):243-49.
Los Angeles Times (2012). 52,000 more primary care doctors needed by 2025. Retrieved November 22, 2012, from http://www.latimes.com/health/boostershots/la-heb-52000-additional-primary-care-doctors-needed-by-2025- researchers-say-20121113,0,6630455.story
Levitov, A., Apostolos, D., & Slonin, A. (2011). Bedside Ultrasonography in Clinical Medicine. New York: McGraw-Hill.
Levitov, A., Mayo, P., & Slonin, A. (2009). Critical Care Ultrasonography. New York: McGraw-Hill.
Matyal, R., Bose, R., Warraich, H., Shahul, S., Ratcliff, S., Panzica, P., & Mahmood, F. (2011). ―Transthoracic Echocardiographic Simulator: Normal and the Abnormal.‖ Journal of Cardiothoracic and Vascular Anesthesia 25(1) (February): 177-181.
Sun, B., McKenzie, F.D. (2011). ―Real-Time Sonography Simulation for Medical Training.‖ International Journal of Education and Information Technologies 5(3): 328-35.
FIGURE LEGENDS
Figure 1. Kinect X Y Z tracking
Figure 2. Orientation of mannequin
Figure 3. 3D heart model
Figure 4. Position and orientation data of heart model
2014 Paper No. nnnn Page 7 of 7
MODSIM World 2014
