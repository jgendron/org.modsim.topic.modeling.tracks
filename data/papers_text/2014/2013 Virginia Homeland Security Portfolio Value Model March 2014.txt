2013 Virginia Homeland Security Portfolio Value Model
Kaleen J. Lawsure and Barry C. Ezell, Virginia Modeling, Analysis and Simulation Center Suffolk, VA klawsure@odu.edu, bezell@odu.edu
ABSTRACT
The Homeland Security Portfolio Value Model was developed by Old Dominion University’s (ODU) Virginia Modeling, Analysis and Simulation Center (VMASC) under the direction and guidance of the Virginia Department of Emergency Management (VDEM) and the Office of Veterans Affairs and Homeland Security in 2012 and again in 2013. The model was developed to aid senior executive decision makers in funding allocations for the Virginia Homeland Security Grant Program (HSGP). This paper provides the background for the project, the decision making environment, and modeling objectives. Then the model development process is described in which researchers elicited from senior leadership the scoring criteria, weighting, and value functions to be used for project scoring. This is followed by a description of the database development and deployment used to capture data and administer the proposal scoring process. The paper then provides a summary of the scoring results as well as allocation decisions, conclusions, limitations and future work.
ABOUT THE AUTHORS
Kaleen Lawsure is a project scientist at the Virginia Modeling, Analysis and Simulation Center of Old Dominion University. She holds a Bachelors of Science degree in geography with a minor in environmental management, and certifications in Geographic Information Systems (GIS) and Spatial Analysis of Coastal Environments (SpACE). Ms. Lawsure provides GIS and analytic support for research conducted in the domains of Homeland Security and Emergency Management. Her most recent work has supported research on vulnerable population mapping for the Hampton Roads Region of Virginia in the event of a catastrophic hurricane, scenario development for a potential terrorist attack in the National Capital Region, and both state and regional support for proposal submission and grant allocation of DHS funds.
Dr. Barry Ezell is Chief Scientist at the Virginia Modeling, Analysis and Simulation Center. He is also the President of the Security Analysis and Risk Management Society. Barry has 25+ years of experience in military decision making, operations research, and risk analysis in the U.S. Department of Defense, U.S. Department of Homeland Security, and the Commonwealth of Virginia. Barry is best known for building risk and decision analysis models for critical infrastructure industrial control systems and terrorism weapons of mass destruction. Ongoing applied research and analytic work combines advanced concepts in adversary modeling and in developing risk models to inform decision making.

2013 Virginia Homeland Security Portfolio Value Model
Kaleen J. Lawsure and Barry C. Ezell, Virginia Modeling, Analysis and Simulation Center Suffolk, VA klawsure@odu.edu, bezell@odu.edu
BACKGROUND
The Department of Homeland Security (DHS) through the Federal Emergency Management Agency (FEMA) providesgrantallocationstoselectedareastofundcounterterrorismandemergencypreparednessprojects. Forthe state of Virginia these grant programs are administered through the Virginia Department of Emergency Management (VDEM). As part of the administrative process it is a requirement that VDEM submit an investment justification (IJ) to FEMA for all funded projects. Investment justifications require funded projects to be consistent with federal, state and local planning documents. This can be challenging because goals, objectives and priorities shift as new guidance is issued and, as projects are implemented and project manager’s work toward closing risk and capability gaps. Also, a proposal is only as effective as the proposal writer’s ability to communicate the necessity and value of the project, which may or may not be consistent with decision maker perception of necessity or value. Knowledge, perspectives, context, and access to information make grant allocation a complex sociotechnical challenge.
In order to address the challenges, VDEM required a more systematic and objective method by which to justify their decisions. While subjectivity can never be totally eliminated from this process, it can be mitigated by establishing a scoring methodology that can be used to rank each proposal within a portfolio relative to others based on senior leadership priorities.
Senior leadership engagement was critical to informing model parameters and ensuring that those parameters were set based on consensus by the group, in this case, the executive senior leadership committee. This required fully engaging senior leadership at every step of the process. Additionally, the model had to be kept as simple and straight forward as possible to allow for enough flexibility that modifications could be easily made as the decision making environment changed, as well as to support model usefulness beyond a single round of decision making.
MODEL DEVELOPMENT
The first step in the model development process required the establishment of project proposal scoring criteria consistent with senior leader guidance and federal and state priorities. These criteria included: necessity/efficacy of the project, viability of the project management plan, results evaluation, risk evaluation, and viability of the long term sustainment plan. The model is based on a multiple-objective decision analysis (MODA) framework, an approach recognized for situations where values, preferences and human judgment is present. In a MODA approach, the objectives are organized into a hierarchy of factors (for this application, threat and vulnerability factors) where the lowest-level objectives are quantified by measurable scoring criteria (Kirkwood, 1997). Our model only had one overall goal and five objectives, where each objective was evaluated with one criterion each.
MODA is used in decision analysis and risk analysis when problems have multiple objectives, often in conflict, that require quantifying explicit value tradeoffs. MODA integrates objective facts explicitly with value preference judgments. MODA models are well proven to help support policy decisions (Keefer et al., 2007). A MODA model is useful when the decision requires organizing and aggregating many variables in a clear, transparent and accountable way (Ezell, 2007).
To assess the value of a proposal, the following additive value model was used to combine all the criteria where the attribute measure, xm is the level of the mth attribute measure, vm(xm) is the value of the attribute value function at level xm, and wm is the weight associated with that attribute measure.

n
V(x)w v (x ) (1)
mmm m1
Equation 1. Additive Preference Model for Multiple Objective Decision Model
Table 1 shows a description of inputs requested of project managers addressing each of the established criteria. This information was collected via a web form shown in Figure 1. Over the course of two years, the senior executive leadership committee revised and improved upon the definition for each criterion as well as the weights for each.
Table 1. Results of Project Proposal Criteria Weighting and Criteria Input Description
   Criteria Name
       Weight
      Description
   Risk Evaluation
  w1
 Describe how this project addresses risk in terms of threat, vulnerability and consequence?
Threat: Describe the threat in the applicant region. Explain the proposal's nexus to terrorism, gangs, violent criminal activity; Example - FBI reports that a state sponsored hacker is attempting to break into computers controlling transportation systems.
Vulnerability: Describe the vulnerability that this proposal addresses; Example - Transportation control systems are susceptible to cyber-attack from external threat.
Consequence: Describe the consequences of not funding the project; Example - The region conducted a cyber-risk assessment and determined that an attack on one or more tunnel systems would cost the region $800 million in damage. In addition there would be significant dread from public not accustomed to this type of event.
      Necessity/Efficacy of the Project
     w2
   Necessity: Explain how this project will address risk, close gaps, etc.; Example - The purchase of proposed equipment and associated training prevents the threat from gaining access to the tunnel's control system. Efficacy: After this project is funded, what will be the new value of loss and probability of loss – how was the new value of loss and probability of loss calculated?
     Viability of the Project Management Plan
     w3
   Explain how the proposal will be managed; how will contracts be managed; how will accountability to timelines and grant rules be monitored and deficiencies corrected.
   Results Evaluation
       w4
      How will the project’s results be evaluated and who will evaluate them? Describe the overall results that the project is expected to accomplish both in qualitative and quantitative terms.
   Viability of Long Term Sustainment Plan
    w5
    How will any equipment, licenses, training and other features be maintained and upgraded past the life of the grant? Break down the requested amount by POETE elements. Estimate the sustainment cost from FY15 through FY18 (this estimate is for planning purposes only and should not be included in the amount being requested to fund the project).
  
Another important aspect of the process was the briefing process that VDEM undertook to educate potential grant submitters on the process and how to input data into the system shown in Figure 1.
Figure 1. Project Manager Web Form
 
The next step in the model development process required establishing value functions for each criterion. A seven point constructed proxy scale was used for scoring and the senior leadership committee assigned values to each (Ezell, 2007). Table 2 shows an example for the risk evaluation value function.
Table 2. Example Value Functions for Scoring Criteria
     VDEM HSGP Proposal Scoring Criteria Value Functions
        Risk Evaluation: How well does the organization submitting the project proposal evaluate the risk in terms of threat, vulnerability and consequence?
           x
       v(x)
    The answer is blank, non-responsive to the question. No nexus to terrorism.
      x1
      v(x1)
   The answer is poor in that the evaluation of risk is not clear from the answer. Weak linkage to terrorism.
    x2
    v(x2)
   The answer is acceptable in that the evaluation of risk can reasonably be discerned from the answer. However, the answer is completely subjective with no evidence used. (THIRA, intelligence reports, risk assessments).
  x3
 v(x3)
   The answer is good in that the evaluation of risk is clear from the answer. It references reports or authoritative documents to address TVC.
       x4
      v(x4)
   The answer is very good in that the evaluation of risk is very clear from the answer. Threat information, vulnerabilities, and consequences are explained with supporting references and clear linkage is established.
    x5
    v(x5)
   The answer is excellent in that the evaluation of risk is clear, direct and described to scenarios of concern to the locality, region and/or state. The capability gap is made explicit and it is clearly understood what the proposal will achieve in closing the gap from the risk. Clear linkage to terrorism; dual benefits.
  x6
 v(x6)
   The answer is exceptional addressing all above with specific details (death, economic impact, etc.) addressing known gaps, and risk from scenarios of concern with authoritative documentations. Strong linkage to terrorism.
       x7
      v(x7)
     DATABASE DEVELOPMENT & DEPLOYMENT
Once the scoring criteria and value functions were established, the next steps involved data capturing. In order to facilitate data entry and analysis, a web enabled database was developed using FileMaker Pro®. This platform enabled development of multiple layouts and views of a single database providing security and an easily accessible interface for submitting, organizing and evaluating projects. Project managers were able to complete and submit project proposal forms online. Once all proposals had been submitted subject matter experts (SME’s), in one of nine investment areas,1 were able to review the projects online, provide comments and make funding recommendations. Project managers were then given the opportunity to present their project proposals to the senior leadership committee. The database enabled VDEM administrators to easily schedule and organize presentations. Multiple instances of the database were distributed to VDEM administrators and senior leadership committee members to record comments, score projects, and make funding decisions. Once the data was captured and all instances of the database merged into one dataset the database was exported to MODA model for assessment.
RESULTS
Grant administrators were presented with a number of ways of summarizing and visualizing projects. Based on VDEM requests projects were summarized based on aggregated totals of requested versus approved amounts in terms of investment area and VDEM region. Figure 2 and Figure 3 illustrate examples of projects funded by investment area and by region respectively.
1 The 9 investment areas included community preparedness, law enforcement, critical infrastructure, mass care, planning, CBRNE, information sharing fusion, communications, and ICS NIMS SHEEP.
 
The total requested amount of funding was approximately $8.9 million, of which approximately $5.3 million was allocated. Investment areas ICS/NIMS HSEEP, information sharing, and mass care received 100% of funding requested. Law enforcement received 94% percent of requested funding. Law enforcement projects unfunded were either recommended to other funding or were not allowable under the grant guidelines. Planning projects were allocated approximately 50% of requested funding. All unfunded planning projects were recommended to alternate funding, with the exception of one project that was denied funding because it did not contribute to sustainment and was not regional in nature. Give the available funds, projects that did not in any way promote sustainment were not funded. Critical infrastructure projects were allocated 62% of requested funding, the results of which were predominantly due to the rejection of projects that were for purchase of new equipment, rather than sustainment of current capabilities. Community preparedness projects were allocated 82% of requested funding, one of which was recommended to other funding and two that were denied funding because they did not contribute to sustainment. CBRNE projects were allocated 74% of requested funding, projects were not funded because they were either not regional in nature or were not allowable under grant guidelines. Communications projects were allocated 27% of requested funding. Communications projects were unfunded for three primary reasons, 1) the capability was being addressed and funded under another project, 2) alternative approaches such as integration with state, regional, or another localities communication system was more economical, or 3) the approach or technology being proposed was considered to be, or soon to be, outdated.
Figure 2. Allocations by Investment Area
 
Funding decisions were not made based on region even though proposals were required to be regional in nature. Of the proposals that were funded, some were funded at a reduced amount, with the exception of Culpepper which received 100% of funding requested. Tidewater had the greatest disparity between requested versus approved funding. The total requested amount for Tidewater amounted to 75% of available funding. However, the majority of projects, 19 of 26, received the requested amount while the remaining projects were funded at reduced amounts. One communications project was significantly reduced by approximately $2 million. Approved amounts in general, regardless of region, reflect reduced amounts for sustaining current capabilities.
Figure 3. Allocations by VDEM Region
In addition to these summaries each of the projects were analyzed based on a cumulative cost benefit analysis of project cost to criteria score. The analysis was presented as a graph (Figure 4), allowing decision makers to visualize how the projects scored. Each point on a graph represents a single project. Figure 4 highlights funded projects that had a higher cost to benefit relative to others in the portfolio. Of the five projects highlighted in Figure 4, one of the projects was necessary funding for the continued maintenance of the state’s Ready Virginia citizen preparedness website. One was a relatively low cost low score project recommended for a small locality in need of training and exercising the jurisdictions emergency preparedness plan. One was funded through alternate funding. One was funded at a reduced cost as it had already received partial funding approval under another grant. The final project was funded as highly recommended by SME’s, but was not scored by the senior leadership.
 
 CONCLUSIONS
Figure 4. Cumulative Cost Benefit of Funded Projects
The model development process enabled senior leadership to make decisions consistent with federal requirements, and the needs and values of the state and local emergency management community. The modeled results were clearly not the final decision. This was the starting point for discussion with the senior leadership committee. In some cases, proposals were funded due to factors beyond the consideration of the model. The model itself served as a tool for informing the process and the investment justifications. In some cases, the analysis of the data captured allowed VDEM administrators to easily identify projects in which funding decisions may not have been consistent with their objectives, enabling them to reconsider a project proposal and the justification for a decision. The web enabled database allowed participants, at every level and step of the process, to easily access the necessary forms and information. Capturing all project proposal details, from submission to final funding decision, in a common database reduced potential data entry mistakes as well as lost proposals and supporting documents traditionally communicated via email. A better organized project portfolio, customized data summaries, and project scoring analysis provided the tools necessary for a successful grant administration process.
Limitations & Future Work
There were some limitations to the database web publishing capabilities. The FileMaker Pro Server 12® and FileMaker Pro Advanced 12®, while a powerful database management tool, had limited web publishing capabilities. There was no page refresh for different sized computer monitors requiring design considerations to be made for the different sized user computers. The Instant Web Publishing (IWP) feature did not accommodate printing by any means other than directly from the web browser. This meant that if project managers wanted to print their proposal after submission it had to be done at the time of submission as they were not permitted to return to the proposal afterwards. Printable documents could be requested, but this was strictly controlled by VMASC personnel. The tradeoff for accepting this limitation was time and cost. Another limitation was the inability to upload supporting documents to the web submission form. While this feature is simple in the database application, IWP does not support document upload. This challenge was overcome by establishing a grant email for supporting document submission. This email account was administered by VMASC. Then supporting documents were uploaded to the software application of the database and transferred to VDEM staff via email once all of the proposals were submitted. This was the only instance in which email was used, but document loss was mitigated by VMASC management and the visual confirmation within the VDEM administrative form that the documents were uploaded to the database despite the inability to upload or download from the web interface. Another limitation was

automated reporting. Improvement to this capability could reduce or eliminate the need to export the data for summary and analysis.
Despite some limitations, the senior leadership committee and VDEM program administrators were satisfied with the model development process, the results yielded by the data summary, and the insights provided by the criteria scoring analysis. That is because the technology needed to only be good enough to a certain point. Developing multiple objective models, eliciting values and preferences, facilitation and interaction with senior executives was the most important aspect of the project. The model provided VDEM with a more organized and efficient method for grant management, and the continued collaboration between VMASC and VDEM will ensure efforts are made to further improve this process for future grant funding decision cycles.
REFERENCES
Ezell, B.C. (2007). Infrastructure Vulnerability Assessment Model (I-VAM), Risk Anlaysis, 27 (3), 571-583. Keefer, D., C. W. Kirkwood, and J. L. Corner (2007). Perspective on Decision Analysis Applications in W. Edwards, R. Miles, & D. von Winterfeldt, eds. Advances in Decision Analysis, Cambridge, UK: Cambridge
University Press.
Kirkwood, C. W., (1997). Strategic Decision Making: Multiobjective Decision Analysis with Spreadsheets,
Belmont, California: Duxbury Press.
