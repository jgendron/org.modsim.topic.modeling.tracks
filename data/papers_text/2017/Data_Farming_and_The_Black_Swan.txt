Data Farming and The Black Swan
Gary Edward Horne Blue Canopy Group Reston, Virginia ghorne@bluecanopy.com
ABSTRACT
Data Farming is a methodology that combines simulation modeling, rapid scenario generation, high performance computing, experimental design, analysis and visualization, and collaborative processes. Data farming is a quantified approach that examines questions in large possibility spaces and evaluates whole landscapes of outcomes to draw insights from outcome distributions and outliers. Data farming has been developed and utilized in many contexts to include a community of interest that has met to implement the methodology in workshops throughout the world. The group recently met for a week in Finland at the 31st workshop on data farming. At this workshop, model development continued through full immersion into the data farming process and many iterations of the data farming process were performed to gain insight into various “what-if?” questions.
A Black Swan event has three characteristics according to author Nassim Nicholas Taleb. First of all, the event is an outlier, i.e. it comes as a surprise. Secondly, the event has a major impact. And finally, the event can be explained after it occurs as if it could have been expected. Because data farming provides the capability of executing enough experiments so that outliers might be captured and examined for insights, it is particularly well suited for analysis of black-swan-type events. This paper describes data farming and a current application. Then it illustrates both successful and potential applications of data farming in the context of questions inherent in military decision-making involving some black-swan-type events.
ABOUT THE AUTHOR
Gary Edward Horne is a Research Scientist at Blue Canopy Group with a doctorate in Operations Research from The George Washington University. During his career in defense analysis, he has led data farming efforts examining questions in areas such as humanitarian assistance, convoy protection, and anti-terrorist response. He chaired the NATO Modeling and Simulation Task Group MSG-088, "Data Farming Support to NATO” that completed documentation of the data farming process and won a NATO Scientific Achievement Award. He continues work with NATO as co-chair of the follow-on task group “Developing Actionable Data Farming Decision Support for NATO” and, in particular, he is focusing on cyber questions using data farming. He has led the Data Farming Community through the 31 International Workshops that have taken place to date and is currently planning the 32nd Workshop.
2017 Data Farming and The Black Swan Page 1 of 10
Horne 2017

INTRODUCTION
Data Farming and The Black Swan
Gary Edward Horne Blue Canopy Group Reston, Virginia ghorne@bluecanopy.com
Data Farming is a quantified approach that examines questions in large possibility spaces using modeling and simulation. It evaluates whole landscapes of outcomes to draw insights from outcome distributions and outliers. This evaluation is made possible by “growing” massive amounts of data through the execution of many simulation runs. The name Data Farming was initially coined in 1997 (Horne 1997). Since that time the data farming community has grown to include people from over a dozen nations. Data farming continues to evolve from initial work in a United States Marine Corps effort called Project Albert (Hoffman and Horne 1998) to work including that done at data farming workshops, most recently Workshop 31 held in October 2016 in Valkeakoski, Finland (www.datafarming.org). The Scythe is the publication of the International Data Farming Community that contains proceedings of workshops that have been held over the years (i.e. Meyer and Horne 2014, 2015, etc.).
Data farming normally uses simulation in a collaborative and iterative team environment (Horne and Meyer 2004) that has been used primarily in defence applications (Horne and Meyer 2010). This process ideally has input and participation by subject matter experts, modellers, analysts, and decision-makers. Data farming is a process that has been developed to support decision-makers by answering questions that are not currently addressed. Data farming uses an inter-disciplinary approach that includes modelling and simulation, high performance computing, and statistical analysis to examine questions of interest with large number of alternatives. Data farming allows for the examination of uncertain events with numerous possible outcomes and provides the capability of executing enough experiments so that both overall and unexpected results may be captured and examined for insights.
In 2010, the NATO Research and Technology Organization started the Modeling and Simulation Task Group “Data Farming in Support of NATO” to assess and document the data farming methodology to be used for decision support. This group was called MSG-088 and this paper includes a summary of the six realms of data farming as outlined during the course of MSG-088 (Horne et al. 2014). Upon completion of MSG-088, a follow-on task group called “Developing Actionable Data Farming Decision Support” was initiated by NATO and was designated MSG-124. This task group is now approaching the completion of work in selected application areas important to NATO, one of which is cyber defense. This work is focused on iterative exploration of “what-if?” questions to reveal the landscape of possibilities inherent in the scenarios and enable the study of any outliers that are discovered.
The strength of data farming is the capability to examine large numbers of possibilities and thus has a natural connection with the Black Swan idea (Taleb 2007). A Black Swan event has three characteristics according to Nassim Nicholas Taleb. First of all, the event is an outlier, i.e. it comes as a surprise. Secondly, the event has a major impact. And finally, the event can be explained after it occurs as if it could have been expected. Because data farming provides the capability of executing enough experiments so that outliers might be captured and examined for insights, it is particularly well suited for analysis of black-swan-type events. This paper describes data farming and a current application. Then it illustrates successful and mentions potential applications of data farming in the context of questions inherent in military decision-making involving scenarios that exhibit outcomes characteristic of Black Swans.
2017 Data Farming and The Black Swan Page 2 of 10
Horne 2017

DATA FARMING
Data farming uses an iterative approach that is illustrated by the loop of loops in Figure 1 (www.datafarming.org). The first realm, rapid prototyping, works with the second realm, model development, iteratively in an experiment definition loop. A rapidly prototyped model provides a starting point in examining the initial questions and the model development regimen supports the model implementation, defining the resolution, scope, and data requirements. The third realm, design of experiments, enables the execution of a broad input factor space while keeping the computational requirements within feasible limits. High performance computing, realm four, allows for the execution of the many simulation runs that is both a necessity and a major advantage of data farming. The fifth realm, analysis and visualization, involves techniques and tools for examining the large output of data resulting from the data farming experiment. The final realm, collaborative processes, underlies the entire data farming process and these processes will be described in detail in this section. These realms are described in detail in Horne et al. 2014, but will be summarized below.
Figure 1: Data Farming Loop of Loops
Rapid Scenario Prototyping
The model development and the rapid prototyping realms of data farming together make up the experiment definition loop in Figure 1. As such, they work hand-in-hand with each other and we could choose either realm to begin our detailed description of data farming. Thus the rapid scenario prototyping process is a good place to start our discussion, although starting with model development realm would also be appropriate.
As with the data farming process in general, the rapid scenario prototyping should always be within the context of the questions to be answered. These questions have to be prepared in such a way that simulation can help to find answers and to get insights. The most important step here is to define measurements to be collected by means of simulation together with required input and output data for the simulation. In most cases this step already requires some rough ideas about the scenario settings. Thus, this realm simply represents the initial formation of the basics of a scenario to be simulated.
Horne 2017
 2017 Data Farming and The Black Swan Page 3 of 10

Model Development
As stated in the previous subsection, the model development realm works hand-in-hand with the rapid scenario prototyping realm in the experiment definition loop on the left side of Figure 1. The fundamental output of this loop is a scenario instantiated in a working simulation model that captures the essence of a question and that can be sent to the multi-run execution loop of the data farming process. Of course, more insight into the question, refinement of the question, and/or deeper examination of the question may be enabled later through a return to the experiment definition loop later in the process.
When developing models, both modeling and subject matter experts should be present. Rapid scenario prototyping provides model requirements for model development. For example, it is important to do one thing well, such as creating aggregated models that combine simple models instead of building single monolithic models, whenever possible. The more independent models are from each other, the better the potential results. Thus, one needs to encourage modularization and clear separation of different models, including development practices for using models of different aggregation level and scope. Other important characteristics of models as they are developed include reusability, interoperability, repeatability, and thorough documentation. And, finally, openness should be encouraged, including the sharing of source code when possible given other constraints.
Design of Experiments
Design of experiments is one of the three realms of data farming in the multi-run execution loop. Along with the realms of high performance computing and analysis and visualization, the realm of design of experiments allow us to perform multiple runs to gain simulation results over a wide landscape of possibilities. Simulation models have many inputs or parameters (factors) that can be changed to explore alternatives. A designed experiment is a carefully chosen set of combinations of these inputs, called design points, at which the simulation model will be run. Design of experiments provides smarter ways of setting up the experiment that facilitate follow-on analysis and visualization of results in a reasonable amount of time.
Changing the factors in a brute force way, by looking at all possible combinations, is impractical or impossible, except for extremely simplistic simulations with only a handful of factors. Changing the factors all at once limits your insights. It will allow you to see whether or not this changes the responses, but you will not be able to tell why the changes occur. For example, if mission effectiveness improves when you equip a squad with better sensors and better weapons, you will not know whether it is the weapon or the sensor that has the most impact. Changing the factors one at a time also limits your insights. If the squad gets a very small improvement from a better weapon, a very small improvement from a better sensor, but a large improvement from both, you will not be able to identify this interaction (or synergistic effect) if the experimental design does not involve factors for both the weapon and the sensor.
High Performance Computing (HPC)
HPC consists of both hardware and software resources. HPC systems can be configured as a single supercomputer with thousands of processors, as a network of clustered computers, or even as a single powerful desktop computer with multi-core processors. The hardware on these systems includes such things as processors, memory, networking hardware, and disk storage. HPC software includes, among other things: the operating system; underlying or supporting software which provide the environment to execute the model; and the data farming software, which enables running instances of the model across the HPC system compute units. By generating and managing each of the model runs over a set of design points or input sets, the data farming software provides the infrastructure “glue” that “sticks together” the model, its set of inputs, the design, and the HPC resources.
The main purpose of HPC in the context of data farming is to provide the means to execute a data farming experiment. Other purposes of HPC are for use in analysis and visualization of the output and for generating designs used in future data farming experiments. Given the large number of model runs made in a typical data farming experiment, HPC facilitates conducting the experiment in a timely manner as well as supporting the storage and analysis of huge volumes of output.
2017 Data Farming and The Black Swan Page 4 of 10
Horne 2017

Analysis and Visualization
Analysis in the data farming context is the process of examining data that is produced by data farming processes using statistical, summarization and presentation techniques to highlight useful information, extract conclusions, and support decision-making. Visualisation is a collection of graphical and visual analysis techniques used to optimize and speed the process of exploring data, conveying understanding, and presenting in data farming processes. Much of the current usage of analysis and visualization in the data farming process has been the analytic examination of multiple replicate and excursion model output.
In order to exploit the potentially huge data output from the high performance computing execution of the design of experiments, highly effective analysis techniques must be employed. Statistical analysis and visualisation can be used to discern whether data may has useful meaningful value and aid in the translation of data into information that is useful in making progress in understanding possible answers to the questions at hand. The ability to use multiple techniques provides the ability to explore, investigate, and answer the questions posed. Every technique has strengths and limitations, therefore, especially for high-dimensional datasets, use of a family of techniques is preferable to use of a single technique. As stated earlier, data farming gives us the ability to map the landscape of possibilities and in the process discover outliers. These outliers should always be considered and only be eliminated for appropriate reasons and can be investigated as a separate cohort of the data using various analysis and visualisation techniques.
Collaboration
The spirit of collaboration is the key tenet of data farming. It underlies the loop of loops in Figure 1 and holds within it much of the power of data farming. Throughout the development of data farming and the formation of the data farming community, people have openly shared experiences and expertise. One focus for collaborative efforts has been and continues to be the international workshops. The first international workshop took place in 1999 at the Maui High Performance Computing Center. The first four workshops were methodology driven, dealing with complex adaptive systems modeling and agent based representation, with statistical experiment design and experiment evaluation. The subsequent workshops were and continue to be application driven and contributions to the overall advancement of data farming takes place in the development of simulation models, scenarios within the models, and computer clusters to run the models audacious numbers of times.
The real work is in making progress on important questions and the real secret is the combination of military subject matter experts and highly knowledgeable and multi-disciplinary scientists. This special mix of personnel has been the hallmark of the international workshops and this mix has promoted much networking opportunity. It has been a dynamic combination to have data farming work teams headed up by a person who really knows and cares about the question (e.g. a military officer who knows that the answers may have an impact on both mission success and lowering casualties) and supported by men and women with technical prowess who can leverage the tools available.
MSG-088 documented the following aspects of the collaborative processes in data farming: defining the characteristics and dimensions of collaboration in data farming, collaboration within and between the realms in data farming, collaboration of the people, collaboration of the data farming results, application of collaboration tools. This information can be found in the full report as well as information on the current status of data farming in the attending nations and ideas about the future development of data farming (Horne et al. 2014).
Data Farming Example: Recent Cyber Work
The Cyber Team of MSG-124 has been using data farming techniques to explore solutions to improve NATO's resilience to cyber-attacks. The scenarios considered so far have spanned the threat spectrum, ranging from lone hackers to cyber espionage organizations. The team is utilizing a NetLogo model developed by the team and a screen shot of the model is shown in Figure 2. The analyses have focused on exploring the value of various network topologies and organizations, firewall policies and intrusion detection systems.
The overall goal of the team is to leverage the current research, develop a suitable simulation, and explore possible scenarios through data farming that could facilitate the understanding of aspects of cyber defense important to NATO. The group has defined questions within the cyber defense area in conjunction with cyber defense experts of
2017 Data Farming and The Black Swan Page 5 of 10
Horne 2017

NATO and the participating nations, provided modeling and simulation support for various cyber defense questions, and performed analysis and iterative exploration of what-if? questions to reveal the landscape of possibilities inherent in the scenarios and enable the study of any outliers that are discovered.
Data farming techniques have proven to be useful thus far in MSG-124 efforts as evidenced by the accomplishment of the three tasks above as well as making progress toward the overall goal. Documentation of the work to date can be found in recent editions of the Scythe (www.datafarming.org). Complete documentation will be found in the forthcoming final report of MSG-124.
Figure 2. Screen Capture of the NetLogo Cyber Model.
THE BLACK SWAN AND EXPLORATION OF QUESTIONS USING DATA FARMING
Data farming, well before the publication of Taleb’s book in 2007, has been applied to explore scenarios with black- swan-type event characteristics in that a particular result was a surprise, had a significant impact, and could be explained retrospectively. Three examples follow and the sub-section headings even include the question regarding whether particular results, characteristics, or tactics can be considered a Black Swan. This question is certainly valuable to consider and may allow researchers to better examine scenarios, but the fundamental question regarding each example is not necessarily the presence of Black Swans. It is: can we improve our chance of succeeding through examining these scenarios, finding these surprises, and acting upon them?
One in a Million: Was the Battle of Midway Outcome a Black Swan?
The Battle of Midway in June 1942 resulted in a victory for US Naval forces over Japan. Over 3,000 Japanese died and they lost many ships including 4 carriers. The U.S. lost the carrier Yorktown and a destroyer with a total of about 300 Americans killed. The battle of Midway is widely considered a turning point in World War II. But the battle remains a wonder and cause for extreme reflection for many, because it could have turned out differently. In fact, by all accounts should have turned out differently. One book actually is appropriately titled Miracle at Midway and describes the battle as the greatest American victory of the Pacific war and how easily it could have been a devastating defeat (Prange, 1982).
The Battle of Midway was recreated in an agent-based model called Pythagoras (see screen shot in Figure 3) and the parameters were tuned so that the result mimicked the actual historical accounts. When the values of these parameters were changed the results were different. For example, the question was asked: what if the Japanese had
Horne 2017
 2017 Data Farming and The Black Swan Page 6 of 10

sent bomber aircraft loaded with original bombs to attack the US carriers? The data farming results from many iterations of the model showed that Japan still loses 4 carriers, but the US loses 1-2 carriers. Also modeled was the question: what if the Japanese had used fighter aircraft as escorts to the bombers? In this case Japan again still loses 4 carriers, but the US loses 2-3 carriers. Other alternative scenarios showed even more of a devastating loss for the US forces.
Figure 3. Screen Capture of the Battle of Midway as Modeled in Pythagoras.
In any of the what-if? scenarios deviating from the base case of the historical facts, the outcome of the data farming was consistently a worse result for the US. Because Japan had 7 more carriers in the Pacific and the US had only 3 carriers, the strategic result of any of these what-if? scenarios likely would have been dramatically different, at a minimum delaying the US counter-offensive in the Pacific and most likely changing the future sequence of events to the extreme detriment of the US war effort.
It appears that the outcome of the Battle of Midway was indeed a Black Swan in that it fits all three of Taleb’s criteria. First of all, the event was an outlier and it certainly came as a “one in a million” surprise. Secondly, the event had a major impact, plausibly significantly altering world history. And finally, the result is explained after it occurs through the historical documentation and the logic associated with each sequential activity during the battle.
The outcome of The Battle of Midway was only made possible by the improbable confluence and timing of events, a “one in a million” outcome. Data farming allows the examination of the many possibilities that could have happened if changes were made to some of the actual parameters of the battlespace and the data farming effort brings support to the conclusion of historians that the result was indeed something close to a miracle. It is difficult to ascertain, however, how the exploration of the Battle of Midway using data farming or other analysis methods could provide any additional lessons to be useful in future combat or even could have informed commanders to make better choices if available at the time.
One in Six: Was there a Black Swan in Gunslinger Characteristics?
A US Army advanced concept technology program a decade ago was designed to detect incoming gunfire using thermal sensors. Gunslinger was the name give to the effort to integrate this detection capability with an existing stable weapon mount in order to return fire. A data farming effort took place at the time to explore characteristics of Gunslinger. The six characteristics explored were (in alphabetical order) accuracy, amount of ammo, area of effect, rate of fire, reaction time, and survivability. In principle, more funding could be put into development of the characteristics that proved more valuable.
Horne 2017
 2017 Data Farming and The Black Swan Page 7 of 10

A simple convoy scenario was developed in the Map Aware Non-uniform Automata (MANA) agent-based simulation model, where a red enemy ambushes a convoy of blue vehicles. First, the model was run over 20,000 times with the convoy without Gunslinger. Then the model was run with the convoy with Gunslinger for a total of over 5 million runs to understand the value of each of the six characteristics. Figure 4 shows screen shots of one simulation of the scenario at the start of the run and during the ambush.
Figure 4. Screen Captures of the Gunslinger Convoy Scenario at the Start and during the Ambush
The data farming analysis showed that one of these six characteristics was clearly the most important and when the model, analysis, and result was initially presented to a group of military experts, the reaction was that it confirmed their intuition. However, the study was then presented to a similar group of experts without revealing the answer up front. After the scenario was explained and demonstrated, the experts were asked what they thought would be the most important characteristic. Their answers were evenly distributed over the six characteristics studied and cogent reasons for each choice were given based on military experience. So the key characteristic of Gunslinger was indeed a surprise (to notionally all but 1 out about six people), but after the answer was given, all of the experts could fit their thinking retrospectively into the actual result and thought it was quite reasonable. (For the record, the answer was survivability. The longer the Gunslinger weapon survived, the more the other weapons in the convoy could follow the lead of the Gunslinger, also focusing their fire destructively upon the enemy.)
It appears that the Gunslinger survivability characteristic could be considered a Black Swan in that the characteristic had a major impact, significantly altering the protection of convoys if real results followed the model output. Also, the result was easily explained and accepted by experts after it was revealed. But in this example, before it was revealed, it was a surprise to all but about 1 of six experts. This fraction may be too large to fit into the strict definition of a Black Swan, but the data farming analysis certainly allowed for improving the chance of succeeding through examining scenarios, finding surprises, and acting upon them.
One in a Hundred: Was there a Black Swan in Possible Hunter Warrior Tactics?
During the early stages of the development of data farming, a United States Marine Corps exercise/experiment called Hunter Warrior took place at Twentynine Palms, California to test the veracity of small hunter teams (the good guys, i.e. blue force) against a large enemy (red) mechanized force. The idea was that if these teams could locate the enemy from assorted vantage points they could call in gunfire and airpower to destroy them.
Before the exercise took place a small team of scientists and subject matter experts modeled a small portion of the exercise using an agent-based model called Irreducible Semi-Autonomous Adaptive Combat (ISAAC). In this portion of the exercise, blue was trying to prevent red from reaching a notional port where they could then destroy a notional oil facility essentially upon contact. Thus, red need only have one of its vehicles reach the goal and they would “win” while blue needed to stop all of the red forces. A scenario to represent what was planned was set up and Figure 5 shows a screen shot of the scenario in ISAAC. The blue and red forces were laid out according to the
Horne 2017
  2017 Data Farming and The Black Swan Page 8 of 10

exercise directive, the parameters were carefully chosen using what were considered reasonable values, and the model was run. In a matter of seconds the result from the first test run was known and the blue team had lost. The test was repeated, using the same parameters but a different seed value. The blue side lost again. And after growing more data by repeating the process over and over again, the results were the same again and again. Blue kept losing.
Figure 5. Screen Capture during a Run of the Hunter Warrior Scenario
Of course, the parameters could have been changed to be more favorable to blue such as giving them an increased detection capability, more forces to call in, or a larger probability of hitting the enemy. But the parameters were set according to the best judgment of the team and they weren’t trying to “game” a favorable answer for the idea being tested. Thus, the data farming was performed by simply changing the initial seed value of the simulation and letting the stochastic nature of the model provide the output. There were output differences, but the end result was still that blue kept losing, except for about one out of 100 runs where blue actually was victorious.
So a blue victory in this scenario, while not highly improbable, was still a surprise and could be considered to be a black-swan-type of event in this respect with a one out of a hundred probability. Also, it was certainly important, at least to planners and to those that might be faced with this scenario. And finally, analysis of a group of the blue victories or outliers showed that there was an explanation behind the victories.
This explanation could be used to purposefully alter the action of the blue forces so that their chances of winning were not one in a hundred, but actually virtually certain. So, in this example, both understanding the landscape of possibilities and the instruction provided by outliers provides support in answering the ultimate question of “what should we do?” which is the ultimate purpose of the data farming. Simulation can provide possibilities of what might happen in the future, not to be confused with the capability of predicting the future. The data farmer would like to understand the possibilities for the future and use this understanding to try to best ascertain what should be done. Using the construct of The Black Swan can help us approach possible events with an eye toward possible surprises as long as we remain focused on the fundamental question inherent in possible scenarios: can we improve our chance of succeeding through examining these scenarios, finding these surprises, and acting upon them?
Future Imaginable Black Swan Scenarios
The examinations using data farming described above certainly proved valuable in the last two cases, although they may not be improbable enough to cleanly fit the strict definition of a Black Swan. And it should be noted that once a particular Black Swan becomes known, the definition itself becomes problematic. But certainly data farming provides the beginning of a path forward in examining many possibilities and discovering surprises.
Horne 2017
 2017 Data Farming and The Black Swan Page 9 of 10

The examples provided above where data farming was used are all in the past and other examples of what could be considered Black Swans could be the 9/11 events, the start of World War 1 due to the assassination of Franz Ferdinand, and the 1962 missile crisis. Like the Battle of Midway work, data farming and analysis of these events may be quite interesting and valuable in understanding the events, but it may or may not provide insight into what should be done in the future to improve the chance of success of our forces.
However, the work described above does imply that an interesting pursuit for future work might be to imagine, develop, and study through data farming some future black-swan-type scenarios such as the following.
1. Development of a pathogenic weapon
2. Nuclear World War 3
3. Breakup of the European Union
4. Secession of California
5. Boundless free energy through nuclear fusion/ignition
6. Mirrors as a videotape of past reflection
The Black Swans to be examined could be military in nature (e.g. numbers 1 or 2), political in nature (3 or 4), or scientific in nature (5 or 6). They could be wildly improbable (e.g. number 6), practically already here (1), or in between on the likelihood scale (4). They could be disastrous (2), positive (5), or again in between (3). In any case, a data farming effort considering cogent what-if? questions could provide insight into these potential Black Swans and imply actions to try to make the world a better place.
REFERENCES
[1] Horne, G. 1997. Data Farming: A Meta-Technique for Research in the 21st Century, briefing presented at the Naval War College. Newport, RI.
[2] Hoffman F. G., and Horne, G. E., Eds. 1998. Maneuver Warfare Science 1998. Quantico, Virginia: Marine Corps Combat Development Command.
[3] Data Farming, http://www.datafarming.org accessed on January 24, 2017.
[4] Meyer, T. and Horne, G., Eds. Scythe, the Proceedings and Bulletin of the International Data Farming
Community. Issue 16 – Workshop 28, Jefferson, Maryland, USA, October 2014.
[5] Meyer, T. and Horne, G., Eds. Scythe, the Proceedings and Bulletin of the International Data Farming
Community. Issue 17 – Workshop 29, Riihimaki, Finland, March 2015.
[6] Meyer, T. and Horne, G., Eds. Scythe, the Proceedings and Bulletin of the International Data Farming
Community. Issue 18 – Workshop 30, Catania, Italy, February 2016.
[7] Meyer, T. and Horne, G., Eds. Scythe, the Proceedings and Bulletin of the International Data Farming
Community. Issue 19 – Workshop 31, Valkeakoski, Finland, October 2016.
[8] Horne, G. and Meyer, T. 2004. Data Farming: Discovering Surprise. Proceedings of the 2004 Winter Simulation
Conference, Eds. R. Ingalls, M. D. Rossetti, J. S. Smith, and B. A. Peters, 171-180. Washington, DC.
[9] Horne, G. and Meyer, T. 2010. Data Farming and Defense Applications, MODSIM World Conference and Expo, Hampton Roads Convention Center, Hampton, VA, USA 13-15 October 2010.
[10] Horne, G. et al. (2014). MSG-088 Data Farming in Support of NATO, Final Report, NATO Science and Technology Office (STO).
[11] Taleb, N. (2007). The Black Swan: the Impact of the Highly Improbable. New York: Random House. [12] Prange, G., Goldstein, D., and Dillon, K. (1982). Miracle at Midway. New York: McGraw-Hill.
Horne 2017
  2017 Data Farming and The Black Swan Page 10 of 10
