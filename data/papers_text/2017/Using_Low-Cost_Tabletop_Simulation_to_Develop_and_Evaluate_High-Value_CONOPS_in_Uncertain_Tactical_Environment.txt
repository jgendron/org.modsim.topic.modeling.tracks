Rolling the Dice: Using Low-Cost Tabletop Simulation to Develop and Evaluate High-Value CONOPS in Uncertain Tactical Environments
Mike Erwin, Steve Dorton, Scott Tupper Sonalysts, Inc.
Waterford, CT hail@sonalysts.com
ABSTRACT
In lieu of more complex, expensive, and high-resolution simulations, a Low Resolution Tactical Simulator (LRTS) has been used to great effect across several rapid development/user-centered design events to visualize and wargame advanced concepts. Using inexpensive office supplies and a few hours of preparation, tactical and technological concepts that are generated during brainstorming sessions can be rapidly tested and refined by playing a turn-based board game. While the game directly supports simulating spatial and temporal dimensions of the tactical scenario (demonstrating when concepts are not viable), the true value of the LRTS is the framework it provides to enable highly detailed discussion of assumptions, goals, constraints, and other information relevant to concept execution. Additionally, the game board itself becomes an artifact that can be used to capture and present scenario results. In an order to address user perceptions, questionnaires were completed by a multi-disciplinary team of LRTS users (N = 22), which provided insights into group dynamics, mechanics of gameplay, and the utility of LRTS, as well as commentary on how to improve the LRTS experience. Results showed that users found LRTS promoted discussion and critical thinking, uncovered underlying assumptions, identified spatiotemporal issues with concepts, and supported determining the effectiveness of concepts. Participants also found LRTS gameplay to be engaging and fun, making it a viable means to facilitate high-speed, high-morale concept development. This paper will discuss the apparatus required and mechanics of LRTS gameplay, the benefits of using LRTS in rapid design processes, and the user perceptions of using LRTS.
ABOUT THE AUTHORS
Mike Erwin is an Analyst and wargaming expert at Sonalysts. His experience includes serving on board Submarines, developing training games for the Submarine Force, being a voice-over for a video of torpedo concepts that he helped develop, supporting Operational Level of War planning for Seventh Fleet, and just being an overall nice guy. His current focus includes improving his wargaming skills, as a Naval Reservist, professional Analyst, and as a hobbyist. When night falls, Mike finds he is always playing a game, whether it’s taking on the enviable task of Dungeon Master at his home/lair, putting a video game controller in his wife’s hands, or a form of patty-cake before wrangling his two adorable kids to sleep.
Steve Dorton is a Human Factors Engineer and the Director of the Human-Autonomy Interaction Laboratory (HAIL) at Sonalysts. He has led and supported a number of projects across the DoD, NASA, and the FAA. His current research interests include decision support, data visualization, text analysis, complexity theory, and modeling and simulation of human-machine systems. In addition to hobbies such as trail running and fishing, Steve enjoys playing D&D as a cunning half-elf rogue with Mike Erwin and friends.
Scott Tupper is a retired Submarine Officer and currently the lead Innovation and Design Thinking Analyst at Sonalysts. His past experience included being Executive Director of the Submarine Tactical Requirements Group and Modernization and Innovation Director at the Undersea Warfighting Development Center. His current focus is on expanding the Tactical Ideation Development (TIDE) workshops beyond DoD applications and into more diverse markets. An avid reader and golfer, Scott hopes one day to have the time to take his long-suffering wife on the Hawaiian honeymoon she deserves.
2017 Paper No. 22 Page 1 of 11
MODSIM World 2017

Rolling the Dice: Using Low-Cost Tabletop Simulation to Develop and Evaluate High-Value CONOPS in Uncertain Tactical Environments
Mike Erwin, Steve Dorton, Scott Tupper Sonalysts, Inc.
Waterford, CT hail@sonalysts.com
INTRODUCTION
A Low Resolution Tactical Simulator (LRTS) was developed for testing high risk, high reward tactical concepts for submarine operations to overcome challenges of a shortage of resources available to conduct in-water testing, and the high overhead costs and time constraints associated with the development and use of high fidelity tactical simulators. While not a replacement for in-water or validated high fidelity simulation testing, the LRTS wargaming concept has proven effective at helping to identify infeasible tactics and low-return concepts before incurring the much greater time and expense of writing code or using valuable assets. LRTS leverages the concept of targeted fidelity to provide an inexpensive and rapid capability to vet Concepts of Operations (CONOPS) and tactics without writing a single line of code in a simulator, while still providing accurate representations of ship, sensor, and weapon performance (Morabito, 2016).
Both the commercial world and the Department of Defense (DoD) have embraced innovation and design thinking methods, including an array of high-energy, high-tempo, and high-morale ideation workshops. These workshops rely heavily on wargaming not only to determine the effectiveness of concepts, but also to serve as a Knowledge Elicitation (KE) mechanism to glean insights from the diverse set of participants at the workshop. This paper will discuss the LRTS concept (apparatus and gameplay), the benefits of using LRTS in a rapid design-thinking process, and some initial results on user perceptions of using the LRTS tool.
Innovation and Design Thinking
Design Thinking is a deliberate, solution-based approach to thinking, involving processes, approaches, and the sensibilities of a designer. Design Thinking was popularized by the design firm IDEO, and was first applied primarily to the design of user interfaces or computer-based tools (Brown, 2009). The core tenets of Design Thinking are: A focus on user needs, an iterative development cycle (Figure 1), engagement with end users throughout development, rapid prototyping and testing of ideas.
MODSIM World 2017
 2017 Paper No. 22 Page 2 of 11
Figure 1. Model of Design Thinking Process with Wargaming at the Center.

Tactical Ideation Development Events (TIDEs)
Tactical Ideation Development Event (TIDE) Workshops have adapted the core tenets of design thinking to propose, test, and refine new tactical Concepts of Operations (CONOPS) under challenging tactical scenarios. TIDEs bring together a cross-functional mix of uniformed personnel, government civilians, and contractors and employ user- centered design thinking, brainstorming, prototyping and wargaming with the LRTS. TIDEs help to identify and prioritize new concepts, provide rapid feedback to innovators to support concept development, and build collaboration across diverse groups of stakeholders. While each TIDE is different and tailored to the current needs of the project (i.e. the level of granularity which the project or concept development has reached) and the Knowledge, Skills, and Abilities (KSAs) of the participants, the overall structure of the workshop is relatively constant. The typical TIDE is three days long. The schedule of events is designed to guide participants through iterative cycles of expansion and refinement of CONOPS. The following is a high-level overview of a generic TIDE schedule of events:
Day 1 consists of introductory warm-up exercises to build morale and rapport, a high-level “why are we here” overview and a presentation of background briefs to focus and scope the workshop, and to explicitly map out the goals of the workshop before any brainstorming or war-gaming exercises. Brainstorming exercises are used to open the aperture on new concepts or on improvements to existing concepts. Participants are then grouped and vote on their brainstormed topics that they believe are worthy of further refinement and development. The concepts that are most highly voted on are then assigned to smaller teams for deep dive sessions. The goal of these sessions is to produce a prototype concept that can be wargamed using the LRTS. The first day concludes with a sharing session where each team out-briefs their deep dive concept and receives feedback from all participants.
Day 2 focuses on wargaming and uses the LRTS to test and discuss the concepts that were developed on Day 1. Depending on the depth and detail of the concept being tested, Day 2 may consist of a single game scenario or of multiple scenarios. After each game scenario, each team out-briefs their game to the larger group of participants, specifically focusing on what worked, what did not work, and their recommendations for future concept refinement. This is typically accomplished by hanging the LRTS game board on the wall in front of the larger room, and walking the group through each turn of gameplay, pointing out significant events. Participants provide feedback to the presenting team regarding what they liked, what concerned them, what questions they had, and any suggestions or wishes they have.
Day 3 provides the participants with the opportunity to brainstorm and self-identify important concepts or changed premises identified during LRTS gameplay in Day 2, and perform an additional deep dive into the most critical and challenging areas of their concept and prototype. After the deep dive sessions they present their findings to the larger group for another round of feedback. The ultimate outputs of each TIDE are user-driven, tested, and refined tactical concepts. Additionally, concepts that have major or minor issues are prioritized and then entered into a backlog of concepts that can be developed further after the conclusion of the TIDE.
The Role of Simulation in Innovation
TIDE workshops leverage simulation and wargaming with LRTS to quickly and inexpensively visualize tactical concepts that are developed in brainstorming sessions. In addition to the low cost and required materials (discussed in Section 2.2), LRTS also enables concepts to be taken out of a conceptual “vacuum” (i.e. creating a concept without considering practical implications of employment) and tested in an ecologically-valid environment and facilitates KE for Research and Development (R&D) personnel.
A key advantage of applying LRTS when developing CONOPS is that it allows concepts to be tested in an operationally-relevant scenario. First and foremost, it rules out infeasible concepts that violate the laws of physics in order to achieve the intended effect. By using a spatially-consistent game board and requiring time-based turns, concepts that do not obey realistic time/speed/distance relationships are immediately identified. Additionally, LRTS scenarios enable getting beyond idealistic use cases and testing the resilience of concepts against the messiness and chaos of the real world. Data collected from in-water testing and operations are leveraged to add realism to a variety of simulation elements, such as the probability of detection or counter-detection based on relevant factors. Furthermore, the game umpire has a similar role to that of a Dungeon Master in Dungeons & Dragons® (D&D), where they can exercise their judgement to inject difficulty or chaos on-the-fly in order to better shape the scenario (Crawford, Perkins, & Wyatt, 2014). This immense flexibility personifies the LRTS mantra of “if you can draw it,
MODSIM World 2017
   2017 Paper No. 22 Page 3 of 11

you can explore it,” encouraging experimentation with chaotic ideas and yielding more robust and fully-understood tactics. It is important to note that all of this is achieved without writing a single line of code, and a typical game can be conducted in under 90 minutes.
The primary goal of using LRTS in TIDEs is not to play scenarios and win the game. Instead, it is to engender critical discussion that enables the R&D team to further refine the concept and develop it for fleet use. Using LRTS during TIDEs promotes discussion and critical thinking throughout the scenario, which enables uncovering underlying assumptions, identifying spatiotemporal issues, and ultimately determining the effectiveness of concepts. The use of a tactical situation under time-based gameplay limits, but does not prevent, the possibility of the discussion from falling into interesting, but less-relevant topics. Additionally, the gamification aspect of tactical simulation (i.e. applying game elements into an operations research effort) fosters an environment that is both engaging and fun, which results in increased participation and morale among the players. Because of the collaborative and participative nature of tactical simulation, participants are more invested in the process, and more likely to buy into and support the outputs of the discussion than if the results were derived from a drawn-out BOGSAT (Bunch of Guys/Gals Seated around a Table).
LOW RESOLUTION TACTICAL SIMULATOR (LRTS)
Background
The LRTS was initially developed by a group of submarine tactical analysts in response to the increasing price of conducting in-water tactical experimentation and concept development. The combination of increasing costs and decreasing availability of test assets not only restricted the number of exercises that could be performed, but also (as a consequence) limited the scope of what could be examined. In other words, the capital investment and time required to conduct an in-water study made it unacceptable to perform high risk experiments with a possibility of failure. The development of fully-validated high resolution simulations had similarly high costs, often requiring a multi-year effort to produce validated results. Thus, LRTS was created to enable experimentation of a wide range of high-risk, high- reward tactics at a low cost and with low time commitments. Only the most promising ideas would then be pushed forward to full at-sea experimentation.
The first use of LRTS focused on development of torpedo attack positioning tactics. Over a short period of time, the analysts were able to experiment with several proposed tactics and were able to, ultimately, down-select them to a small list of candidate tactics for in-water testing. LRTS was further leveraged for a single day event to address proposed improvements of countermeasures and other technologies.
To be effective, the LRTS had to faithfully model the characteristics of the environment that mattered to the question at-hand, while ignoring (or approximating) extraneous factors. For example, models of the torpedo performance were based on data collected from actual in-water torpedo firings, since they were highly relevant to the tactics being examined. Conversely, modelling of the acoustic environment was ignored (or roughly approximated) because it did not impact the time-distance focus of the experiment.
Required Apparatus
Aside from the advantages described in Section 1.3, an advantage of using LRTS over a higher-fidelity computer- based simulation is the exceptionally low cost of entry, and apparatus consisting of commonly available office products. Table 1 shows a breakdown of these required items and their costs. It should be noted that some of these supplies are relatively perishable (e.g. dry erase markers), several are reusable dozens of times (e.g. game board and transparency sheets), meaning that the cost per game is significantly lower than the total cost provided herein.
2017 Paper No. 22 Page 4 of 11
MODSIM World 2017

Table 1. Required Apparatus for Conducting LRTS Gameplay
MODSIM World 2017
   Item
   Purpose(s)
     Cost*
   35” x 24” Laminated Poster Board w/ Hex Pattern
     Game Board
       $31.99
    40” x 12’ Grafix Clear .007 Dura-Lar Transparency Sheet
 Distance Strips Speed Strips Sensor Geometries
  $34.90
   Permanent Markers (6 Pack)
     Template Creation
       $11.29
    Printable Transparency Film
 Compass Rose
  $16.99
   Meter Stick
   Straight Edge
     $12.89
   Dry Erase Markers (Box)
   Inputs/Display of Info.
     $10.00
   Gaming Dice
   Event Determination
     $10.05
   Game Rules
     Guide Gameplay
       -
    Data Recording Sheets (“Move” Sheets)
   Data Logging
    -
 Total Cost*
       $128.11
   * Costs were generated based on web searches conducted in January 2017 of popular online retailers and do not include tax or shipping.
The laminated poster board with the 16mm Hex pattern serves as the game board for the participants. The numbered hex pattern provides a reference for locations and calculations of distance in the simulated environment. The lamination allows for easy drawing and labeling of entities and actions by the players and the umpire with dry erase markers. When required, multiple hex boards can be used side-by-side or over-under the other to make the play space larger.
Since the game is designed to operate in distinct blocks
of time (usually a few minutes), speed strips are made of
Dura-Lar to show how far an entity moves in that time,
based on a certain speed, and given a particular board
scale (i.e. the distance of each hex). Templates are
generated for each anticipated speed to enable players to
see how far an entity would travel during the next turn,
depending on commanded speed. The Dura-Lar sheet is
used to cut out and create any templates that are
necessary to make the game move smoothly. The Dura-
Lar and permanent markers are also used to create other
templates such as detection geometries or geometric
areas (such as a cone or beam) where a sensor can
potentially detect another entity. The printable
transparency film allows for computer-generated
templates for the game to be printed out, which typically includes a compass rose (Figure 2) to determine bearings from one entity to another. The set of gaming dice are used to determine the outcome of events based on probabilities and rules for each event type included in the game rules.
 Figure 2. Compass Rose on Printable Transparency Film for Bearing Determination
Ruleset and Operation
In addition to the inexpensive hardware setup, another advantage of using LRTS is its simple ruleset and operation. Because the overarching goal of wargaming and LRTS in a TIDE environment it to facilitate topic- relevant KE, the research team usually employs two or three personnel to facilitate each game. This setup enables multiple personnel to concentrate on stimulating and documenting discussions, while a single person serves as the umpire and conducts
 Figure 3. Game Dice Showing a Roll of 11.
2017 Paper No. 22 Page 5 of 11

gameplay. As previously mentioned, the umpire serves a role that is analogous to the dungeon master in D&D®, controlling all aspects of gameplay not expressly controlled by the players.
Thus far, LRTS has been used to test different tactical concepts for weapons and sensor employment in naval scenarios, where the users control a submarine or surface ship and their payloads (i.e. weapons and sensors), and the umpire controls all hostile forces, neutral forces, and the environment (e.g. they can modify sea conditions). Before gameplay begins, the umpire designs the environment and initial conditions based on the objectives for the game. Environmental conditions that can be modified include the depth of the water, sea state, sound speed profiles, and other factors that affect acoustics (Urick, 1983). These complex acoustic properties and probabilities, based on real data, are calculated ahead of time and placed into probability tables ahead of time. The umpire is only required to roll two 10-sided die (shown in Figure 3) to determine whether an event has occurred during gameplay. Finally, the umpire will set the scale of the game board based on the game scenario. The hex game board lends itself to different scales of play. If the scenario calls for a small game board, hexes can represent 100 yards or less, or for a large board, the distance between hexes could be made to represent several nautical miles each.
The game can be played in either a ground truth mode or single blind mode. Ground truth mode uses the same board for both the game umpire and the players, where locations for every entity (vessels and weapons) are plainly available for all to see. Single blind mode uses one board for the players containing data known by the player and a separate board for the umpire with ground truth data. In this mode, the player must determine where and what the target is doing using representative sensor information provided by the umpire at each turn. The umpire uses the gaming dice and pre-determined probabilities, in conjunction with the distances from sensors to other entities to determine what information is shown on the player board. The objectives of the game determine which mode will be used. For example, if the goal is to elicit knowledge to develop a decision support capability, a single-blind game would be played because it would allow the research team to assess how different pieces of information affect their decision making in relevant scenarios.
Also similar to D&D®, gameplay for the players largely resembles the turn-based schema made popular in that title (Crawford, 2014). Turns are initiated by submitting “move sheets” to the umpire, which then starts a sequence of actions for each turn. Move sheets include basic commands such as commanded course, speed, and heading of the controlled vessel, but may also include actions such as the employment of weapons or turning certain sensors on or off. The sequence conducted by the umpire each turn is as follows:
1. Discuss options and submit move sheets to umpire
2. Launch/deploy assets (e.g., torpedoes, sensors, countermeasures)
3. Move entities (platforms and weapons)
4. Process actions (sensor detections, munitions effects)
5. Results are provided from umpire
Depending on the needs of the scenario, gameplay may involve delays or require additional turns to complete actions. For instance, when a speed change command is made, it can take time for a vessel to change to the new speed based on the difference between the current and newly desired speed. The specifics of how that calculation is made and how far a vessel will travel while changing speeds is provided by the umpire. Similarly, when a course change is made, considerations may be made for the distance and time it takes the vessel to turn from its original course to the newly commanded course. The umpire would consult pre-made spreadsheets of ship performance calculations since the scale, speed, and vessel type are all a factor in the distance traveled to make a turn
Because a purpose of LRTS is to test the resilience of concepts developed in a vacuum against the uncertainty of real world scenarios, the umpire can inject new events and conditions into the scenario as they see fit. The modification or overriding of probabilistic determinations for sensor and weapon events is used to add randomness to games as needed. If the umpire wants to evaluate how a player would respond to an off-nominal situation (i.e. something breaking or misfiring), the actual probabilities are ignored to force a condition during gameplay. This strategy can be used to force events based on research objectives, or to counteract a series of “good” or “bad” rolls.
All turns and resultant conditions are recorded in the provided move sheets, which preserves the decisions made and the reasons behind them for future use and analysis. Similarly, photographs are taken of the game board at the end of the scenario, along with any post-it notes or annotations made during gameplay. These artifacts are used for analysis, and are often placed in analytical products delivered to stakeholders to explain the outcomes of the innovation event.
2017 Paper No. 22 Page 6 of 11
MODSIM World 2017

Example Scenario Walkthrough
To provide a more rich understanding of LRTS gameplay and the kinds of information generated during a game, the following is a hypothetical submarine-on-surface engagement scenario using hypothetical values (ranges, geometries, speeds, etc.) and tactical concepts that are generated strictly for demonstration purposes in this paper. Because of the adaptability of LRTS, real values based on operational capabilities and acoustics data would be used.
The left image within Figure 4 shows a hypothetical setup that a player would be presented with in a single-blind scenario (the target is shown only for purposes of this paper). They would be presented with a location of ownship (blue), briefed that there is a potential target to the north, and in this scenario, shown the three obstacles (e.g. islands, shoals, or other structures). The players would control the blue submarine and the umpire would control the target ship. The umpire would start the game by showing them the game board, and describing a background narrative stating why they find themselves in this situation, what their orders are, and any other relevant information that may constrain the actions or approaches they can take. KE begins immediately, where the players may be asked sample questions such as:
• What do you think the target’s intentions are? What information do you need to confirm that?
• How do you think the obstacles will affect your tactics?
The right image in Figure 4 shows the game board after three turns of play. In this case the players did not act for three turns in order to determine the operating pattern of the target. The general concept is that, using range and speed templates along with the bearing compass, the players can determine roughly how far the target contact is and how fast they are traveling. Using those determinations, the players can plan out a course of action. In this hypothetical case, the team assumes the target vessel will move behind the obstacle, but does not want to lose their chance to shoot the target, so they launch a weapon to the right side of the obstacle in an attempt of hitting the target. Example KE questions asked of players at this point in the game may include:
• Where is the enemy moving? How confident are you in this assessment?
• What tactics or courses of action could you employ to engage the target?
• How could this tactics go wrong? What cues would you use to determine they are failing?
The players’ moves and decisions are recorded at each turn of gameplay to allow for reconstruction of the game for analysis at a later point. Information recorded includes where each piece on the board is, what they see, their range and bearing to different targets, and their current course, speed, and heading.
Figure 5 shows this scenario played out after seven turns of play. At this point, the umpire would begin to use detection geometries (shown in green) to determine if the weapon can detect the target. Similarly, the umpire would measure the distance between the weapon and the target, use the lookup tables generated, and then roll dice to determine if the
MODSIM World 2017
  Figure 4. Game Board at Initial Setup (Left) and After Three Turns of Play (Right).
The green circles represent obstacles, while the blue lines represent ownship motion, and the orange lines represent bearing readings and a deduced potential course of target movement.
2017 Paper No. 22 Page 7 of 11

weapon was counter-detected. If counterdetected, the umpire would employ any number of tactics or assets at their disposal to thwart the attack in a representative manner. Adding the red line to show actual contact location (for the purpose of this paper), one can see the weapon is pointed right at where the target is expected to be in the next turn. With a successful intercept the scenario will be ruled a “hit,” although the success of employing LRTS comes from the knowledge gained from the player’s perspectives and decisions throughout gameplay. A retrospective verbal protocol is typically used after the game to glean further insights (Bainbridge & Sanderson, 2005). Sample questions that may be asked following gameplay include:
• What factors influenced the success/failure of that tactic?
• What made you decide to engage when you did? What would have happened if you engaged sooner or later?
USER PERCEPTIONS of LRTS
Although the benefits of using LRTS are inherently obvious, user perceptions were surveyed to determine the effectiveness of LRTS in accomplishing several objectives in TIDEs. To do so, surveys composed of Likert items based on these objectives were distributed to and collected from participants at a TIDE. The available responses to the Likert items ranged from 1 = “Strongly Disagree” to 5 = “Strongly Agree,” where 3 was a neutral statement of “Indifferent to.”
Participants
Questionnaires were handed out to participants at the third and final TIDE in a series of three events that were stretched across a nine month innovation and technical maturation project. A total of 22 participants provided responses, where all had played LRTS at least twice at the time of responding to the questionnaire. Because this particular community of interest has conducted innovation events in the past (in addition to the two previous TIDEs on this particular project), participants had played LRTS a mean of 5.00 times (SD = 2.67), with at least one participant having played LRTS 12 times. These participants were from a diverse set of backgrounds and project roles, including end users, engineers from many different relevant disciplines, and program managers. Participants also spanned across experience strata by including junior, mid-level, and senior personnel in their respective organizations.
2017 Paper No. 22 Page 8 of 11
MODSIM World 2017
 Figure 5. Game Board of Hypothetical Scenario after Seven Turns of Play.

Questionnaire Results
Descriptive statistics including Mean (M), Standard Deviation (SD), Minimum (Min), and Maximum (Max) were generated for all questionnaire items, which are shown in Table 2. Results showed that participants strongly agreed that LRTS promotes discussion and critical thinking (M = 4.59, SD = .50) and that LRTS helps uncover and discuss assumptions that are made in a scenario (M = 4.59, SD = .50), which were the items that participants most positively responded to. Conversely, the item that participants responded to least positively was the appropriateness of the amount of overhead time (i.e. time spent for measuring distances, moving entities, and rolling dice) spent during gameplay (M = 3.05, SD = 1.00), which is corroborated by the relatively low rating for the statement regarding smooth and error-free gameplay (M = 3.45, SD = .74). Based on participant commentary and written feedback, these low ratings are attributed to issues with people making errors in measuring distances and bearings (driven in part by the large size of dry erase marker felts and the small size of the grids), and the time it takes to translate moves and results to and from the umpire’s ground truth board in the case of a single-blind game.
Table 2. Descriptive Statistics of LRTS Questionnaire Responses
MODSIM World 2017
   (#) Statement
     M
   SD
   Min
   Max
   1: Number of LRTS games played.
     5.00
   2.67
   2
   12
   2: LRTS Promotes discussion and critical thinking.
     4.59
   .50
   4
   5
   3: I feel involved in gameplay during LRTS sessions.
     4.45
   .51
   4
   5
   4: The entire group gets involved when playing LRTS.
     3.77
   .92
   2
   5
   5: I have fun and enjoy the LRTS sessions.
     4.41
   .59
   3
   5
   6: The LRTS setup facilitates smooth, error-free gameplay.
     3.45
   .74
   2
   5
   7: The amount of time spent on overhead calculations is appropriate for smooth play.
     3.05
   1.00
   2
   5
   8: I jot down notes to keep track of things during LRTS.
     3.36
   1.05
   2
   5
   9: Showing/sharing our results to the larger group is easy.
     4.14
   .64
   3
   5
   10: I can easily visualize and plan moves in advance.
     3.77
   .97
   2
   5
   11: LRTS helps uncover and discuss assumptions.
     4.59
   .50
   4
   5
   12: LRTS helps identify spatiotemporal issues w/ concepts.
     4.36
   .66
   3
   5
   13: LRTS supports determining effectiveness of concepts.
     4.32
   .57
   3
   5
   14: LRTS is a useful tool for developing advanced concepts.
       4.45
      .74
     3
     5
  Note: The first question was regarding past experience with LRTS, so Likert items began on #2.
A quick look at the results in Table 2 will show that LRTS is highly regarded by those who have played it. Of particular interest to the analytical team are the perceptions of whether or not participants find it useful (Statement 14) and whether or not they find LRTS to be fun and enjoyable (Statement 5). These two criteria comprise a large proportion of the rubric by which the merits of using LRTS for concept development in high-morale innovation events such as TIDEs are judged. Of course, any analytical method or tool should be useful, but because of the high-paced intensity of TIDEs there is a considerable need for them to be engaging and fun. To better understand why participants found LRTS useful and fun, correlations were calculated across responses using Spearman’s Rho because the data was non- parametric (Field, 2009).
Several perceptions were strongly positively correlated to perceptions of LRTS being a useful tool for developing advanced concepts (Statement 14). Those who thought LRTS was useful also felt involved in gameplay (Statement 3, RS = .58, p < .01), that LRTS promoted discussion and critical thinking (Statement 2, RS = .58, p < .01), and that LRTS helped uncover and discuss underlying assumptions in concepts (Statement 11, RS = .58, p < .01). Several other perceptions were positively correlated to finding LRTS to be useful, including the perception that LRTS enables the identification of spatiotemporal issues in concepts (Statement 12, RS = .45, p < .05), and that it supports determining the effectiveness of concepts (Statement 13, RS = .44, p < .05). Because causation cannot be determined by correlation, no conclusion could be drawn as to whether participants found LRTS to be useful because they felt that their involvement made a positive impact on the results, or whether participants decided to get involved in LRTS sessions because they perceived it as a useful tool.
Results showed that perceptions of finding LRTS fun and enjoyable (Statement 5) were significantly correlated to perceptions of LRTS encouraging discussion and critical thinking (Statement 2, RS = .57, p < .01), that the entire group
2017 Paper No. 22 Page 9 of 11

gets involved in gameplay (Statement 4, RS = .39, p < .05), that sharing results of gameplay to the larger group is easy (Statement 9, RS = .58, p < .01), and that LRTS helps uncover spatiotemporal issues (Statement 12, RS = .48, p < .05). These results show that a large part of the fun of LRTS is likely due to the nature of collaboration in the TIDE environment, as evidenced by the correlations to statements 2, 4, and 9. Additionally, the process of engaging in critical thinking and seeing their recently brainstormed concepts “unfold” before them (statements 2 and 12) is also a component of participant enjoyment with LRTS. This finding is congruent with the intrinsic enjoyment of problem solving that is discussed in the “Flow” construct of user engagement (Csikszentmihalyi, 1990).
At a higher level, an interesting result is that participants find LRTS to be both useful and fun, although, largely for different reasons. LRTS is perceived as useful by those who think it helps uncover implicit assumptions and drives critical thinking and working out spatiotemporal issues. Those who perceived LRTS also thought it engendered social interactions, including discussion, group involvement, and sharing the outcomes of gameplay. Another finding that has yet to be explained; however, is the negative correlation between experience with LRTS (Statement 1) and the perception that it helps identify spatiotemporal issues with concepts (Statement 12, RS = -.63, p < .01).
CONCLUSIONS
Findings
From the multiple, repeated, use of LRTS and the user perception data analyzed, a number of high-level findings and conclusions can be asserted:
• At less than $150 of initial cost and the ability to use data collected in real world scenarios, LRTS is an inexpensive means to test CONOPS with a relatively high level of fidelity.
• LRTS serves a valuable role in innovation and design-thinking workshops, such as TIDEs, by providing a mechanism to test tactical concepts and engender critical thinking and discussion for KE.
• LRTS follows rules and gameplay mechanics similar to D&D and other popular tabletop games, making it intuitive and simple to conduct.
• Participants agree that LRTS is both useful and fun, albeit for different reasons.
• The greatest potential for improvement of LRTS is through automation or other efforts to reduce the amount
of “overhead time,” or time it takes between turns to process participant inputs.
Discussion
Despite the overwhelmingly positive findings from the user perception questionnaires, there are some issues that limit the generalizability of these findings. Foremost, the Likert items used in the questionnaire were not mutually exclusive or collectively exhaustive (therefore lacking construct validity). Instead, they were aimed at validating or disproving anecdotal evidence and a priori research goals of the R&D team. However, recent research has shown that even when overall subjective usability ratings of a product differ from the average rating of specific components, there is still a high correlation and reliability across measures (Smith, 2015). Given these findings and the generally positive anecdotal evidence from gameplay, the authors have high confidence in the results of the user perceptions questionnaire despite the lack of formality in its development.
Another methodological issue with the results presented in this paper is that the effectiveness of LRTS, based on its primary goal, has not truly been assessed. The participant perceptions of LRTS are valuable insights, specifically for assessing the fun and engagement of gameplay, but they do not enable the objective assessment of the quantity or quality of discussion, which is the primary outcome of using LRTS in a TIDE. Some items in the questionnaire allude to the quality of thinking, discussion, and sharing of ideas across teams, but no data have been used to triangulate these perceptions with empirical grounding. Some biases can be confidently dismissed, while others drive the need for empirical measurement of the conversations resulting from LRTS gameplay. Naïve realism, or the bias for humans to misplace confidence in high-resolution representations over low-resolution alternatives (Smallman, Cook, Manes, & Cowen, 2007), does not appear to be an issue, as evidence by agreement with Statements 10 and 12. However, the authors share a concern that participants may be positively biased towards LRTS because of their personal involvement with it. That is, participants feel involved in LRTS (as evidenced by responses to Statement 3) and therefore are biased to report it as useful and effective, because they are intrinsically connected to it. Further research will be needed to compare objective measures of user participation and resultant conversations with subjective perceptions of these variables.
2017 Paper No. 22 Page 10 of 11
MODSIM World 2017

Another item of discussion is the single negative correlation between the experience with LRTS (measured by the number of LRTS games played) and the perception that LRTS helps uncover spatiotemporal issues (Statement 12). Two theories prevail among the authors. First, it is a statistical anomaly due to the scalar value of LRTS experience. Second, there is an “expectation” creep that occurs with increased gameplay. Because the number of LRTS games played is a scalar variable among ordinal variables and due to the relatively small sample size (N = 22), it is possible that if the few participants with high experience with LRTS provided lower responses to Statement 12, it may account for the negative correlation. A counterpoint is that all other variables are ordinal (i.e. therefore equally susceptible to this anomaly), yet only Statement 12 has a negative correlation (significant or not). The other explanation is that after playing LRTS numerous times, there is a higher expectation for the utility of the outcomes. People are initially surprised by the utility of such a simple approach in addressing forward-thinking concepts, but this may be diminished over time. As more data are collected from future gameplay sessions, this relationship will be examined for clarification.
Future Work
Although LRTS was positively received by participant overall, the user perceptions regarding the amount of overhead time between turns and the smoothness of gameplay had the least consensus across participants. Acknowledging this, the authors and their colleagues have developed and begun evaluation of a Medium Resolution Tactical Simulator (MRTS). MRTS has shown positive feedback from the initial set of participants with regards to reduced overhead time; however, the time between turns was filled with relevant discussion- the key purpose of wargaming. Further analysis is needed to assess this tradespace between the perceived efficiency of gameplay and the value of lost information from the reduced discussion time.
Because the main purpose of LRTS sessions at TIDEs is to facilitate KE from the participants, further work will address measuring the quantity and quality of discussions that occur during LRTS and MRTS sessions. Text analysis methods will be ran on transcripts from LRTS sessions to determine the quantity/volume of discussion, and to assess whether or not there is a shared mental model across participants (Dorton, Spaulding, Burton, & Wetzel, 2016). The authors are also looking to implement social network analysis methods to determine the underlying structures and emergent roles of participants during gameplay, which will provide a more rich understanding of how to structure teams to effectively facilitate discussion.
ACKNOWLEDGEMENTS
The authors wish to thank LeeAnn Maryeski and Rob Hanna for their inputs, which greatly helped the manuscript.
REFERENCES
Bainbridge, L. & Sanderson, P. (2005). Verbal protocol analysis. In J. R. Wilson and N. Corlett (Eds.) Evaluation of Human Work, pp 159-184. Boca Raton, FL: Taylor & Francis.
Brown, T. (2009). Change by Design. New York, NY: Harper Business.
Crawford, J., Perkins, C., & Wyatt, J. (2014). D&D dungeon master’s guide. Renton, WA: Wizards of the Coast. Crawford, J. (2014). D&D player’s handbook. Renton, WA: Wizards of the Coast.
Csikszentmihalyi, M. (1990). Flow: The Psychology of Optimal Experience. New York, NY: HarperCollins.
Dorton, S., Spaulding, R., Burton, P, & Wetzel, A. (2016). Assessing corporate perceptions of a human factors lab
using thematic text analysis. Proceedings of the 2016 International Annual Meeting of the Human Factors and
Ergonomics Society, September 19-23, Washington, DC.
Field, A. (2009). Discovering Statistics Using SPSS, Third Edition. Los Angeles, CA: Sage.
Morabito, T. (2016). Targeted fidelity: Cutting cost by increasing focus. MODSIM World 2016, pp. 1-6.
Smallman, H. S., Cook, M. B., Manes, D. I., & Cowen, M. B. (2007). Naïve realism in terrain appreciation.
Proceedings of the 51st Annual Meeting of the Human Factors and Ergonomics Society, October 1-5, Baltimore,
MD.
Smith, T. J. (2015). Observer perceptions of overall system quality – the Lake Wobegon Effect. Proceedings of the
2015 International Annual Meeting of the Human Factors and Ergonomics Society, October 26-30, Los Angeles,
CA.
Urick, R. J. (1983). Principles of Underwater Sound, 3rd Ed. New York, NY: McGraw-Hill.
2017 Paper No. 22 Page 11 of 11
MODSIM World 2017
