Enhancing Trainee Immersion with Goal-Directed, Reactive Populations and Realistic Surroundings
Colin A. Puskaritz, Todd W. Griffith, Jason R. Potts
Discovery Machine, Inc.
Williamsport, PA
cpuskaritz@discoverymachine.com, tgriffith@discoverymachine.com, jpotts@discoverymachine.com
ABSTRACT
David Knox Loyola Enterprises Virginia Beach, VA david.knox@loyola.com
Anthony Cross USMC TECOM Quantico, VA anthony.cross1@usmc.mil
Virtual simulation lacks the variation and realism necessary to fully immerse trainees into a simulated world. As a result, trainees have a difficult time paying full attention and waste valuable training cycle time. As training budgets shift from live to virtual approaches, predictable artificial intelligence and unrealistic surroundings detract from training goals, and undermine training efficacy. To increase return on investment and better prepare soldiers, it is important to simulate a population that acts and communicates realistically. It is essential to shift away from traditional scripting approaches to adaptive techniques which can be reviewed, understood, and augmented by subject matter experts visually.
This paper highlights how goal-directed, configurable, and reactive behavior templates address training gaps often ignored by existing training simulations. It details how a framework that allows for adaptive character goals creates more realistic and cost-effective, immersive experiences for trainees than scripted equivalents. With a goal-directed approach, details like how Non-Player Characters (NPCs) communicate, what NPCs recognize in the surrounding terrain, who an NPC knows, and how an NPC engages with players can contribute to the choices NPCs make. This paper explores how a cognitive architecture enables NPCs to make their own decisions throughout their day based on their role in a population and what they actually need to do. Each NPC is not hard-coded but instead observes others, perceives outcomes, reacts to changing situations, and chooses activities (e.g. working, eating) accordingly, thus adding a level of realism to training simulations that is unparalleled in traditional scripted training scenarios.
ABOUT THE AUTHORS
Colin A. Puskaritz is the Product Development Manager for Discovery Machine, Inc. He is a 2009 cum-laude graduate of Lycoming College where he studied business administration and psychology. Since graduating, he has focused his efforts on understanding artificial intelligence and its applications to instruction and simulated training.
Todd W. Griffith, Ph.D. has worked in the area of intelligent systems research for 25 years, has published numerous papers in the field, and has frequently been invited to present at related conferences and panels. He has focused his research on building knowledge acquisition and deployment tools that enable SMEs to encode their own expertise on the computer. He has obtained grant funding through DARPA, NASA, NAVAIR, ONR, US Army, ERDC, MDA, US Air Force, USMC, and NSF. Dr. Griffith holds 4 US Patents and Discovery Machine’s RESITE® Suite, Knowledge Service Engine, and Behavior Modeling Consoles are commercial realizations of his research.
Jason R. Potts is the VP of Software Development for Discovery Machine, Inc. Mr. Potts graduated with honors from WPI in 2001 with a Bachelor’s of Science degree in Computer Science and has been designing and developing software with the company since. His work has focused on development of tools which facilitate knowledge capture and representation of human expertise in a machine executable form. Applications of his efforts have been applied to behavior modeling of simulated entities and automation of expertise both in military and commercial sectors.
David Knox is a graduate of Columbia College who spent 26 years as a Topographic Engineer and 23 years as an innovator in content creation in support of military simulations. He currently serves as the Program Manager for the United States Marine Corps Pattern of Life program and is employed by Loyola Enterprises Inc.
Anthony Cross is retired from the USMC, received a B.A. in Information Technology Management, and has an M.S. in Information Assurance and Security from American Military University. His professional interests focus on design and development of a single enterprise-wide, geo-specific, synthetic training environment that includes oceanic, atmospheric, and human geography; cyber-security processes; and his current projects include terrain generation for training simulations, institution of a common database format for training environment development, and pattern of life. He currently serves as the Branch Head Current Training Programs, TECD, TECOM, USMC.
2018 Paper No. 18 Page 1 of 11
MODSIM World 2018

Enhancing Trainee Immersion with Goal-Directed, Reactive Populations and Realistic Surroundings
Colin A. Puskaritz, Todd W. Griffith, Jason R. Potts
Discovery Machine, Inc.
Williamsport, PA
cpuskaritz@discoverymachine.com, tgriffith@discoverymachine.com, jpotts@discoverymachine.com
INTRODUCTION
David Knox Loyola Enterprises Virginia Beach, VA david.knox@loyola.com
Anthony Cross USMC TECOM Quantico, VA anthony.cross1@usmc.mil
Trainee immersion is a critical, often overlooked factor in simulated training development across the Department of Defense (DoD). True immersion is essential to adequate training results and requires a variety of factors such as realistic surroundings, realistic civilian populations, and realistic training objectives. A lack of any of these factors detracts from the immersion values of a training scenario and lessens the potential for training results. If done correctly, simulated training should impart students with a suspension of disbelief and create better training outcomes at a fraction of the cost of live training.
This paper describes efforts undertaken to equip instructors with cost-effective ways to create, configure, and reuse training content which enhances the trainee experience. Our approach addresses common training gaps which are preventing total immersion during simulated training events across the DoD and thus reducing potential return on investment. To that end, we present work funded by the United States Marine Corps Training and Education Command (TECOM) to create an observable pattern of life which is realistic, rational, reliable, and repeatable. Factors considered in our efforts are twofold: create a realistic visual environment which depicts the real world and correctly simulate the complexities of human behavior in a culturally correct way.
We discuss how applying visual artificial intelligence techniques and subject-matter expertise can be used to create configurable, goal-oriented behavior templates which adapt to surrounding conditions. Further, we explore how situation awareness, communication, player involvement, and other factors contribute to how an NPC makes decisions and what they choose to do throughout a training event. The techniques discussed provide the framework for a solution which will immerse trainees better than alternative approaches and reduce operator requirements, while increasing training effectiveness and mission preparedness. Samples highlighting different behavior templates and how our approaches enhance trainee immersion are also discussed.
BACKGROUND
Current State of Simulation
The demand for simulated training environments that realistically depict the real world has been increasing with each passing year. With anticipated Pentagon investment increases from $400 million in 2015 to $550 million by 2021 (Harper, 2017), the demand is only set to rise. Numerous simulation environments have emerged with the common promise of enhancing real-world results through realistic immersive training experiences. Even though there are many virtual simulation systems deployed throughout the DoD, there is still much debate over the efficacy of simulated training and the level of realism that is required to impart essential knowledge and an adequate return on investment.
With added investment into simulated training, there is concern over if investments truly enhance training effectiveness at a reasonable cost. Now, more than ever, it is essential to recognize the shortcomings of current simulation environments and address them to make better, more effective future simulations. When investigating live vs. virtual training outcomes, Maxwell and Zeng (2017) found that live training led to better decision-making
2018 Paper No. 18 Page 2 of 11
MODSIM World 2018

for trainees, but recognized a potential cause was that their simulations did not properly recreate training environments, training tasks, and/or necessary interpersonal communications to accurately mimic the real-world. By investing in aspects like these, a better training environment can be produced in a virtual space. Likewise, investments in enhancing AI have been made, but often focus their efforts on tactical behavior alone and lack controls for realistic human populations. Often investments in graphics, terrain, and AI are taken in isolation, leading to disjointed solutions which are either graphically beautiful or functionally intelligent, but seldom both.
Importance of Civilian Populations for Training
The forgotten element of simulated training is often the civilian population. In training terms, cultural skills are often thought of as a separate training line item, often dismissed in exchange for other mission-essential training procedures (Connable, 2018). This is unfortunate, because cultural competency at a basic level is essential to every deployed soldier and is attainable in an affordable way through simulation. Research has shown that it is possible to create patterns for cultures around the globe. These patterns are structured in nature and can be modeled in a functional, ontological way. More, emergent behavior can evolve within a properly constructed population to allow for realistic identifiable anomalies (Schatz, Folsom-Kovarik, Bartlett, Wray, & Solina, 2012).
As the world puts a greater emphasis on virtual training in order to cut costs, an increased emphasis will be placed on immersive training (Fernandez, 2017). If the quality of an individual’s threat detection skills are truly a result of experience (Zimmerman, Mueller, Marcon, Daniels, & Vowels, 2011) and training budgets are shifting towards simulation, then creating a realistic immersive experience is even more essential. In their research, Zimmerman, Mueller, Marcon, Daniels, and Vowels (2011) made the observations that time pressure had a factor in novice decision-making, but their accuracy under time-pressure increased with added exposure to potential threats. Novices also tended to describe threats they saw based on circumstantial cues like “they look kind of suspicious” alone, whereas more experienced individuals associated contextual situation detail when identifying threats. By increasing exposure to threats in immersive environments trainees are able to rehearse critical thinking and recognition skills, thus accelerating their path to becoming an expert prior to deployment.
It is possible to create civilian populations in many of the most popular simulations, but these solutions often rely on predictable, scripted behavior to control populations and seldom take into account the cultural nuances found in populations around the world. Though scripted behaviors often appear realistic, they lack the ability to adapt to changing situations and select appropriate actions based on the current state of a simulation. Fortunately, incorporation of a more goal-oriented design has been shown to allow for greater adaptation to environmental changes (Stensrud, Purcel, Fragomeni, & Garrity, 2012).
TECHNOLOGY OVERVIEW
Replacing Scripts with Visual Cognitive Models
The approach taken for this effort included a transition from traditional scripting approaches, typically used within simulation environments, to a visual programming format, TMK (Task-Method Knowledge). This was done for a variety of reasons. Mainly, scripts are difficult for experts to understand and adapt based on the current situational need. They tend to be hard to reuse, except for very constrained scenarios, and often reference exact locations, objects, NPCs, and/or players. These factors limit the complexity of what a training scenario can be, increase training development costs, and detract from the overall goal of creating a dynamic, reactive civilian population which interacts with their surroundings.
Conversely, TMK allows a framework to create hierarchical routines for NPCs to perform throughout their day. TMK is based on work completed by Chandrasekaran (1986) where he argues that human behavior can be encapsulated by combining “generic tasks”, or process knowledge, with more traditional concept knowledge. It is designed to be an understandable programming language which subject-matter experts (SMEs) can use themselves to document their expertise. At its root, TMK consists of three primary elements to break down decision-making techniques: tasks, methods, and procedures. Tasks are steps that need to take place whereas methods and procedures are different ways to accomplish tasks (Sharp, & Potts, 2011). Figure 1 illustrates a sample TMK model representation.
2018 Paper No. 18 Page 3 of 11
MODSIM World 2018

MODSIM World 2018
  Figure 1. Sample TMK Model
By creating visual behavior models, it allows SMEs to remain involved throughout the entire development process from vision to final deployment. This gives them direct oversight over the knowledge embedded in a system so they can continually adapt and change behaviors until they perfectly represent their experiences. Visual aspects also simplify the creation of more complex behavior strategies. This better-facilitates a working representation of an NPCs surroundings and allows each NPC to adapt and dynamically interact with their surroundings while remaining true to their primary goal in a simulation.
Lastly, TMK allows behavior creation efforts to focus on recreating the thought processes of one individual instead of an interrelated script. This allows the knowledge and
decision-making capabilities to be severed from any one training scenario or simulation easily. It allows those behavior models to be transferred to other environments and reused for different training outcomes without expensive, time-consuming, repeated effort.
Situation-Specific Goal-Oriented Design
In order to create a realistic simulated environment that will engage trainees, it is essential to create an adaptive civilian population. To do so, we take a non-scripted, goal-oriented approach to create a set of character templates which are capable of adapting their behavior based on environmental changes (See Figure 2). The structure of each
template is a combination of previous efforts funded by Naval Air Systems Command Training Systems Division (NAVAIR-TSD), Office of Naval Research (ONR), and Air Force Research Laboratory (AFRL). The primary template structure includes three concurrent branches: Process Situational Awareness, Participate in Default Behavior, and Handle Communications (See Figure 3).
Using a situation awareness processor, it becomes possible to take into account numerous environmental factors and contextualize information in a meaningful way. The ability to process situational information and perceive outcomes is essential to creating intelligent behavior models. The initial implementation of situation awareness is an application of Mica Endsley’s model of cognition (Endsley, 1995). By applying the first two phases of Endsley’s
  Figure 2. List of Templates Created for Effort
2018 Paper No. 18 Page 4 of 11

model, the ability to perceive information and comprehend information becomes possible (Potts, Griffith, Sharp, & Allison, 2010).
MODSIM World 2018
  Figure 3. Sample Template Architecture
For the purpose of human populations it becomes important to consider a wider array of factors when deciding appropriate goals to perform. Initial explorations of how a human population would determine appropriate goals are explored in previous research efforts by Sharp and Potts (2011). In their investigation, Sharp and Potts considered factors like mood, attitude towards player, time, the effect of player interactions, and basic environmental threats as factors to determine the best goal to perform. This effort extends on this work by adding additional situation awareness considerations like NPC allegiances to others, individual occupational and personal needs, and increased environmental threats. As factors change, different options are selected, but ultimately, the most optimal goal is chosen based on the situation at hand.
Once a goal is selected, a separate strategy is triggered to carry out that particular goal. Goals fall into two main categories: primary goals and reactionary goals. Primary goals are top level tasks such as working, socializing, and sleeping. While conducting one of these goals, any number of other reactionary goals can interrupt their completion. Factors such as time, emerging character needs, or external stimuli could trigger a reaction. The unique structure used in this project allows for each NPC to react to situations as they evolve and then return to previous activities based on the current state of the simulation. For a full list of goals included in templates for this project see Figure 4.
Figure 4. Possible Character Goals
It is important to note, that goals do not replace each other as new goals are identified, but instead interrupt goals temporarily. For example, a shop vendor’s first goal might be “Perform Occupation” which would cause them to approach their market stall and open it to interact with customers. As the day progresses, the shop vendor might become hungry, which would cause their situation awareness processor to determine a new, most appropriate action to be eating, and therefore might set the goal to “Eat Meal”. This causes the shop vendor to temporarily interrupt their typical daily life to go find food and eat for a time. Then, after successfully eating, that goal would end allowing them to pick up where they left off in their previous goal, “Perform Occupation”.
  2018 Paper No. 18 Page 5 of 11

Though many character goals are common across each template, some factors can be tailored to a specific character role. For instance, each character template will have its own unique “Occupation” goal with individual details of how to accomplish their necessary tasks. In this way vendors, farmers, fisherman, clergy, etc. each behave differently by nature. Similarly, different types of characters might perform other goals in unique ways. For example, an Imam would handle prayer differently than the average worshipper. Both behaviors might decide that their current goal is “Pray”, but an Imam would proceed with leading the worship service, whereas others would pray independently or follow along with the Imam (See additional examples in Sample Training Use Cases Section below).
Another aspect included to enhance realism is communication. By including a handle communication branch to each behavior template, it allows players and NPCs to interact verbally. As each individual NPC carries out its daily life, they can talk to others to perform coordinated tasks, give directions, and/or send alerts. For example, if one character becomes frightened or sees something dangerous, they will run home and call a family member to warn them of potential threats. In this way information can propagate through the population and alter how the entire city behaves in real time. Similarly, players can communicate with populations to ask questions and learn information. Based on how they interact with each NPC, players can adjust that character’s individual mood and, similar to the case outlined above, trigger a domino effect throughout an entire population based on their altered opinion of a player.
Creating a Realistic 3D Experience
Creating a realistic environment in which training can take place is equally as important to any AI creation. Loyola Enterprises provided all terrains and 3D models for this effort. For this effort, two terrains were created: one in Qere Qozaq, Syria and one in Malabang, Philippines (Figure 5). The basic approach taken to creating a terrain is as follows. During the planning phase, a focus area is identified and a list of necessary models is created. Afterwards, research begins. The initial step is to acquire GIS data and then refine imagery, vector, and shape data associated with it. Next, existing models are identified and new models are created for inclusion on the terrain as needed.
MODSIM World 2018
  Figure 5. 3D Terrains Created Malabang, Philippines (left) & Qere, Qozaq (right)
From here, the terrain starts to take shape. While constructing the terrain, a myriad of tools are used to research details about the focus area. Among aspects researched are building dimensions, road widths, and textures for real world construction material and infrastructure objects. The rationale is to recreate the real world as best as possible by identifying what structures are made of and creating objects which look similar. For example, if a structure is made of concrete block, it will be made to look like concrete block. Similarly, if the water is five meters deep in the center of the pond and one meter deep at the shore then the terrain elevations are adjusted accordingly. Ultimately, an initial terrain is built and details are added to it. Water levels are adjusted, roads are added, edifice models are added, bridges are added, custom models are placed, infrastructure is incorporated, and vegetation is added. With each addition, adjustments are made to fix any anomalies that arise.
When researching 3D avatars, a similar approach is taken. For this project, the look of characters was
   Figure 6. Real vs. Simulated Terrains and Objects
2018 Paper No. 18 Page 6 of 11

researched primarily through internet research of the focus regions. Tools like Google Street View were used to search for the kinds of clothing people would wear (See Figure 6). If a particular style was desired, such as business casual or school uniforms, internet searches were performed to find representations of typical area dress. If regional research indicated various ethnic groups with their own unique look, such as Kurds in Syria, then an Image Search would be done again with altered criteria.
The net result is a virtual environment that is a mixture of geo-specific and geo-typical features that is populated by accurately depicted, culturally correct virtual avatars. This provides a realistic backdrop for trainees to engage with their surroundings and provides a framework for realistic training creation.
Simulation Selected
For this effort, Bohemia Interactive’s Virtual Battlespace 3 (VBS3) simulation engine was selected as the primary training environment. VBS3 was selected by the program sponsor due to its widespread use across the DoD. By creating a realistic, real-world location in VBS3, the intent was to create a functioning society that simultaneously pushed the boundaries of the AI capabilities with VBS3 while improving the training experience using VBS3. Though VBS3 was selected for use in this project, it is important to note that the terrains, 3D models, and AI behavior models were created externally to VBS3 and thus could be ported to other simulation environments.
SAMPLE TRAINING USE CASES
The following examples highlight practical applications where injecting reactive, goal-oriented NPCs would enhance trainee engagement. These samples are cases which were designed to address key USMC training needs in Malabang, Mindanao, Philippines.
Using an Authoring Environment Instead of Scripting
Creating realistic human populations for simulated training was a two-fold effort: region-specific research and scenario authoring. Both aspects were essential to bringing a population to life in a virtual world. Research was required to create complete dossiers about individual characters, their affiliations, and family connections. Authoring tools for scenario creation provided an easy way to configure information about the population.
  Figure 7. Scenario Authoring Environment
For this effort, a variety of research was conducted which culminated in detailed descriptions of two regions of the world and identified cultural patterns associated with twelve ethnic groups within those regions. Numerous families were identified with individual personality details for a variety of family connections (i.e. parents, children, siblings, etc.). This provided the foundation for a large population of unique individuals. Details identified for each individual included their name, occupation, age, gender, ethnic group, religion, home, work locations, and more.
To create the final training simulation a Scenario Advisor tool was used (See Figure 7). This tool allowed instructors to define character details like those identified above, specify clan affiliations, create family trees, and define organizational affiliations for each character. The ability to specify details about a character set was necessary for instructors to create a representative simulated population with minimal effort. Part of the process was to select a behavior template, which contains details about how to conduct a particular role within the population. The use of an
2018 Paper No. 18 Page 7 of 11
MODSIM World 2018

authoring tool removed the requirement to write complex scripts, increasing instructor ability to specify details about a large population.
Family trees provided a level of connection which many simulation environments lack. In order to create a realistic population, their interconnectedness must carry through. One way to do this was along familial lines. The scenario advisor allowed users to connect individuals so that they have grandparents, parents, grandchildren, children, siblings, and/or spouses. This was not a superficial representation and is referenced throughout training scenarios to contribute to NPC decision-making (See use cases below for examples).
Organizations were also defined using the scenario authoring environment. These structures were hierarchical in nature and could be used to augment character behavior within the training simulation. Similar to family trees, organizations could connect NPCs along social or business lines. This information was primarily used to coordinate activities between NPCs throughout training execution (See the Parallel NPC Insurgent Operations example below).
Parallel NPC Insurgent Operations
In addition to basic occupational details, each NPC created has the capability to operate as an insurgent in parallel to their daily routines. This means that any vendor, charcoal maker, priest, imam, etc. can also have a more nefarious role within the population while creating the illusion of normalcy. It is unrealistic to think that insurgent activity acts in isolation, so there is no benefit to simulating it as such.
In this project, we set out to model two types of insurgent action: assassination via suicide bomber and assassination via gunfire. For both examples, an entire network including leaders, logistics personnel, surveillance personnel, direct action members, and couriers was created using a hierarchical organizational structure. To better represent a real world insurgent cell, we intentionally kept NPCs in the dark about certain other insurgents within their network. In the event a trainee detained an insurgent, they would only be able to provide information about their superior, their subordinates, and in some cases select individuals they dealt with.
Consider the following example of an insurgent cell in operation. The steps of this operation are to identify a target for assassination, observe the target, coordinate assembly of a bomb, and carry out a final attack on the target. In this example, the insurgent cell leader identifies the target to be Eman Riga Abas, a prominent government official, and begins preparations for his assassination. He first needs to contact his surveillance leader and logistics leader to coordinate their respective roles. To do so he may make a phone call or relay key details via a more secure means, a courier. In both cases, he communicates initial details about the target and deadlines associated with the attack. Once tasked, the surveillance leader coordinates his team to observe the target over a period of time and estimate where he might be on the day of attack. Similarly, the logistics leader coordinates assembly of fuses, triggers, and explosives. Ultimately, surveillance details and an assembled bomb are delivered to the direct action team for use during the attack. An attacker approaches the anticipated location of our target, Eman Riga Abas, and detonates the bomb upon arrival. Eman Riga Abas has been assassinated and people scatter. Figure 8 shows snapshots of this example.
Figure 8. Insurgent Operation in Action
Insurgent operations are an optional capability which can be turned on and off when publishing a training scenario. This allows the option to first expose trainees to a scenario with normal day to day activities of a population and then expose trainees to the same scenario with suspected insurgent activity. By injecting potential threats, like insurgents, into a well-known environment, it allows trainees to spot any anomalies which emerge and helps reinforce their contextual understanding of danger in real-world environments.
MODSIM World 2018
  2018 Paper No. 18 Page 8 of 11

AI Utilizing Terrain Features, 3D Objects, and NPCs to Aid Decision-Making
To truly immerse a trainee, civilian populations need to interact with their surroundings. They need to do more than mill around in the background as a painted crowd. By incorporating the use of key terrain features within each behavior model created, we were able to increase interaction between NPCs and their surroundings and improve the overall look and feel of the environment.
Think about the following example of police officers
establishing a checkpoint on a major roadway. On a typical
day, roadways are clear. NPCs drive to and from homes,
workplaces, etc. unrestricted by any sort of roadblock, but
they are still aware of their surroundings and monitoring
for things which might impede their travel plans.
Meanwhile, as NPCs carry out their daily life, the local
police force decides to establish a checkpoint. They use
their knowledge of the surrounding terrain and NPC
movement to identify an appropriate checkpoint location and take steps to establish a checkpoint. They take into account common transit areas, road positions, and other factors. Barriers and signs are unloaded from police vehicles and positioned on the roadway. Now, each NPC passing through the checkpoint will stop, listen to officers, and proceed through the checkpoint. Their perception of the environment has allowed them to shift their goal from simply driving to handling a checkpoint first. See Figure 9 for an example of an operational checkpoint.
MODSIM World 2018
  Figure 9. NPC Drivers Recognizing and Handling a Checkpoint
All behaviors created use the terrain in some fashion throughout their day. Wandering barbers will position their stalls to high traffic areas based on the time of day and movement of other NPCs; wives of fisherman will periodically go door to door selling fish to others; farmers will plant and harvest fields; and delivery drivers will transport goods between producers and vendors to name a few. Figure 10 depicts a few examples of NPCs utilizing terrain features.
Need Recognition and Handling for Daily Tasks
A unique aspect to the behavior templates constructed during this effort is their need handling capability. As NPCs carry out their various goals, they will recognize things that they need in order to complete their goal and then attempt to satisfy those needs prior to continuing what they were doing. This creates context-specific motivation to attain goods and services. By doing so, a more natural pattern emerges amongst the simulation as NPCs recognize needs and approach others to satisfy them. Activity spikes also emerge naturally, as multiple NPCs recognize similar needs at similar times (i.e. shopping prior to a meal time, purchasing a snack). Figure 11 and Figure 12 show examples of market activity.
Figure 10. Samples of NPCs Utilizing Terrain
    For example, consider a construction worker completing his daily routine. The construction worker wakes up and goes to work. He assesses the construction zone and determines that he lacks wood, nails, and other essential supplies he needs to complete the job at hand. He decides to go to the market to purchase supplies prior to starting work for the day. On his way to purchase supplies, he notices that the barber shop is empty and decides that he
2018 Paper No. 18 Page 9 of 11
Figure 11. Numerous NPCs Shopping for Needs

needs a haircut and so will stop. As each NPC moves throughout the simulation, details about their surroundings, the current situation, and their individual characteristics contribute to their recognized needs. The fact that the construction worker is self-motivated creates a more realistic depiction in the simulation than his scripted counterparts.
Beyond handling needs themselves, NPCs are also able to task others to get things for them or complete tasks for them. For example, a mother may determine it is time to prepare a meal. She then may task her children to go to the garden for produce and/or to the market for meat and other items.
MODSIM World 2018
  Figure 12. Restaurant at Lunchtime
Player Engagement with Population
A unique aspect of each behavior template created is their ability to communicate, both with other NPCs and with the player(s) in real-time (See Figure 13). More, each interaction will alter how an NPC perceives and interacts with the world around them. Communication is used to coordinate activities when carrying out individual goals, to issue orders, and to relay information within each training scenario. This means that how a player engages with a population can actually alter how the scenario progresses.
  Figure 13. Player Interaction with NPC Fish Vendor
As discussed above, factors such as mood are monitored within the situation awareness of every character. Direct player-character interaction is one of the primary factors which contribute to mood adjustment within a population. By offending one well- connected individual, a ripple effect will be created which will make it more difficult for trainees to accomplish key objectives.
For example, if a player says something offensive to an individual, their mood towards the player will decrease. Then, as the scenario progresses, the offended NPC will slowly propagate their opinion of the player to others within their sphere of influence. This means that family
members, close associates, etc. will become slightly more upset with the player. The more upset someone is, the less forthcoming they might be with information. NPCs can even lie to players under the correct circumstances. Proper engagement with civilians in different cultures around the world is essential to mission success. As such, it is essential to simulate the dynamic nature of conversation within simulation.
In a slightly different context, players can also interrupt the flow of information throughout a training event by questioning individuals. In the case of an insurgent cell, as discussed previously, this could have a net positive effect because it could prevent the dissemination of key information, thereby disrupting the final attack. In contrast, preventing communications essential to a local economy would result in a negative outcome.
Regardless of the motivation, reactions to player communications will have an impact on the simulated population. Positive and negative interactions will lead to illustrations of how a real-world population might respond. This lets training participants witness the effects of communication first-hand to increase trainee readiness levels.
CONCLUSION & FUTURE WORK
The work completed to date as described in this paper is backed by research in goal-oriented cognitive architectures. Based on success implementing similar systems for other branches of the DoD, it is our belief that creating adaptive behavior templates allows for a more realistic experience for trainees while maximizing return on training
2018 Paper No. 18 Page 10 of 11

investment. Only with the ability to adapt to an evolving simulation environment, is it possible for NPCs to truly mimic real-world situations. Through the use of a situation awareness processor, NPCs are able observe their surroundings, infer information about the world, and adapt their behaviors accordingly. In this way, their behaviors can be driven both by expertise and adaptation to a changing scenario landscape.
Focusing purely on AI or visual effects is a mistake. Instead, it is essential to create behaviors which represent the real-world while maintaining the ability to adapt to changing information and communicate with each other. The goal-oriented design used in this project facilitated the creation of baseline character behaviors which represent regional expertise while maintaining the dynamic nature of life. As a result, the models created for this project allow for emersion of natural randomized patterns which are dictated not by programmers during development, but instead by individual NPCs within the simulation itself at runtime.
We are currently pursuing additional efforts where we will explore the use of different simulations, expand our list of available behavior templates, and enhance existing capabilities. As part of these continued efforts, we plan to investigate more dynamic ways of authoring populations to save instructors time and increase the scale of deployed civilian populations. Additionally, we are recognizing test audiences where we can receive direct feedback from instructors and trainees so we can begin to monitor the efficacy of our approaches.
ACKNOWLEDGEMENTS
The efforts described in this paper were conducted in conjunction with Loyola Enterprises and have been sponsored as part of a joint contract for the Joint Staff and TECOM.
REFERENCES
Human Factors,37
Proceedings of the Proceedings of the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC) Proceedings of the Interservice/Industry Training, Simulation, and Education Proceedings of the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC) Proceedings of the Interservice/Industry Training, Simulation, and Proceedings of the Interservice/Industry Training, Simulation,
MODSIM World Conference 2017. 2011.
Conference (I/ITSEC) 2012.
2011.
MODSIM World 2018
 Chandrasekaran, B. (1986). Generic Tasks in Knowledge-Based Reasoning: High-Level Building Blocks for Expert
  System Design.
IEEE Expert,1
(3).
 Connable, B. (n.d.). Human Terrain System is Dead Long Live... What? Retrieved January 22, 2018, from
 http://www.armyupress.army.mil/Journals/Military-Review/English-Edition-Archives/January-February-
 2018/Human-Terrain-System-is-Dead-Long-Live-What/
  Endsley, M. R. (1995). Toward a theory of situation awareness in dynamic systems.
(1), 32-64.
 Fernandez, M. (2017, August 2). Live, Virtual, Constructive or Mixed-reality Training Transforms US DoD
 Training and Simulation Market. Retrieved February 26, 2018, from https://ww2.frost.com/news/press-
 releases/live-virtual-constructive-or-mixed-reality-training-transforms-us-dod-training-and-simulation-market/
 Harper, J. (2017, November 17). Training Investments Expected to Shift to Simulations. Retrieved January 22,
 2018, from http://www.nationaldefensemagazine.org/articles/2017/11/17/training-investments-expected-to-shift-
 to-simulations
 Maxwell, D. (2017). Large Scale Testing and Evaluation of Virtual Environments for Infantry Soldier Tasks
 Comparing Mental Effort for Live Versus Virtual Training Performance Assessments.
  Potts, J., Griffith, T., Sharp, J., & Allison, D. (2011). Subject Matter Expert-Driven Behavior Modeling Within
 Simulation.
  Schatz, S., Folsom-Kovarik, J. T., Bartlett, K., Wray, R. E., & Solina, D. (2012). Archetypal Patterns of Life for
 Military Training Simulations.
  Sharp, J. J., & Potts, J. R. (2011). Improving Trainee Engagement Levels through Adaptive Entity
 Behaviors.
  Stensrud, B. S., Purcel, E. R., Fragomeni, G., & Garrity, P. (2012). No More Zombies! High-Fidelity Character
 Autonomy for Virtual Small-Unit Training.
 Education Conference (I/ITSEC) 2012. and Education Conference (I/ITSEC) 2011.
 Zimmerman, L. A., Mueller, S. T., Marcon, J. L., Daniels, J. B., & Vowels, C. L. (2011). Improving Soldier Threat
 Detection Skills in the Operational Environment.
 2018 Paper No. 18 Page 11 of 11
