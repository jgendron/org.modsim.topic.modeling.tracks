Automated Generation of Holographic Heart Visualization from Coronary Tomography for Multi-place Medical Diagnostics using Holographic devices
Arthur A B Bucioli, Edgard A Lamounier Universidade Federal de Uberlândia Uberlândia Minas Gerais arthurbuccioli@gmail.com, elamounier@gmail.com Author1@email.com, Author2@email.com
Gerson F M Lima, Alexandre Cardoso Universidade Federal de Uberlândia Uberlândia, Minas Gerais gersonlima@ieee.org, alex.cardoso.ufu@gmail.com Author3@email.com
MODSIM World 2018
  ABSTRACT
Medical imaging techniques play an important role in the diagnostic process. Through these techniques, it is possible to observe and analyze hidden details of the human anatomy, which is critical to the success of surgeries or clinical treatments. In so doing, an extensive experience in analyzing digital medical images is requested. However, physicians do not currently master such expertise. Therefore, greater accuracy and improved technology in dealing with these images must be sought. In particular, according to the Center for Disease Control and Prevention, about 610,000 people die of heart disease in the United States every year, which equates to 1 in every 4 deaths. Thus, computational tools for dealing with this grim reality are also imperative. In this context, emerging technologies such as Mixed Reality (MR) and Holography are increasing rapidly. These technologies allow for 1) the creation of high-definition virtual computing models of human organs and 2) the direct manipulation of interacting interfaces through such 3D models within a holographic environment that blends virtual and real elements seamlessly. This work combines several imaging techniques to support the automated generation of Holographic 3D volumetric heart models from coronary tomography. In turn, these models are presented in a real time shared holographic experience using Microsoft’s HoloLens, without the need of any further editing of the generated model. As a result, a tangible collaborative medical diagnostic solution, using shared reality concepts with other MR devices, such as HTC’s Vive, is provided.
ABOUT THE AUTHORS
Arthur A B Bucioli is graduated in Computer Science by UNASP- Sao Paulo(2005), Master in Science by Universidade Federal de Uberlândia(2008) and currently working as a federal professor in Instituto Federal do Traângulo Mineiro.
Edgard A Lamounier is graduated in Mathematics by Universidade Federal de Uberlândia(1986), Master of Science by Uniersidade Federal de Uberlândia(1989), PHD by Leeds School of Computing(1996), currently working as a full professor in Universidade Federal de Uberlândia.
Gerson F M Lima is graduated in electrical Engeneering by Universidade Federal de Uberlândia(1994), Master of Science by Universidade Federal de Uberlândia(2008), PHD in Electrical Engeneering by Universidade Federal de Uberlândia (2014), currently working as professor in Universidade Luterana do Brasil.
Alexandre Cardoso is graduated in Electrical Engineering by Universidade Federal de Uberlândia(1987), Master in Electrical Engineering by Uniersidade Federal de Uberlândia(1991), Doctor in Electrical Enineering by Universidade de São Paulo (2002), currently working as professor in Universidade Federal de Uberlândia.
2018 Paper No. nnnn Page 1 of 11

Automated Generation of Holographic Heart Visualization from Coronary Tomography for Multi-place Medical Diagnostics using Holographic devices
Arthur A B Bucioli, Edgard A Lamounier
Universidade Federal de Uberlândia
Uberlândia Minas Gerais
arthurbuccioli@gmail.com, elamounier@gmail.com Author1@email.com, Author2@email.com
1 INTRODUCTION
Gerson F M Lima, Alexandre Cardoso
Universidade Federal de Uberlândia
Uberlândia, Minas Gerais
gersonlima@ieee.org, alex.cardoso.ufu@gmail.com Author3@email.com
MODSIM World 2018
  The integration of information and communication technology brings many social, economic and political benefits, with higher degrees of satisfaction, cost reduction and the expansion in the access to Healthcare (ITMS, 2017).
Over recent years, the diagnosis process has been greatly aided by imaging techniques. These images enable doctors to study the patient’s anatomy, without the need for invasive procedures. In this case, Computed Tomography (CT) is the most common diagnosis process. However, image data interpretation requires a large quantity of training time.
Cardiovascular diseases play a major role in general morbidity and disability, representing one of the major burdens to healthcare systems as a whole (CDC and NCHS,2015). Telemedicine can reduce the pressure on medical experts (who are limited in number) and extend their expertise to patients in isolated or remote locations. In fact, Telemedicine appears particularly promising in the area of cardiovascular disease, as early, tailored interventions are extremely cost- effective in terms of life-saving and functional recovery.
Experiments have shown that telecardiology holds advantages for patients who find themselves in the interaction between primary and secondary care (Scalvini, 2010). In addition, General Practitioners (GPs) are able to acquire additional educational gain and hospital follow-up appointments may also be reduced in number (Scalvini, 2010).
The reconstruction of medical images in 3D models has been shown to improve the interpretation process. In addition, when these models are shared among virtual environments, it is possible to create an experience that allows doctors to take part in a collaborative medical diagnostic solution. However, sometimes the process of 3d reconstruction can lead to very heavy models, which are not ideal to real time visualization on devices with limited resources like the HoloLens for example. In addition, issues like loose geometry and granularity of polygonal faces occur very often in the reconstruction process (Preim and Bartz, 2007).
This paper proposes a 3D Visualization technique from coronary tomography to support medical diagnosis within a Telemedicine context. The aim is to present the reconstructed 3D visualization optimized to support a holographic real time visualization, where it is possible to share this experience through Microsoft’s HoloLens in a collaborative medical environment. Also, some filtering algorithms like masking and blur are added to the preprocess phase, to give to the user several possibilities of custom visualization.
2 THEORY
2.1 Coronary Computed Tomography Angiography
Coronary computed tomography angiography (CCTA) uses an injection of iodine-rich contrast material and computed tomography scanning (CT) in order to examine the arteries that supply blood to the heart and determine whether these have been narrowed by plaque buildup. The images generated during a CT scan can be reformatted to create three- dimensional images that may be viewed on a monitor, printed on film or transferred to electronic media (CCTA, 2017).
2018 Paper No. nnnn Page 2 of 11

2.2 3D Model Reconstruction from Imagery Techniques
Medical images are obtained through several different techniques, according to a specific organ or aspect that one wishes to observe. So, the resulting data is also very heterogeneous, requiring different approaches that need to be interpreted.
In the current paper, the tomography technique was chosen as the subject of interest, as this is one of the most commonly used techniques for obtaining 3D models of the human heart. Data generated by tomography deals with tissue density, which is stored in a 16-Bit format, supporting up to 65,536 variations. Normally, the range of densities of the human body does not go so wide, as they require the selection of a window of different ranges in order to analyze the upper and lower limits in density. Fig 1 shows two sample slices of a thoracic tomography.
Figure 1: Tomography sample frames.
As seen in the Fig 1, gray tones represent the tissue density. Therefore, it is possible to select a particular density for further analysis, as well as to generate 3D models. Each frame of the tomography represents a slice of the patient’s upper body, in a specific position. In turn, this position is changed on the next frame, in order to obtain a slice of another portion of the body, covering the whole area of interest. The 3D model is generated by joining data contained in all slices into a solid geometric object.
The process of generating a 3D solid model from tomography images requires a technique for detecting the boundaries of tissues, and thus to generate the appropriate 3D representation. One of the most popular algorithms, widely used by 3D reconstruction software is Marching Cubes (Lorensen and Cline, 1987). This algorithm works by dividing the space into cubic cells and then processing the content of each cell individually, which results in one of 14 predetermined 3D patterns. At the end of this process, a high-density surface is generated by the algorithm. An alternative algorithm, called Marching Tetrahedra is also proposed. However, it requires more computational power, since instead of processing a single cube per cell; the algorithm interacts with 6 tetrahedral(Doi and Koide, 1991).
It is important to note that the most advanced algorithms nowadays are under copyright by few enterprises around the world.
2.3 3D Alternative Volume Visualization through raycasting-voxel Techniques
3D reconstruction can be very expensive and generate lots of artifacts in the final geometry. Common issues in these techniques are long triangle faces, loose geometry and flipped face normals. Also, the geometry density of the generated models is often too high for real-time performance applications. Furthermore, the nature of tissues is hard to fully represent only with true 3d models. So, if the objective of the reconstruction is a high quality visualization, combining precision with maximum detail preservation, it is possible to use another approach, which not involves actual 3D geometry generation, but only a smart combination of the available 2D slices into an 3D environment. There are several variations of these techniques, like Volume Ray Casting (Weiskopf, 2007), Shear Warp (Lacroute and Levoy, 1994), Splatting (Westover, 2017) and Texture-Based volume rendering (Hibbard, 1989). Based on the most common demands of medical visualization and the hardware capabilities of the holographic available devices, it was chosen to implement in this paper a technique based on voxel raycasting, using GPU hardware capabilities of the holographic devices. The objective was to maximize the possibilities of manipulation and the compatibility with most devices possible.
MODSIM World 2018
 2018 Paper No. nnnn Page 3 of 11

2.4 The DICOM Standard
This standard, designated Digital Imaging and Communications in Medicine (DICOM), embodies a number of major enhancements from previous versions of the ACR-NEMA Standard (NEMA,2017). One of the most widely used features on DICOM is the Store subset, which defines rules for coding image files, such as file header, tags defining properties and places to store the raw data.
2.5 Telecardiology
Telecardiology has been widely used in the diagnosis of arrhythmias and for the management of patients with chronic cardiovascular conditions. It is important to note that in many cardiovascular conditions, such as acute coronary syndromes, the opportunity to offer prompt diagnosis and treatment will improve outcomes in terms of mortality and functional recovery (Scalvini, 2010).
In this situation, doctors and other healthcare providers use electrocardiographic data that is transmitted remotely, in real time, for interpretation by a specialist. It enables specialist care to be accessed by people in remote locations. The advancement of technology is making it easier and less expensive to set up wireless or satellite networks for this purpose, increasing their effectiveness and ease of use (Medical Life Science, 2017).
2.6 3D Visualization/Interaction Interfaces
Several 3D visualization systems have been proposed in the Literature. This paper, however, focuses on the Virtual Reality, Mixed Reality and Computational Holography, as described in the following.
2.6.1 Virtual Reality. Virtual Reality is described as an advanced user interface, based on the 3 Is pillars: interaction, immersion and imagination (Burdea and Coiffet, 1994). Virtual Reality applications are found virtually everywhere, from games to medical visualization.
2.6.2 Mixed Reality/Computational Holography. Mixed Reality (MR) can be defined as the "amplification of sensory perception through computational resources" (Cardoso and Lamounier , 2006). It allows for a more natural interface when working with computer-generated data and images across computing data and real-world information.
One of the most important characteristics of MR is that the interaction occurs within the real environment that surrounds the user, thus guaranteeing the conditions necessary to interact with this data naturally. Accordingly, MR uses the association of Virtual Reality and real environment, offering the user a better perception of the environment and favoring their interaction with it.
2.6.3 Microsoft HoloLens and HTC Vive. HoloLens is a wearable holographic computer based on Mixed Reality and built into a headset that lets the user see, hear, and interact with holograms within an environment such as a living room or an office space. Microsoft has built the headset without the need to be wirelessly connected to a computer, and has used high-definition lenses and spatial sound technology to create an immersive, interactive holographic experience (Microsoft , 2017).
HTC Vive is a Virtual Reality headset designed to utilize room scale technology, turning a room into 3D space via sensors, with the virtual environment allowing the user to navigate naturally, with the ability to walk around and use motion tracked handheld controllers to vividly manipulate objects, interact with precision, communicate and experience immersive environments (HTC, 2017).
2.6.4. Shared Holographic Experiences. A shared holographic experience is when two or more people experience the same holographic object(s). This could be in the same or different environments. The key to shared holographic experiences is multiple users seeing the same holograms in the world on their own device (Microsoft, 2017).
MS HoloLens keeps holograms in place by using various coordinate systems to keep track of the location and orientation of objects. When these coordinate systems are shared between devices, it is possible to create a shared
2018 Paper No. nnnn Page 4 of 11
MODSIM World 2018

experience that allows the user to take part in a shared holographic world. Fig 2 shows a shared experience example with HoloLens (Microsoft, 2017).
Figure 2: Shared holographic experience using HoloLens
3 RELATED WORK
This session reviews several systems, both commercial and academic, with features close related to the set proposed on this work.
3.1 Invesalius
This is a free software, in continual development since 2001 (CTI, 2017). It can be used to open DICOM files and generate 3D meshes from such files. It is possible to control the quality/complexity of the mesh by cutting down the number of slices used on the reconstruction (loosing the data contained on the skipped slices). The models can be exported to popular formats, like .OBJ and VRML. It uses the marching cubes algorithm for 3D Reconstruction. It can run on Windows, Linux and MacOs X. Additionaly, it allows the user to visualize the data using volume rendering by GPU raycasting techniques, including several pseudo-color schemes to improve the visualization. The user can also create his own schemes. The 3d surfaces generated by this software often presents the common artifacts of the marching cubes algorithm, and can easily reach millions of triangles.
3.2 Amira
Amira is a commercial suite of software for several different applications, not only medical reconstruction. The module called “Amira for Life Sciences” is that which makes 3D models from DICOM files (FEI, 2017). It can view DICOM files, take measurements and generate the 3D models. The algorithm used to generate the models is similar to that of marching cubes. Amira also haves support to volume rendering visualization, enabling great visual results, with pseudo-color schemes using the most common parameters to improve the visualization.
3.3 Osirix
OsiriX is a very popular commercial software that has been under development over the last 10 years. It can open DICOM files, generate 3D Models and export these to several formats, like .OBJ and .VRML. This software runs only on Apple desktop or mobile platforms. It possesses tools for refining the generated model, performs trimming of the undesired noisy resultant objects from the final file (Osirix, 2017).
Osirix can also visualize the data using volume rendering powered by GPU. The user can choose from a range of predefined color schemes in order to change the visualization.
3.4 Comparisons and remarks on the related work
MODSIM World 2018
 2018 Paper No. nnnn Page 5 of 11

Based on the current scenario, it is important to note that shared holography in conjunction with Telecardiology has still been poorly explored in all major systems available. Models generated by the systems analyzed are often too heavy in polygon count, noisy(lots of isolated polygons) and inappropriate to real-time visualization in simpler, most limited devices such as Microsoft Hololens . Control over the complexity and level of details on the generated surfaces are absent or incomplete in most cases. Some systems are mostly limited to 2D image representation and lacks in providing direct manipulation of reconstructed 3D models. Thus, it is believed that a collaborative environment solution for coronary tomography diagnosis can handle more advanced medical problems. The next section presents a system architecture to support this kind of application.
4 SYSTEM DEVELOPMENT
4.1 Objectives
The specific objectives of this project are as follows:
• To obtain a precise heart 3D model visualization that preserves the critical details such as vascularization.
• To generate controllable 3D visualization, with options to optimize the resolution and generation method of the visualization to the target device.
• To provide image preprocessing filtering tools, like noise removal options, blur filtering, threshold filtering, range filtering and negative filtering, in order to maximize the final results according to the user needs
• To automatically generate 3D Visualizations of the heart to be used in Virtual and Mixed Reality devices.
4.2 Methodology
The methodology of the project was organized as follows:
• Review volume rendering algorithms, as well as 3D generation algorithms, such as marching cubes.
• Study of the DICOM standard storage module, in order to process files.
• Review optimization techniques to simplify regions detected on the slices.
• Review shared holographic techniques to provide the virtual model interaction.
• A case study implementing all features needed.
• Evaluation of the case study on its computational efficiency, ease of use, model quality and simplicity.
4.3 Results
To prove the concepts presented in this article, a standalone application has been developed to run on several platforms by using the Unity IDE (Unity,2017). This application is modular, enabling any part may to be replaced with an upgraded version, as seen on the Fig 3.
Figure 3: System architecture.
2.4.1 Initial DICOM Files Reading and Viewing. DICOM files follow a tag-based approach, where each tag contains an identification code along with additional information. A simple parser has been developed to retrieve the tags of interest from a DICOM file, such as image dimensions, bit depth and patient data. The parser uses a table containing the tag identifier and the function to retrieve the tag information, according to the type of information. Only
MODSIM World 2018
 2018 Paper No. nnnn Page 6 of 11

a limited number of functions were implemented at the time, but this architecture allows for the expanding of the modules as necessary, just by adding tags to the table and implementing functions to process the different kinds of information contained.
After parsing the file tags, it is possible to retrieve the image data and put it into the memory for further processing. Selection functions of the density range and center of the interest window have been implemented, enabling a fine- tuning over the parameters for selecting the desired regions. Fig 4 shows the user interface of the functions developed and a sample file being opened.
Figure 4: DICOM file opened and managed with the developed functions.
2.4.2 Filtering and Preprocessing. The process of image acquisition is beyond the control of the application developed. Problems like noisy images, lack of contrast and poor quality scans can occur sometimes. In order to improve the user final visualization, the application includes several filtering options, that can both enhance the image quality and also allow to modify the parameters and select the ranges of densities to include in the final visualization.
The first function to note is the selection of window width and window Center. These functions allow the user to navigate into the densities captured by the image and select the ones where the visualization better captures the subjects of interest, like organ tissue, bones and contrasts. These functions are present in the vast majority of DICOM systems. Fig 5 shows the use of these functions in the developed application
Figure 5: Window Width and Window Center Options
Following, the user can toggle the negative filtering, which allows to invert the colors of the image, obtaining an interesting effect, that sometimes enables better visualizations than the original images, revealing hidden details in dark areas. Fig 6 shows the result of this operation.
Figure 6: Negative Filtering
MODSIM World 2018
   2018 Paper No. nnnn Page 7 of 11

Sometimes the subject of interest can be very noisy in the images. In that case, the user can choose to apply a simple/Box blur filter to filter the image, smoothing the visual result by blending neighbor pixels. The user can control how many iterations are used, and increase the blur radius. It is important to note that the indiscriminate use of this filter tends to cause loss of fine detail. Fig 7 shows a few examples of this function being used.
Figure 7: Blur Filtering
Most CT processing software allows the user to apply pseudo-color schemes to the images, that mimic with a certain precision the colors present on the real tissue, or enhance certain types of tissues while fades the others. The application developed can also apply this effect, enabling it in real time to the 2D slices while the user navigates through a sequence of images. The Fig 8 shows an example of this feature being applied.
Figure 8: Pseudo-Color Scheme Assignment to a sample
4.3.3 Computational Holography application. The process of reconstruction can take from seconds to several minutes, depending on the number of slices, filtering algorithms used, etc. All the parameters and settings can be tested on the samples in real-time, allowing a good preview of the final results. Once the parameters are all set, the system can process the selected slices applying the filters and generate a volume rendering visualization, model is generated, it is ready to use with the various viewing devices. In this particular case, the model generated is exported and configured automatically to be used with HoloLens, eliminating the need to any further edition/optimization. The volumetric render visualization feature requires to create a structure called 3DTexture, a special kind of texture supported in Unity that stacks lots of the 2D slices into a 3D Voxel structure. This texture is obtained by overlapping the desired slices one “above” the other, like paper sheets in a pile. The 3DTexture can be used to visualization inside the application, and also to be exported to another developed Unity project, which is specially designed to load the 3DTexture file and configure it to Microsoft Hololens. This is achieved through a binary file containing all pixels of the slices with filters and pseudocolors already applied. In order to enable the visualization of this special texture, a simple 3D Cube is created , and the texture is mapped onto it. Also, a shader, based on a Nvidia free example(Nvidia ,2017) is used to process the voxel data and apply a raycasting algorithm to it, enabling the visualization. The result inside the application is shown in the Fig 9.
MODSIM World 2018
  2018 Paper No. nnnn Page 8 of 11

MODSIM World 2018
 Figure 9: The final 3D Voxel visualization inside the application environment
Computational Holography, supported by wearable computers, like HoloLens, has the potential to allow simultaneous medical diagnosis as a second opinion initiative, based on Mixed Reality and Computer Vision capabilities. It is believed that this set of tools will improve the medical diagnosis procedure. Fig 10 shows a real image where a physician manipulates a 3D heart, generated by the techniques proposed in this paper, through HoloLens.
Figure 10: 3D Heart Hologram of a Computational Tomography scan.
4.3.4 Development of the Shared Reality. Thanks to the vivid Microsoft's HoloLens and HTC Vive kit, observers can share in a virtual experience, simultaneously, in virtual and augmented reality environments. A challenge in this experiment was not just getting the Vive and HoloLens to talk to each other, but also to bring them to a shared understanding of space.
The hardware embedded in the HoloLens (holographic processor and sensors) is responsible for the spatial mapping of the room where the holograph objects are projected. To share this space with HTC Vive, it is necessary for HoloLens to know where HTC Vive is in the room to place the holographic object in the correct position so that all users see this object in the same reference frame. Fig 11 shows this architecture, and the visual results of the architecture can be perceived on Fig 10, where it’s possible to perceive the real world being mixed with the virtual organs generated.
HoloLens can do this in two ways. The first is the use of an image recognition algorithm running on the HoloLens to locate the HTC Vive through the images generated by its camera. Although efficient, this method overloaded the HoloLens processor, this in turn may cause the projection of holographic objects not to be as natural as they should be. Another way to do this, but not so elegantly, would be to create an application to align the devices, so, when the HoloLens application connects to this app, the application enters the "alignment mode". HoloLens speaks, prompting the user to pick up one of the Live controllers and cross it with a floating 'ghost' controller. Once the actual and holographic controllers are aligned, the user pulls the trigger and the voice proudly announces, "You are now aligned." There is no limit to how many physicians can participate.
  2018 Paper No. nnnn Page 9 of 11

 Figure 11: HoloLens on the left and Vive on the right. HoloLens identifies the position of Vive and projects the heart model into the environment in order to share it with Vive.
5 CONCLUSIONS AND FUTURE WORK
In this work, a system was proposed for the visualization of a virtual model of a 3D heart from a coronary tomography, presented in a real time shared holographic experience. None of the reviewed solutions can deliver this kind of functionality, probably due the novelty of these kind of devices. As a result, a collaborative medical environment is provided to support inspecting and diagnostic solution. The virtual and Augmented Reality environments can easily be combined, so doctors can share a unique virtual space.
At the end of this project, it is expected a functional standalone application will arise that is capable of performing all of the proposed objectives. The capacity to simultaneously visualize images created through experiments using Holograms have shown that the coupling of these techniques of visualization has the potential to reduce the learning curve of users, since it changes the mode in which it collaborates among different professional specialists by considering the proposal of the simulation. Further tests will be applied to determine the effectiveness of the application and add/fix features as demanded by potential users.
ACKNOWLEDGEMENTS
The authors want to thank CAPES and CNPq for financial support.
REFERENCES
International Telemedical Systems (ITMS). “Telemedicine”. Available at: <http://www.itms.cl/>. Access in: 09/05/2017.
CDC, NCHS. Underlying Cause of Death 1999-2013 on CDC WONDER Online Database, released 2015. Data are from the Multiple Cause of Death Files, 1999-2013, as compiled from data provided by the 57 vital statistics jurisdictions through the Vital Statistics Cooperative Program. Accessed Feb. 3, 2015.
S. Scalvini. “Applications of Telecardiology: Recommendations for its Use in Practice.” Imaging Management. Vol. 4, 2010.
Preim , B. ; Bartz, D. Visualization in Medicine: Theory, Algorithms, and Applications. Elsevier. 2007.
Radiological Society of North America. “Coronary Computed Tomography Angiography (CCTA)”. Available at: <https://www.radiologyinfo.org/en/info.cfm?pg=angiocoroct>. Accessed 09/05/2017.
2018 Paper No. nnnn Page 10 of 11
MODSIM World 2018

Lorensen, W. E.; Cline, H. E. “Marching Cubes: A High Resolution 3D Surface Construction Algorithm”. In: Computer Graphics, Vol. 21, Nr. 4, July 1987.
Akio Doi, Akio Koide. "An Efficient Method of Triangulating Equi-Valued Surfaces by Using Tetrahedral Cells." IEICE Transactions of Information and Systems, Vol.E74-D No. 1, 1991.
Nema. “Dicom Specification PS3.1 2015a”. Available at: <http://dicom.nema.org/standard.html>. Access in: 23/03/2017.
Medical Life Science. “What is Telecardiology?”. Available at: <http://www.news-medical.net/health/What-is- Telecardiology.aspx>. Access in: 09/05/2017.
BURDEA, G. & COIFFET,P. (1994) - Virtual RealityTechnology. John Wiley & Sons, New York, NY, 1994.
Cardoso, A. Lamounier, E. “A Realidade Virtual na Educação e Treinamento” In: Fundamentos e Tecnologia de Realidade Virtual e Aumentada. VIII Pré-Simpósio de Realidade Virtual e Aumentada, Belém, 2006, pp. 304-312.
MOON, Inkyu; JAVIDI, Bahram. 3-D visualization and identification of biological microorganisms using partially temporal incoherent light in-line computational holographic imaging. IEEE transactions on medical imaging, v. 27, n. 12, p. 1782-1790, 2008.
Microsoft. “Microsoft HoloLens”. Available at: <https://www.microsoft.com/microsoft-hololens/en-us>. HTC. “VIVE”. Available at: < https://www.Vive.com/us/>. Access in: 09/05/2017.
Microsoft. “Shared holographic experiences”. Available at: <https://developer.microsoft.com/en-us/windows/mixed- reality/shared_holographic_experiences>. Access in: 09/05/2017.
Microsoft. “Holograms 240”. Available at: <https://developer.microsoft.com/en-us/windows/mixed- reality/holograms_240>. Access in: 09/05/2017.
CTI. “InVesalius”. Available at: <http://www.cti.gov.br/invesalius/?lang=pt>. Access in: 23/03/2017.
FEI. “Amira & Avizo - 3D Software for Scientific and Industrial Data | FEI”. Available at: <view- source:https://www.fei.com/software/amira-avizo/> . Access in: 23/03/2017.
G. M. Treece, R. W. Prager, A. H. Gee et al. “Fast surface and volume estimation from non-parallel cross-sections, for freehand 3-D ultrasound.” Medical Image Analysis 3(2), pp. 141–173, 1999.
Osirix. “OsiriX | The world famous medical imaging viewer”. Available at: <http://www.osirix-viewer.com/>. Access in: 23/03/2017.
Weiskopf, Daniel. GPU-Based Interactive Visualization Techniques. Springer Science & Business Media. p. 21. ISBN 978-3-540-33263-3.2007.
Lacroute, Philippe; Levoy, Marc (1994-01-01). "Fast Volume Rendering Using a Shear-warp Factorization of the Viewing Transformation". Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques. SIGGRAPH '94. New York, NY, USA: ACM: 451–458. doi:10.1145/192161.192283. ISBN 0897916670.
Westover, Lee Alan (July 1991). "SPLATTING: A Parallel, Feed-Forward Volume Rendering Algorithm. Available at: < http://www.cs.unc.edu/techreports/91-029.pdf> Accessed 22/11/2017.
Hibbard W., Santek D., "Interactivity is the key", Chapel Hill Workshop on Volume Visualization, University of North Carolina, Chapel Hill, 1989, pp. 39–43.
Unity. “Unity”. Available at: <https://unity3d.com/pt>.Acessed 22/11/2017.
NVIDIA. “NVIDIA OpenGL SDK 10 Code Samples”. Available at <http://developer.download.nvidia.com/SDK/10/opengl/samples.html> . Acessed 22/11/2017.
2018 Paper No. nnnn Page 11 of 11
MODSIM World 2018
