Use of Real-Time, Predictive Human Modeling for Spatial Disorientation Detection and Mitigation
Ronald Daiker, Dr. Kyle Ellis
National Aeronautics and Space Administration Hampton, VA ronald.j.daiker@nasa.gov, kyle.k.ellis@nasa.gov
ABSTRACT
Dr. Santosh Mathan
Honeywell, Inc. Redmond, WA santosh.mathan@honeywell.com
The National Aeronautics and Space Administration (NASA) is conducting research into the utilization of real-time human characterization models for the prediction and mitigation of flight crew Spatial Disorientation (SD) through customized alerting solutions. Despite rapidly evolving flight deck technologies over the past fifty years, reported occurrences of flight crew SD have not decreased.
Under the Technologies for Aircraft State Awareness sub-project, NASA researchers have partnered with experts in the field of flight crew SD research from academia and private industry to develop a human software model for the real-time prediction of flight crew SD. Using a combination of a human-vestibular system model, aircraft dynamics, and physiological sensors, a characterization model was developed to estimate the discrepancy between perceived aircraft state (via eye tracking and other devices) for comparison against state data from the avionics system in order to detect flight crew SD.
The Cost Effective Devices for Alerting Research (CEDAR) study seeks to build upon this work using the human SD software model to trigger salient alerting solutions which have been customized to meet the current attentional demands of the flight crew. This research is intended to develop a proof-of-concept for real-time SD mitigation which could eventually be utilized to improve safety in future air transport operations. This paper will discuss the details of how the proposed system will function, including the current state of this research and directions for future work.
ABOUT THE AUTHORS
Ronald Daiker is a Technical Lead and Research Engineer in the Crew Systems and Aviation Operations Branch at the NASA Langley Research Center in Hampton, VA. Much of his career has been spent applying Human Factors principles to the design, testing, and certification of flight deck user interfaces for a variety of fixed and rotary wing aircraft. Since joining NASA, he has contributed to a number of research activities spanning a variety of topics, including function allocation between humans and automated systems, NextGen separation assurance, battlefield human-autonomous teaming, the detection and mitigation of flight crew spatial disorientation, and flight deck design. Mr. Daiker is interested in new and innovative technologies which improve aviation safety and efficiency.
Dr. Kyle Ellis is a Technical Lead and Research Engineer in the Crew Systems and Aviation Operations Branch at the NASA Langley Research Center in Hampton, VA. He has performed extensive research in the field of human factors and aviation, with over 14 years of experience in the conduct of human subject research, experiment design, and aeronautics. He is a technical expert in the fields of eye tracking, psychophysiometrics, systems integration, avionics, airspace operations, statistics, and machine learning.
Dr. Santosh Mathan is an Engineering Research Fellow at Honeywell Aerospace in Redmond, WA. His research at Honeywell ranges from computational neuroscience to aviation system development and safety research. This work, in collaboration with academic and industrial collaborators around the world, has led to algorithms that detect variations in attention and workload using sensors, identification of signatures associated with injury-related compromised cognitive function, and brain computer interfaces that are the first to control aircraft in-flight. He has also led the development of pilot-centered user interfaces for systems ranging from autopilots and weather radar, to air traffic control display systems and decision aids. Santosh has a PhD in Human Computer Interaction from the School of Computer Science at Carnegie Mellon University and is an instrument-rated commercial pilot.
2018 Paper No. 14 Page 1 of 10
MODSIM World 2018

Use of Real-Time, Predictive Human Modeling for Spatial Disorientation Detection and Mitigation
Ronald Daiker, Dr. Kyle Ellis
National Aeronautics and Space Administration Hampton, VA ronald.j.daiker@nasa.gov, kyle.k.ellis@nasa.gov
INTRODUCTION
Dr. Santosh Mathan
Honeywell, Inc. Redmond, WA santosh.mathan@honeywell.com
NASA is conducting research into technologies which have the potential to reduce pilot Spatial Disorientation (SD). While flight deck technology has advanced rapidly over the past fifty years, the reported occurrences of flight crew SD have not decreased. This research effort has been named CEDAR (Cost-Effective Devices for Alerting Research), and is focused on the identification and development of low cost, user-centered alerting solutions for the purpose of mitigating the occurrence of pilot SD.
Spatial disorientation has been defined as “an erroneous sense of one’s position and motion relative to the plane of the earth’s surface”. This erroneous sense stems from the “incorrect perception in magnitude/direction of any of the aircraft control and performance flight parameters” (Gillingham, 1992). Control parameters under this definition refer to aircraft attitude and engine power parameters, while performance parameters refer to vertical speed, altimeter, and heading. This definition is broad enough to encompass energy situation awareness: “the ability to know and control the complex combination of the aircraft’s airspeed and speed trend, altitude and vertical speed, configuration, and thrust” (Jacobson, 2010) as the sources of information relevant to both SD and loss of energy state awareness (LESA) phenomenon are common to both.
The research activities summarized here have been motivated by the observation that the incidence of loss of control events (LOC) stemming from SD and LESA appear to be increasing, even as the overall safety of Part 121 and Part 25 operations continues to improve. Research indicates that spatial disorientation and loss of energy situational awareness account for 32% and 19%, respectively, of 34 LOC accidents over the last decade (Bateman, 2010). These statistics (see Figure 1) are a matter of rising concern as commercial air traffic growth shows little sign of slowing, and accident data suggests that newer airplanes are also vulnerable to these problems.
2018 Paper No. 14 Page 2 of 10
MODSIM World 2018

 Figure 1. Causes of aviation fatalities in commercial jet fleet (Boeing, 2015)
In light of these statistics, the importance of prognostic analyses for identifying future risks for loss of control precursors such as SD is being widely recognized in the aviation safety community. For example, Belcastro and Foster (2010) have raised the importance of identifying currently unforeseen risks for loss of control incidents that may materialize in the context of NextGen operations risks whose causal bases may not be represented in prior accidents. Unfortunately, the latest generation of air transport and business aircraft with display and control features that have not been scrutinized extensively by the aviation research community for vulnerability to SD, additionally these aircraft lack an accident and incident record from which to draw meaningful inferences about SD vulnerability.
Gibb, Ercoline & Scharff (2011) present a review of the accidents and incidents related to pilots’ SD as foundation for renewed call to action. They cite a 2002 keynote address at the “Research and Technology Organization, Human Factors and Medicine Symposium on Spatial Disorientation in Military Vehicles: Causes, Consequences and Cures” that emphasized the continued role of SD in aviation accidents and incidents for 50 years; underscoring that, despite improved understanding of its etiology and enhanced pilot displays, SD has killed pilots since 1913 and continues to do so. Gibb et al., (2011) state that, despite the fact that today’s pilots have instruments/visual displays to help maintain orientation, it is apparent that aviation’s extreme demands on pilots exceed human sensory-perceptual-cognitive capabilities, even with new technology. In fact, they observed, at times the new technology plays a contributing factor in SD. SD-related mishaps still occur, and unfortunately, SD is often not formally recognized as a contributing factor in mishaps, and accidents are differentially classified otherwise, e.g., “visual illusion” or “loss of control” (LOC). Gibb presented an assessment of visual spatial disorientation at 2010 annual Aerospace Medical Association conference and cited 25 studies dating from 1947 that illustrated SD’s role in mishaps as well as surveys of pilots anonymously sharing their SD experiences. Most striking across all the data from various countries and researchers was the consistency over the years — SD rates are not decreasing.
In December 2014, as a result of analyzing 18 loss-of-control events, the Commercial Aviation Safety Team (CAST) recommended research into flight deck technologies that have potential to mitigate the problems and contributing factors that lead to flight crew loss of airplane state awareness (ASA) and conditions likely to produce spatial disorientation. The aviation community (government, industry and academia) has been charged with conducting research in the following areas:
1. Assess the relative benefits associated with various methods of displaying angle-of-attack on the flight deck.
2018 Paper No. 14 Page 3 of 10
MODSIM World 2018

2. Develop and refine algorithms and display strategies to provide control guidance for recovery from approach-to- stall or stall.
3. Develop and refine systems that predict the future aircraft energy state and/or autoflight configuration if the current course of action is continued and provide appropriate alerting.
4. Cost-effective, user-centered flight deck alerting systems to alert flight crews, especially for the two conditions that produced spatial disorientation in the ASA event data set (sub-threshold rolls and the somatogravic illusion).
They suggest this research should raise the technology readiness level (TRL) of these features to a level that enables cost-effective implementation and certification of these technologies. This work supports the NASA Airspace Operations and Safety Program (AOSP), System-Wide Safety (SWS) Project, Technologies for Aircraft State Awareness (TASA) Sub-Project in support of CAST’s Safety Enhancement #207, Outcome #4.
The TASA Cost-Effective Devices for Alerting Research (CEDAR) effort is tasked with identifying safety enhancements capable of providing salient alerting solutions to pilots and flight crew operating aircraft while in a state of SD. This research will give special consideration to combating two types of SD illusions in particular; somatogravic illusions and the sub-threshold roll illusion. Somatogravic illusions are defined as illusions in which “there is a false perception of attitude on exposure to a force vector that differs in direction and/or magnitude from the normal gravitational force” (Benson, 1999). The sub-threshold roll illusion (aka the “leans”) is a false sensation of roll attitude (Benson 1999). A prolonged roll can create the illusion that the aircraft’s wings are level. In both of these SD illusions, it is when the pilot attempts to correct the aircraft’s attitude that problems arise, sometimes with lethal consequences.
MODEL
NASA has partnered with experts in the field of flight deck SD to conduct research into the utilization of real-time human characterization models for the prediction and mitigation of pilot SD through customized alerting solutions. Honeywell, Inc., working in collaboration with researchers from the Georgia Institute of Technology, implemented an overarching model that integrates models of the vestibular system, instrument scanning behaviors, and aircraft dynamics to estimate a pilot’s sense for aircraft orientation and dynamics. The Model-Based Observer is a computational model developed under a previous NASA-funded effort (led by Dr. Ellis), which serves as the basis for the Predictive Alerting (PA) concept described later (Pritchett et al., 2014). NASA’s CEDAR effort sought to modify the MBO to incorporate it with an alerting capability in order to create a Predictive Alerting Model (see Figure 2).
Figure 2. Predictive Alerting Model (PAM)
MODSIM World 2018
 2018 Paper No. 14 Page 4 of 10

Humans rely primarily upon two sensory systems to determine their current orientation and motion: the visual and the vestibular. Human estimation of aircraft state is grossly compromised when visual cues are deficient. Under these conditions a pilot must rely on a combination of cues provided by the vestibular system, and an internal representation of aircraft state. To effectively infer human operator perception in real-time, a detailed model of the human vestibular system is necessary, as is a model that represents the pilot’s internal representation of aircraft dynamics. Located in the inner ear, the vestibular system perceives self-motion and is a primary input to postural control (Angelaki, et al., 2008). Over the past century, aviation’s three dimensional maneuvers have subjected the human vestibular system to forces which it was not evolved to accurately interpret (Gillingham, 1966). Prolonged maneuvers, constantly changing accelerations, and a wide range of maneuver rates can cause illusions and, thus, misinterpretation of the actual orientation (Previc & Ercoline, 2004). The vestibular models employed for this effort incorporated elements from a large body of research in this area (Previc & Ercoline, 2004; Merfeld et al, 1990, 1993, 2002; Grant & Best, 1986).
The outputs of the vestibular system are mediated by a pilot’s internal estimate of the state of the aircraft under his or her control. Hence, a model of the best-possible pilot expectation, under varying levels of deficits in visual cues, needs to complement a model of the vestibular system with an “internal simulation” of the aircraft dynamics, i.e., is a Model- Based Observer (MBO). The estimated state within the MBO is propagated with the help of an accurate linear model of the aircraft dynamics, and is updated continuously by the vestibular system model and at discrete intervals by visual sampling. To optimally combine both continuous-time and discrete-time measures, the MBO employs a Hybrid Extended Kalman Filter design.
Figure 3. The MBO - Model of aircraft dynamics and pilot's best possible expectations
MODSIM World 2018
 2018 Paper No. 14 Page 5 of 10

The MBO is tightly coupled to an aircraft simulation that describes the dynamics of the system (see Figure 3). The solid line signal paths illustrate continuous-time signals while the dashed lines illustrate discrete-time signals. The MBO assumes a model of the aircraft dynamics as shown in label (1) propagates the aircraft state vector (x) with additive process noise (w), weighted by (G), that has zero mean and a covariance of (Q). The measured or observed state variables, label (2), account for the measurement errors (v). The continuous path carries the continuous signals coming from the vestibular system measurements (yc). In the continuous case, measurement error is the vestibular sensors error denoted by (vc). The discrete path carries the discrete signals due to the discrete visual measurements (yd). In the discrete case, measurement error comprises the errors due to aircraft’s sensor error, errors due to the design of the flight instrument, and errors due to pilot’s perception of the scanned instrument. Label (3) is the “internal simulation” of the aircraft dynamics maintained by the pilot (xest) as simulated with a linearized model of the aircraft. The measurement values that would be expected from xest, indicated as yest, are compared with the actual measurements y, and the discrepancy, shown in label (4), is weighted by the Observer gain to correct xest.
When the MBO is run off-line for computational analysis, the visual scan model represents hypothesized pilot scans of the flight instruments; when run in real-time, the visual scan model can instead be informed by an eye tracker when a pilot visually samples specific flight instruments. The visual scan model provides a set of values to the MBO representing visual samples of any flight instrument: yD, the measurement made by the visual sample; RD, the assumed variance in additive measurement error ε ~N(0,RD) added to yD; and yD’s immediate linear relationship to state as represented by the measurement matrix CD.
The instrument scan patterns or behaviors are modeled by visual-scanning actions. Each visual-scanning action is a discrete measurement of the aircraft’s state. These instrument-scanning actions may occur synchronously or asynchronously, and at high or low frequencies.
For the purpose of this model, instrument-scanning behaviors are classified into four categories:
1. T Scan: The ideal T scan will represent the optimal instrument scan a pilot can implement: a continuous, high frequency scan of the primary flight instruments. This scan pattern may be degraded by occurring at lower frequencies. 2. Omission: The first varied scan will implement a T scan at a high frequency, but omits one instrument from the T scan throughout a particular scenario (e.g., pilot fails to monitor the airspeed indicator, or the airspeed indicator has failed). This type of scan will have four variants, excluding a different instrument from the T scan each time. Again, the frequency of each scan can be varied.
3. Emphasis: The second varied scan will consider scanning three flight instruments at a low frequency while scanning the remaining instrument at a high frequency (i.e., putting an emphasis on this particular instrument). Again this will have four variants with each having a different ‘high frequency’ instrument. Here both the ‘high’ and ‘low’ frequencies can be varied.
4. Distraction: The third instrument-scanning behavior category, distraction, will represent a distinct period where the pilot stops monitoring all instruments. Outside of this period, the pilot will apply a high-frequency T scan. In this case, the distraction period will start just before the onset of a key maneuver and its duration will be varied.
Figure 4 illustrates the relationship between the visual information presented to the pilot (by flight instrument), the estimates of the vestibular model (consisting of SCC and Otolith sub-models), and the elements of aircraft state estimates.
2018 Paper No. 14 Page 6 of 10
MODSIM World 2018

 Figure 4. Relationship between visual information, vestibular system estimates, and elements of aircraft state estimate
The model described above can provide the basis for estimating discrepancies between pilot perception of aircraft orientation and dynamics, and aircraft state. The model will likely show little discrepancy between expectations and reality when instruments are being scanned appropriately, particularly when the aircraft is in a stable state. In the absence of appropriate scanning behaviors, we would expect model estimate of discrepancy to be more pronounced, particularly when the aircraft is actively maneuvering. Figure 5 illustrates estimates of pilot expectation and aircraft state as a function of scanning behaviors.
Figure 5. Roll rate and its expectation during a sub--threshold bank maneuver (Distraction from 3 to 15 seconds - No visual scanning at beginning of maneuver)
MODSIM World 2018
 2018 Paper No. 14 Page 7 of 10

PREDICTIVE ALERTING MODEL
Through the TASA CEDAR effort, the models described above were modified and incorporated into an overarching model developed to alert pilots and flight crew who may be operating aircraft in a state of spatial disorientation (as shown in Figure 2). The Predictive Alerting Model (or PAM) has the potential to accurately predict and alert pilots through a powerful combination of passive sensors (i.e. eye tracking), predictive human characterization modeling, and adaptive alerting.
The PAM could one day be applied to modern commercial air transport aircraft, becoming fully integrated with the avionics system. The model is capable of running continuously in the background, ready to provide flight crew with real-time alerts when a high likelihood of SD is predicted. The fully integrated nature of the model presents several interesting opportunities for highly customizable flight deck alerting.
The alerting thresholds within the model can be customized based on a number of system parameters to create adaptive alerting solutions. For example, the alerting threshold for an operator who is manually controlling the aircraft could be lower than that for an operator who is utilizing automated controls (i.e. autopilot), due to the increased likelihood of a LOC event during manual control. Under automated control, a higher alerting threshold can be used to reduce the occurrence of nuisance alerts, or mute SD alerts altogether.
Figure 6 illustrates how the PAM may be used to mitigate SD illusions (specifically, a case of somatogravic illusion). Once the discrepancy between the operator’s expectations and reality exceeded a pre-determined threshold, an alert was triggered. This alert effectively notified the operator to the discrepancy, who then re-established the visual scan pattern and regained situational awareness. In addition to eye tracking data, the PAM can also use data from the avionics system to measure the time at which an operator has become aware of the SD illusion and made appropriate corrections. For example, a course correction made using the Flight Mode Control (FMC) panel or manual control inputs could be used as a secondary means for terminating a SD alert.
Figure 6. Somatogravic illusion: pitch-up sensation - Pitch angle and its expectation during and acceleration (no pitch) maneuver (Distraction from 15-30 sec).
Adaptive alerting enables the PAM to provide the most salient forms of alerting to the operator for a given situation. The advent of glass cockpit display systems makes it possible to place visual alerts in many more locations than previous technologies allowed. This new technology, when paired with a combination of real-time eye tracking data,
MODSIM World 2018
 2018 Paper No. 14 Page 8 of 10

the model of pilot perception described above, and estimates of aircraft state and trend at a given moment can serve as the basis for estimating the likelihood of pilot disorientation and offer timely and context specific recovery cues. For example a gradual steep turn that accompanies appropriate visual scanning behaviors would lead to the model of pilot perception and reality to overlap – allowing the system to defer alerts to the default bank limit. However, in the absence of appropriate scanning behavior, the real-time estimate of aircraft state will diverge from the actual state of the aircraft. A threshold based on the error between the model and reality can allow earlier alerting – well ahead of an unsafe attitude. Modern glass cockpits enable the placement of highly effective visual alerts within the operator’s primary field of view and supplement these with aural warnings. For example, if a pilot becomes distracted while focusing on an auxiliary display, the system (informed by eye tracking data) can adapt to place the alert on the auxiliary display for increased saliency.
Adaptive alerting also allows for varying levels of alert intensity and duration, depending upon the situation. If eye tracking data indicates a distracted pilot who does not respond to routine aural and visual alerts, the intensity of such alerts can be increased (i.e. flashing, volume) or the duration can be extended until the pilot has been alerted. Alerting modalities can also be varied in order to improve saliency, by customizing the form of alert to a given situation.
The fully integrated nature of the system makes it possible to monitor pilots’ sensory channels for saturation and target an alerting modality which is capable of being received and interpreted by the pilot. For example, if the pilot’s aural sensory channel is already saturated by heavy radio communications, an alternate alerting modality may be selected (i.e. visual, haptic, etc.) to increase saliency.
FUTURE WORK
An alerting prototype was developed and integrated into NASA and Honeywell simulators as a proof of concept for real-time human modeling for SD detection and mitigation. This prototype effectively illustrates the usefulness of model-based adaptive alerting within the context of commercial air carrier operations. The model will require more development before it is able to undergo the verification and validation testing necessary in order to transition from concept prototype into a functional flight deck for real-time applications. Additional studies aimed at refining the concept through focus groups, human-in-the-loop experiments, and flight testing must be performed in order to eventually field the system.
While eye tracking was incorporated into this initial prototype, the model is capable of ingesting and interpreting data from multiple physiological monitoring sources simultaneously to more accurately characterize the human operator. Incorporation of these physiological data sources will require research into how best to utilize this new data, in addition to requiring updates to the model.
CONCLUSION
The research effort detailed herein is intended to serve as a proof of concept for the utilization of human characterization models for adaptive alerting and SD mitigation. As previously identified, SD cases are not decreasing, which poses a significant risk to aviation safety. Pilots experiencing SD illusions are often incapable of recognizing it themselves, which is why the powerful combination of physiological monitoring paired with human model-based prediction has the potential to accurately predict and notify pilots before it is too late to ultimately improve the safety of flight.
ACKNOWLEDGEMENTS
The authors would like to thank the NASA System Wide Safety project for funding this research, researchers from Honeywell, Inc. and the Georgia Institute of Technology for their dedicated research and development efforts, and the Commercial Aviation Safety Team (CAST) for the impetus and scope for this and other research into promising new technologies that will one day improve the safety of aviation.
REFERENCES
Angelaki, D., & Cullen, K. (2008). Vestibular system: The many facets of a multimodal sense. Annual Review of Neuroscience, 31, 125-150.
2018 Paper No. 14 Page 9 of 10
MODSIM World 2018

Bateman, D. (2011, March). Some thoughts on reducing the risk of aircraft loss of control. Paper presented at the 23rd Annual European Aviation Safety Seminar (EASS). Istanbul, Turkey.
Belcastro, C. & Foster, J. (2010, August). Aircraft loss-of-control accident analysis. Paper presented at the AIAA Guidance, Navigation, and Control Conference. Toronto, Ontario.
Benson, A. (1999). Spatial disorientation – common illusions. In J. Ernsting, A.N. Nicholson, D.J. Rainford (Eds.), Aviation medicine (3rd Ed., pp. 437-481). Oxford: Butterworth Heinemann.
Boeing. (2015). Statistical summary of commercial jet airplane accidents worldwide operations | 1959– 2015. Retrieved from
http://www.boeing.com/resources/boeingdotcom/company/about_bca/pdf/statsum.pdf
Gibb, R., Ercoline, B., & Scharff, L. (2011). Spatial disorientation: Decades of pilot fatalities. Aviation Space &
Environmental Medicine. 82(7), 717-724.
Gillingham, K. (1992). The spatial disorientation problem in the United States Air Force. Journal of
Vestibular Research, 2, 297-306.
Grant, J., & Best, W. (1986). Mechanics of the otolith organ-dynamic response. Annals of biomedical
Engineering, 14(3), 241-256.
Jacobson, S. (2010, August). Aircraft Loss of Control Causal Factors and Mitigation Challenges. Paper presented at
the AIAA Guidance, Navigation, and Control Conference, Toronto, Ontario.
Merfeld, D. (1990). Spatial Orientation in the Squirrel Monkey: An Experimental and Theoretical Investigation
(Doctoral dissertation). Massachusetts Institute of Technology. Cambridge, MA.
Merfeld, D., Young, L., Oman, C., & Shelhamer, M. (1993). A multidimensional model of the effect of
gravity on spatial orientation of the monkey. Journal of Vestibular Research, 3, 141–161. Merfeld, D., & Zupan, L. (2002). Neural processing of gravitoinertial cues in humans. III. Modeling tilt and
translational responses. Journal of Neurophysiology, 87, 819–833.
Previc, F.H., & Ercoline, W.R. (2004). Spatial disorientation in aviation (Vol. 203). Reston, VA: American Institute
of Aeronautics and Astronautics.
Pritchett, A., Feigh, K., Kim S., & Kannan, S. (2014). Work models that compute to support the design of
multi-agent concepts of operation. Journal of Aerospace Information Systems, 11, 610-622.
United States Air Force. (1966). Aeromedical Reviews – A Primer of Vestibular Function, Spatial Disorientation,
and Motion Sickness. (USAF Publication No. AD637943).
United States Air Force. (1993). Spatial Orientation in Flight. (USAF Publication No. AL-TR-1993-0022).
2018 Paper No. 14 Page 10 of 10
MODSIM World 2018
