Evolution of Green Pig: Best Practices in Mobile App Design
Ashley Reardon, Julian Abich IV, Jennifer Murphy, Frank Hannigan Quantum Improvements Consulting LLC
Orlando, FL
areardon, jabich, jmurphy, fhannigan@quantumimprovements.net
ABSTRACT
From conception to implementation, the development of a well-designed training system requires effective communication and tactful compromise within a multidisciplinary team of instructional designers, user experience experts, software developers, stakeholders, and end users. The design process applies even to seemingly trivial design choices. In this paper, we describe the process implemented to design a mobile application to train financial literacy. Taking a user-centered design approach, the team worked with customers, subject matter experts, and end-users to gather contextual information and design requirements specific to the users’ needs. To strengthen the bond between the users and the tool, financial concepts were re-imagined in the voice of a relatable mentor, akin to a trustworthy and knowledgeable friend, named Green Pig. What started initially as a mechanism for mobile immersion quickly emerged as its own entity capable of taking on multiple guises. In this presentation, the journey of Green Pig is used as a metaphor for the evolution, de-evolution, and resolution of the mobile-app design process. The goal for this paper is to provide a description of the iterative development process to understand the barriers that challenged success, how they were overcome, and what it takes to be established in today’s overcrowded world of training systems and mobile applications.
ABOUT THE AUTHORS
Ashley Reardon is a Human Factors Engineer Intern at Quantum Improvements Consulting LLC, where she applies her background in psychology, modeling and simulation and instructional design to understand and improve human performance. Her current research focuses on applying user-centered design and mobile application best practices to the development of an adaptable mobile application for financial literacy training. She holds a B.S. in Psychology and is a M.S. candidate for Modeling and Simulation at the University of Central Florida. She is also a candidate for the Graduate Certificate in Instructional Design for Simulations.
Julian Abich IV, Ph.D., is a Senior Human Factors Engineer at Quantum Improvements Consulting, LLC He has over 10 years focused on applying human factors, ergonomics and modeling & simulation principles to the assessment, prediction, and improvement of human performance. His current research efforts focus on the application of human performance data from complex training systems for improving training efficiency and effectiveness and enhancing human-system interaction. He holds a Ph.D. in Modeling and Simulation with a specialization in Human Factors from the University of Central Florida.
Jennifer Murphy, PhD., is the CEO of Quantum Improvements Consulting, LLC. She has over 12 years of military selection and training research experience, with an emphasis on leveraging innovative technologies for improving training in a measurably effective way. Her current research focuses on developing assessments of Warfighter performance to enable adaptive training, predictive modeling, and improved training effectiveness. She holds a PhD in Cognitive and Experimental Psychology from the University of Georgia.
Frank Hannigan is the Chief Operating Officer of Quantum Improvements Consulting, LLC. He has over 10 years of experience applying human factors and systems engineering principles and methods to the design of expert system displays and training curricula. Frank holds a M.S. in Human Factors & Systems from Embry-Riddle Aeronautical University and B.S. in Aviation Science from Saint Louis University. Frank's research interests are rooted in human performance with respect to automation increases and technology enhancements, whether on the battlefield, in the cockpit, or in the classroom.
2018 Paper No. 23 Page 1 of 10
MODSIM World 2018

Evolution of Green Pig: Best Practices in Mobile App Design
Ashley Reardon, Julian Abich IV, Jennifer Murphy, Frank Hannigan Quantum Improvements Consulting LLC
Orlando, FL
areardon, jabich, jmurphy, fhannigan@quantumimprovements.net
INTRODUCTION
The ubiquitous use of mobile devices lends itself to an advanced training platform that can deliver portable, personalized and just-in-time content. To deliver effective training to users, experts skilled in pedagogy and instructional design must collaborate with experts in software development and mobile application design. To create a usable training tool, the user should be placed in the center of the design process thereby emphasizing a user-centered design approach (Bannon, 1991). User-Centered Design (UCD) has become increasingly important in facilitating greater satisfaction and therefore greater use in human-computer interactions. In a UCD process, the user’s needs are analyzed and integrated in all stages of the design process, leading to an intuitive, enjoyable, and efficient system (Brhel, Meth, Maedche, & Werder, 2015). Merging UCD with the popularly used Agile process lends support to an iterative and user-focused refinement of design throughout the development cycle to ensure training is not only useful, but usable (Constantine, 2002). Current research on training development utilizing mobile applications is quick to emphasize issues and their solutions that are framed from a developer’s perspective (Zhang & Adipat, 2005), or from an instructional designer’s perspective (Park, 2011), yet minimal research exists that combines both perspectives into a cohesive development framework. Multidisciplinary teams are becoming the norm in science and engineering, therefore research is needed that targets effective collaboration within diversity of knowledge expertise, known as knowledge diversity. When properly utilized, knowledge diversity is implicated to be a positive factor and critical to complex performance (Klein, 2005; Paletz & Schunn, 2009). While knowledge diversity has been shown to positively impact innovation, it has also been found to increase unproductive conflict that can create a divergence from a shared vision (Kurtzberg & Amabile, 2000). To mitigate these negative implications, multidisciplinary collaboration should incorporate synergistic communication methods. Gerbert, Boener, and Kearney (2006) define synergistic communication as “the extent to which diverging positions are specified and recombined to generate new and useful solutions.” Even when properly integrated, communication gaps are likely to occur, creating challenges that can thwart development, like conflicting opinions, conveying the need for user testing, and managing different perspectives. In this paper, we describe the development process of a mobile training tool called Sen$e, to examine the multidisciplinary challenges that may emerge when promoting a synergistic team. To offer a unique perspective on these multidisciplinary challenges, we introduce Green Pig, a pedagogical character, as a metaphor for adapting to and overcoming prospective challenges in the development process. The development of Sen$e was shaped by a distinct need to close the gap in military financial literacy. Specifically, a user-friendly mobile application would be developed to support Service members and their families with financial readiness information using microlearning, gamification, and other motivational techniques to cultivate life-long learning.
Green Pig emerged out of a need to create motivation and engagement within Sen$e. Pedagogical characters or “agents” are prevalent in eLearning environments. These agents can enhance the learning environment when used as a tool to facilitate effective communication between humans and machines. Knowledge is socially constructed, and humans learn through vicarious experiences (Bandura, 1977), therefore when used appropriately, agents can help create meaningful and effective learning experiences (Hietala & Niemirepo, 1998; Veletsianos, Miller, & Doering, 2009). Pedagogical agents offer many benefits such as modeling human behaviors to serve as a role model (Rosenberg- Kima et al., 2008), taking on the role of a mentor or instructor to breakdown complex tasks (Johnson, Rickel, Stiles, & Munro, 1998), personalizing learning experiences, and increasing user motivation by creating a more entertaining, likeable, and engaging environment (Johnson, Rickel, & Lester, 2000; Gulz, 2004). Pedagogical agents differ in their visual appearance, ranging from human-like (visual naturalism) to cartoon-like (stylized), and from dynamic to static. Together, these qualities add up to the total visual experience, or the innate behavioral and attitudinal response that occurs as a result of the visual appearance (e.g., facial shape, body and costume, graphical style) of others (Gulz & Haake, 2006). Naturalistic agents provide a means of intuitive communication since it is easy for us to relate to other
2018 Paper No. 23 Page 2 of 10
MODSIM World 2018

humans, whereas stylistic agents can be easier for us to identify with. Similar to how we find ourselves identifying with popular cartoon and comic book characters, stylized agents offer an ambiguity that invites user elaboration for a more subjective and personalized experience.
Green Pig was designed as a stylistic agent that would borrow naturalistic elements by adding anthropomorphic features. Since humans can easily communicate and relate to other humans, by anthropomorphizing non-human objects, we begin to draw parallels between unlike things (Laurel, 1997). Using an anthropomorphic agent should theoretically increase the ‘bond’ between the user and tool, thereby enhancing the training and learning experience. In Baylor’s (2000) requirements for designing a mentor agent, he recommended using an anthropomorphic approach where agents took on the role of a character, akin to an actor in a film. The agent should have an educationally appropriate persona and provide feedback and reassurance (Baylor, 2000). It should also be dynamic, trustworthy, honest, cooperative, and expressive. By following these guidelines, Green Pig was created. Initially, Green Pig had a simple persona of a responsible and trustworthy financial pal who lived within the walls of the application to translate dense financial information into user-friendly learning. Over time, Green Pig grew and shrank in complexity, leaving behind a trail of colorful personas like, ‘Wizard Green Pig’, ‘Snow Day Green Pig’, and ‘Surfer Green Pig’ (Figure 1).
Figure 1. Introducing Green Pig
Each design iteration revealed new challenges and lessons learned that could be applied to the broader understanding of the multidisciplinary process of mobile application design and development. In an effort to shed light on the higher- level considerations for training tool development, these iterations will be used as a case study. The purpose of this paper is to not only provide an overview of how mobile training was designed, but to explore the multidisciplinary challenges that emerge through the perspective of Green Pig, and to offer unique guidelines to support future efforts in multidisciplinary teams. A summary of the lessons learned for each challenge discussed will be presented as a Today I Learned (TIL) component. These lessons are provided based on the authors experience working on the design team and they serve as a metaphor for each stage of Green Pig’s growth.
The Team and The Process
A design team, comprised of human factors experts and instructional designers, and a development team, comprised of software engineers, worked in unison to develop a mobile training tool to support financial literacy called Sen$e. These two teams were led by the direction of the stakeholders, Advanced Distributed Learning (ADL) and the Office of Force Education (OFE) and guided by the insights of Service members and their families. Development of a training tool is a complex problem, requiring knowledge that is distributed among experts and stakeholders. A common problem within multidisciplinary teams is the reconciliation of domain specific languages. Meaning, each team of experts is efficient in communicating amongst themselves due to their shared perspective derived from a similar background, but language barriers are subject to arise when communicating across domains or teams within the same domain. Consequently, each team brings a unique perspective to the process; the designers think in terms of the Service members and their families, the developers think in terms of the functional aspects of the training tool, and the stakeholders think in terms of business value. Teams that fail to share diverse expert information can cause poor decision making, whereas a strategic exchange of information can give rise to vital innovations (Gerbert, Boener, &
MODSIM World 2018
    2018 Paper No. 23 Page 3 of 10

Kearney, 2006). Using a UCD and Agile approach, information sharing was promoted through ongoing iterations and collaborations.
An Agile method emphasizes a collaborative and iterative process that can adapt to dynamic changes throughout development. This process favors high level and frequent communication among teams and stakeholders to enable thoughtful user experience through design sprints and iterations (Beck et al., 2001). Because of the many short iterative cycles that replaced the traditional phase of long development and documentation, more opportunities arise to verify that requirements align with the needs of end-users. The design team was responsible for generating these requirements, designing training instruction and the architecture, and measuring the usability and effectiveness of these implementations. The development team was responsible for transforming instruction and intent into tangible training components.
As part of the UCD approach, requirements were collected to get at the root of Service members and their family’s needs by conducting a competitive analysis and focused discussions with customers, stakeholders, subject matter experts, and end-users. From this, we derived a content ontology which captured the relationship between high level financial themes, categories, and subcategories. Formative and summative assessments were conducted at the end of each major phase to extract user expectations and satisfaction of the site structure, content organization, terminology, user interface, and functionality. Testing involved think-aloud protocol and surveys to elicit user feedback and user insights for future iterations. Through these methods minor, and even major, challenges were swiftly resolved.
From Minor to Major
Many of the financial training tools currently implemented in the military do not fully take into account the instructional design principles that are important to developing and delivering effective training. For example, in one mobile training application, financial information is presented in large documents, making information retrieval cognitively demanding. Due to the overwhelming amount of information densely packed with financial jargon, users found it difficult to grasp and comprehend financial concepts. This has led to a lack of financial literacy. By using a microlearning approach, this training was redesigned into engaging, and bite-sized pieces that were better aligned with their needs and expectations. Microlearning is a learning strategy that designs relatively short, small, and stand-alone learning units and encourages exploration for active participation. The transformation from text heavy screens to bite- sized information is effective in reducing short-term memory load (Shneiderman et al., 2016). Training was designed with a microlearning approach to put the learner back in control. This way, information can be accessed on the go, and at the point of need. Financial training was reimagined from the perspective of Service members and their spouses, enhanced through gamification techniques and motivational elements like Green Pig.
Created out of a need to engage and connect with Service members and their families, Green Pig emerged as a motivational element throughout training. The concept of a Green Pig was intuitive and simple; the use of a piggy bank is already widely recognized as a financial symbol, and the decision to color it green derived from established associations between green and money, as well as green and the military. Green Pig would be the character that broke down the barrier between user and tool by giving users something to connect with. Anthropomorphic features were added to increase user’s attention and promote learning and recall. Early design mockups displayed a rough concept of a cheerful and trustworthy Green Pig, who brought simplicity and understanding to pertinent financial information. As part of our innovative approach to training, the idea of Green Pig quickly assimilated into our design mockups (Figure 2).
Figure 2. The Birth of Green Pig
MODSIM World 2018
  During this time, other design concepts were also being developed. Referencing the training goal to give users greater control, or “power,” over their finances, the application was initially named $POWER (pronounced Money-Power). A complementary mood board embedded with bold colors of deep red, forest green and stock images of Service members from every branch was also designed. With initial aesthetic design choices complete, mockups laced with Green Pig and complimented with a powerful mood board, were distributed to the customer, and content development began while the customer discussed the design choices. Since we were working from multidisciplinary perspectives, each team, customer, and users expressed different priorities, making it difficult to achieve a shared vision for Green
2018 Paper No. 23 Page 4 of 10

Pig, the mood board, and the title of the application. At the core of each priority was the goal of developing an engaging and effective training application. To focus on this goal, synergistic communication was facilitated through daily, weekly, and monthly meetings and both divergent and convergent thinking followed. This led to not only a shared vision, but an innovative vision that reflected everyone’s priorities. Innovation must take into account both types of thinking; divergent thinking is successful in generating new ideas (brainstorming), and convergent thinking selects the best ideas from this set (Paletz & Schunn, 2009). From these collaborations, Green Pig evolved to take on different personas to further enhance engagement, like Piggy Smalls, Loan Shark Green Pig, and George Washington Green Pig (Figure 3).
Figure 3. Green Pig: Full of Personality
Additionally, Service members thought the color placement and color choices distracted attention away from relevant areas in training. Therefore, the development team suggested overhauling the mood board completely, and using the identical color scheme and theme of the customer. Finally, back-and-forth discussions regarding the training title surfaced, and the training was renamed to Sen$e to better match our training goals. The iterative nature of these minor design issues is typical in collaborative and multidisciplinary environments and should be planned accordingly. Since training development was well advanced when these decisions were made, iterations occurred not only on the minor design issues, but on the copious amount of finished content mockups, elevating this collaboration from a minor to major rework. While not ideal, the Agile process facilitated major iterations and customer input, so development could continue at a fast pace even during a complete design overhaul.
When working in a multidisciplinary team environment, it is important to develop a unified timeline across all teams keeping in mind schedule limitations. Information should be disseminated according to the customer’s needs, and turnaround expectations should be discussed early on to manage an efficient schedule. TIL: Understanding the internal operations of your development and customer partners is important for a successful collaboration. Expectations should be managed, and sufficient time should be allotted for design reviews to prevent the escalation of minor design decisions.
MODSIM World 2018
    You Can’t Spell ‘User-Centered Design’ Without ‘User’
To add even more human elements and the sense of personalization, Green Pig developed its own voice by embracing different personalities serving as a guide to call attention to specific areas and encouraging engagement through quirky comments (Figure 4). To measure the end-user’s performance in financial training, Green Pig Challenges were created at the end of each training segment (Figure 5). These challenges serve as a form of training assessment to measure training effectiveness while also providing insights that can be used to drive updates to content and additional features. The development team created several games centered around Green Pig like “Bring Home the Bacon,” (Figure 6) and discussion emerged about a future shop feature where users could purchase items for their Green Pig avatar. One year into development, our design team had a clear vision of the training tool, one that revolved around Green Pig being the mechanism that revitalized current financial training.
Figure 4. DJ Green Pig
  2018 Paper No. 23 Page 5 of 10

MODSIM World 2018
   Figure 5. Green Pig Challenge Figure 6. Bring Home the Bacon
As financial concepts became integrated into mockups and subsequent iterations of the application, we began to see a growth in the amount of content that needed implementation. A UCD approach takes into account all end-users, and in this case, that included a diverse range of Service members and their families. At one end of the spectrum is the 18- year-old beginning basic training during the first year in the military, and at the other end is the Service member who was preparing for retirement. The diversity and complexity of these life events was problematic in defining an intuitive architecture and training scope. Our training needs quickly outgrew our initial architecture, and we undertook the challenge to rearrange the new pieces in a way that met the expectations of the Service members and their spouses. TIL: When designing an intuitive system, it is important to design the interface based on user behaviors and expectations, not intuition alone. Usability testing provides valuable insights into the end-user’s attitudes and expectations about a product or service. These insights lend themselves to informed user-centered design decisions.
Gaining access to Service members and their families was difficult due to the geospatial differences between us and the customer and the extensive approval needed before accessing the command leaders who would grant us access to the military community. With our deadline advancing, we leveraged our network of representative end-users from our local community to pilot test the training tool. A sample size of five participants were recruited which sufficiently met usability experts’ sample size recommendations (Nielsen, 2012). By adding more participants, the overall cost increases but the number of findings quickly reaches the point of diminishing returns because more participants tend to show you the same observations, yielding no new findings (Nielsen, 2012). Using a mixed-methods approach, participants were asked to complete several scenarios that targeted different functionalities and training areas of the application. Participants were instructed to complete a think aloud test, where they were asked to verbalize their actions and thoughts while moving through scenarios. Think aloud testing is cheap, robust, flexible, and effective at uncovering design misconceptions which can lead to actionable redesign recommendations (Nielsen, 2012). Participants then completed several usability questionnaires and were interviewed about their overall opinions and expectations of the application. Testing results yielded important findings regarding the training tool; participants held contradictory opinions about Green Pig, and the use of limited functioning software caused participants to inconsistently navigate the content. Due to the low-fidelity prototype and early round of testing, we expected these navigation errors and used testing as a means to capture them and inform future iterations. Also, while the majority of users liked the idea of a character as a mentor, some thought the use of a Green Pig was irrelevant to the training and expected a character that better represented the military, like a drill instructor. Several participants commented that Green Pig’s personality was corny, cheesy, and child-like. The majority also found the organizational architecture to be unintuitive and confusing.
Collaboration between teams followed these findings, laying the groundwork for redesign. Green Pig’s personality driven implementation was more divisive than helpful, and thus Green Pig was completely removed from the application. Instead of presenting multiple options for implementing a more dynamic Green Pig, we presented the same option with slight character modifications. Options allow the customer to pick and choose elements they like or dislike, giving shape to a clear vision. TIL: When establishing successful customer relationships, present multiple
 2018 Paper No. 23 Page 6 of 10

design options to better capture the customer’s goals and vision. Additionally, even though design expertise and findings from SME interviews was applied to the design of the content architecture, the current presentation did not fully capture the user’s expectations and mental model regarding financial content and terminology. TIL: User- testing is needed to supplement design expertise and reveal errors early in the development cycle. The important of user insight should be conveyed early on to ensure adequate time is allocated towards recruiting participants, designing testing, gathering data, and distributing and incorporating findings.
From ‘Tool’ to ‘Pal’
The growth of available mobile training tools has increased in recent years, making the quality of experience crucial to their acceptance. Many training applications poorly transfer from a computer experience to a mobile experience (Schade, 2017). It is important to remember that our interactions with these two systems are widely varied. Mobile devices are used almost as an extension of ourselves; we interact naturally with these interfaces performing a variety of functions from picture taking to verbal, visual, and text-based communication. Even though mobile devices contain scaled down versions of desktop functionalities, like small screens and tiny keyboards, they should not be seen as restrictive. Rather, they are more empowering than their desktop compatriots because they offer many functions to aid in innovative on-the-go learning experiences (Schade, 2017). Sen$e was developed from an UCD approach to supplement military financial training and Service member interactions with financial support at their installations. The opportunity for innovation involved the creative presentation and transformation of bite-sized information into interactive components. Overcoming the physical constraints of mobile devices, like the small screen size and limited processing capability and power (Zhang and Adipat, 2005), financial concepts were presented at a high level with the opportunity for expansion, if desired by the user. For example, the components contained in a credit report were displayed as buttons, that when tapped, displayed an overlay describing those components in more detail. This strategy transfers learning independence to the user so they can direct their learning experience. Parsing information facilitates microlearning strategies by reducing the cognitive load placed on users when faced with a dense screen of all available financial concepts and sub concepts, as seen in current military financial mobile applications (Cowan, 2010). Inspired by mobile user experience best practices, financial training was integrated into user-friendly and mobile-friendly interactions like: hotspots, flip-books, overlays, multimedia clips, and phone and out of application access. TIL: When it comes to managing a diverse range of end-users and content complexity, design information that focuses on WHAT is important and WHY it is important, then provide the user more access to additional information if they want it.
Working from mockups that described the above interactions and accompanied training, the development team elevated our design concepts into functional software. The design team went into great detail describing how the content, layout, graphics should be implemented, but the development team preferred more succinct documentation. Consequently, some of the design intent was lost in the process. Additionally, the design team had a limited understanding of mobile constraints, limiting the type and complexity of desired implementations. We were faced with the challenge of compromising engaging training interactions to meet the need of developers and mobile constraints. TIL: Understand perspective from all teammates. The design team was working from the perspective of the user, while the development team was working from the perspective of the software. Overcoming these communication differences required learning more about the developers process and functions in the development cycle. Instead of communicating through detail-heavy PowerPoint mockups, we learned how to use an authoring tool that better resonated with the software development perspective. A week of training on this new software gave us valuable insight into the limitations and functions needed to build a mobile training tool. TIL: Reaching outside of your comfort zone facilitates team growth and fosters a unified collaborative process. By adapting our strategy before problems could emerge, we were able to maintain an aggressive development schedule while also satisfying the needs of all team members.
With training development back in full swing, the concept of Green Pig was unexpectedly brought up again. Time was needed to understand why Green Pig had failed in the previous iteration. While the execution of Green Pig was poor due to misalignment with the user’s expectations, the actual concept of a pedagogical character was not. Too much characterization pushed Green Pig into the realm of a children’s theme, isolating our targeted end-users who approached training in a more formal manner. Motivational elements can be fun without being childlike, therefore a new design was needed that balanced both a responsible and a charismatic character. Green Pig was born again, this time embracing several unique options that widely differed from the original design.
2018 Paper No. 23 Page 7 of 10
MODSIM World 2018

However, these options were vastly different from our vision. The problem arose due to perspective differences clouding communication between the design and development team. TIL: When communicating with teammates who share different perspectives, always remember that quality of communication is just as important as quantity of communication. Once again, we chose to adopt the lens of the software developer to accurately portray our ideas and intentions. TIL: When communicating design concepts in multi-disciplinary teams, always provide multiple options so the favorable, or unfavorable, parts can be selected and molded into a cohesive design that satisfies the intended vision. Rough sketches and samplings of characters were sent to the developers that gave structure to our new design goal. Through visualizations that everyone could understand, we ensured communication did not get lost. Consequently, Green Pig was reborn into its final form that can be seen throughout the final version of the financial training mobile application (Figure 8).
CONCLUSION
Figure 8. Green Pig’s Final Form
MODSIM World 2018
  Mobile training tools offer the potential for adaptive and on-the-go learning needs. To build a tool that is both usable and effective, a diverse team of experts in human factors, instructional design, and software development must work in unison to overcome multidisciplinary obstacles. Focus should be placed on the end-user throughout the design and development process to ensure a positive and consistent experience is created. The scope and complexity of training development invites challenges that must be overcome to find success. These challenges were captured by the evolution of a pedagogical character named Green Pig that is embodied in the Sen$e financial training application. Sen$e was developed to fill the gap in military financial training. Currently military financial training tools do not effectively capitalize on instructional design methods that could be used to transform cognitively challenging documentation into engaging training. As a result, the impact of current training methods on financial literacy are minimal, and the financial gap persists. Innovating current training through a User-Centered Design (UCD) and microlearning approach and supported through an Agile process, complex financial content was transformed into bite- sized pieces and integrated alongside gamification and motivational elements like Green Pig. The use of pedagogical agents in learning environments is well established due to the many benefits they offer like modeling human behavior to serve as a role model, breaking down complex tasks, personalizing learning experiences, and increasing user motivation. Green Pig was designed as a stylistic agent that was enhanced through anthropomorphic features to increase the bond between the user and the tool. Green Pig started out as a simple green piggy bank that evolved to take on several anthropomorphic personalities, de-evolved when it was removed from the application, and was born again into the simple but friendly mentor that is seen throughout the application today. Green Pig persisted throughout the entire development process, and through it taught us several valuable lessons, seen within the paper as “Today I Learned” segments, and summarized below.
Today I Learned:
TIL (1): Good customer relationships are important in any collaborative process. Understanding the internal operations of all collaborating partners helps manage expectations to create an appropriate development schedule.
TIL (2): When designing any system, never underestimate the power of the end-user. User testing provides valuable insight into end-user’s behaviors and expectations. By conducting testing throughout the development cycle, you can catch errors as they arise and mitigate accordingly. This not only saves costs down the line but ensures your training system is consistent with the needs of the user. Conclusively, design decisions should be based on the user’s needs and expectations instead of pure intuition.
TIL (3): When conveying design concepts, it is easier to provide multiple options to increase the chance of satisfying the intended vision. Multiple options allow for the selection of positive and negative elements to better capture what is difficult to describe with words alone.
2018 Paper No. 23 Page 8 of 10

TIL (4): When presenting information in a microlearning format, the goal is to provide succinct and relevant information that removes unnecessary jargon. Focus on what needs to be said, and why it needs to be said, then offer the option to delve into further detail. Doing so, gives the user greater control over their learning experience without compromising engagement or instructional material.
In collaborative teams, it is more common to approach problems from multiple perspectives. Make sure you understand these perspectives when making decisions and prepare to reach outside of your comfort zone to better understand your partners and provide quality synergistic communication. Embracing these lessons will help facilitate teamwork within a multidisciplinary team.
REFERENCES
Bandura, A. (1977). Self-efficacy: Toward a unifying theory of behavioral change. Psychological Review, 84(2), 191- 215. doi: 10.1037/0033-295X.84.2.191
Bannon, L. J. (1995). From human factors to human actors: The role of psychology and human-computer interaction studies in system design. In J. Greenbaum, & M. Kyng (Eds.), Design at work: Cooperative design in computer systems (pp. 25-44). Hillsdale: Lawrence Eribaum Associates.
Baylor, A. (2000). Beyond butlers: Intelligent agents as mentors. Journal of Educational Computing Research, 22(4), 373-382.
Beck, K., Beedle, M., Van Bennekum, A., Cockburn, A., Cunningham, W., Fowler, M., ... & Kern, J. (2001). Manifesto for agile software development. Retrieved Feb. 5, 2018 from http://agilemanifesto.org/
Brhel, M., Meth, H., Maedche, A., & Werder, K. (2015). Exploring principles of user-centered agile software development: A literature review. Information and Software Technology, 61, 163-181.
Laurel, B. (1997). Interface agents: Metaphors with character. In Batya Friedman (Eds.), Human values and the design of computer technology (pp. 207-216). Cambridge University Press.
Constantine, L. L., & Lockwood, L. (2002). Process agility and software usability: Toward lightweight usage-centered design. Information Age, 8(8), 1-10.
Cowan, N. (2010). The magical mystery four: How is working memory capacity limited, and why? Current directions in psychological science, 19(1), 51-57.
Gulz, A. (2004). Benefits of virtual characters in computer based learning environments: Claims and evidence. International Journal of Artificial Intelligence in Education, 14(3, 4), 313-334.
Gulz, A., & Haake, M. (2006). Visual design of virtual pedagogical agents: Naturalism versus stylization in static appearance. Proceedings of the 3rd International Design and Engagability Conference. Oslo, Norway.
Hietala, P., & Niemirepo, T. (1998). The competence of learning companion agents. International Journal of Artificial Intelligence in Education (IJAIED), 9, 178-192.
Johnson, W. L., Rickel, J., Stiles, R., & Munro, A. (1998). Integrating pedagogical agents into virtual environments. Presence, 7(6), 523-546.
Johnson, W. L., Rickel, J. W., & Lester, J. C. (2000). Animated pedagogical agents: Face-to-face interaction in interactive learning environments. International Journal of Artificial intelligence in education, 11(1), 47-78.
Nielsen, J. (2012, June 4). How many test users in a usability study? Retrieved Feb. 5, 2018 from https://www.nngroup.com/articles/how-many-test-users/
2018 Paper No. 23 Page 9 of 10
MODSIM World 2018

Nielsen, J. (2012, January 16). Thinking aloud: The #1 usability tool. Retrieved Feb. 5, 2018 from https://www.nngroup.com/articles/thinking-aloud-the-1-usability-tool/
Park, Y. (2011). A pedagogical framework for mobile learning: Categorizing educational applications of mobile technologies into four types. The International Review of Research in Open and Distributed Learning, 12(2), 78- 102.
Rosenberg-Kima, R. B., Baylor, A. L., Plant, E. A., & Doerr, C. E. (2008). Interface agents as social models for female students: The effects of agent visual presence and appearance on female students’ attitudes and beliefs. Computers in Human Behavior, 24(6), 2741-2756.
Schade, A. (2017, October 15). We can do better on mobile: designing for the medium. Retrieved Feb. 5, 2018 from https://www.nngroup.com/articles/better-mobile/
Sharples, M. (2000). The design of personal mobile technologies for lifelong learning. Computers & Education, 34(3- 4), 177-193.
Veletsianos, G., Miller, C., & Doering, A. (2009). EnALI: A research and design framework for virtual characters and pedagogical agents. Journal of Educational Computing Research, 41(2), 171-194.
Zhang, D., & Adipat, B. (2005). Challenges, methodologies, and issues in the usability testing of mobile applications. International journal of human-computer interaction, 18(3), 293-308.
2018 Paper No. 23 Page 10 of 10
MODSIM World 2018
