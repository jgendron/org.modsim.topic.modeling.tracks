Simulation-BasedEvaluation of Medical Workstations Designed for Human Space Exploration
Jacob Richardson, Brian Dilinila, Thomas Tracey, Minh Dong, John Paul Asija, Michael Poteat, Jake Webster
OldDominion University
Norfolk, Virginia
jrich087@odu.edu, bdili002@odu.edu, ttrac005@odu.edu, mdong004@odu.edu, jasij001@odu.edu, mpote001@odu.edu, jwebs001@odu.edu
AB S TRACT
The Exploration Medical Capability (ExMC) element at NASA Langley Research Center desires a process for evaluating and comparing designs for medical workstations capable of supporting long-duration human space e xp l o r a t i o n . T h e a u t h o r s , a s p a r t o f t h e i r s e n i o r c a p s t o n e d e s i g n e xp e r i e n c e , a r e j o i n t l y c h a r g e d w i t h b o t h d e s i g n in g an evaluation process and implementing a prototype of that process as a proof of concept. A key component of the evaluation process is a simulation having the capability to assign quantitative values to dynamic performance measures. Dynamicperformancemeasuresareevaluatedbyobservingtheconductofanactivityortaskoveraperiod of time. Examples of dynamic performance measures include the time required to complete a task, or the volume/shapeofthespatialenveloperequiredtoperformatask. Thedesignteamhasdeterminedthatusingadiscrete eventsimulation,inwhichavatarsaremonitoredwhileperformingrepresentativemedicaltasks,is thebestapproach forevaluatingdynamicperformancemeasures. Thefocusofthispaperistheprocessofdefiningthosemetrics,as well as the approach to evaluating the dynamic metrics of the corresponding simulation.
ABOUT THE AUTHORS
AllauthorsofthispaperareseniorsatOldDominionUniversity(ODU)graduatingMay2018in theundergraduate program for Modeling, Simulation, and Visualization Engineering.
J a c o b R i c h a r ds o n i s c u r r e n t l y a n i n t e r n a t J e f f e r s o n A p p l i e d R e s e a r c h f u n d e d b y t h e D O E a s w e l l a s a t u t o r f o r t h e Modeling and Simulation Engineering department at ODU.
BrianDilinilais currently an intern underCombat Direction Systems ActivityDamNeck representing NAVSEA at and providing assistance to Joint Staff J7.
Thomas Tracey is both a teaching assistant for Modeling and Simulation courses at ODU and a research assistant working on a graphical user interface used for assisting in the education of discrete event system simulations. Minh Dong is interested in game development and is currently working on a personal video game project. JohnPaulAsijais aresearchassistantintheDardenCollegeofEducationatODUfundedbytheNSFGEODEgrant. Michael Poteat is a research assistant at Old Dominion University working on computational recognition and segmentation of secondary structure elements embedded within a larger protein image.
Jake Webster has interests in game and mobile development.
MODSIM World 2018
       2018 Paper No. 49 Page 1 of 7

Simulation-BasedEvaluation of Medical Workstations Designed for Human Space Exploration
Jacob Richardson, Brian Dilinila, Thomas Tracey, Minh Dong, John Paul Asija, Michael Poteat, Jake Webster
OldDominion University
Norfolk, Virginia
jrich087@odu.edu, bdili002@odu.edu, ttrac005@odu.edu, mdong004@odu.edu, jasij001@odu.edu, mpote001@odu.edu, jwebs001@odu.edu
INTRODUCTION
As of 2018, many advanced challenges in astronautics have been achieved. This includes the challenge of sending numerous space exploration vehicles to Mars. However, the National Aeronautics and Space Administration views t h i s a s o n l y t h e b e g i n n i n g . O n e o f t h e m a n y n e a r - h o r i z o n g o a l s o f N A S A i s t h a t o f a d v a n c i n g d e e p s p a c e e x p l o r a t io n , as well as sending humans to Mars. Advancements in deep space exploration have in turn resulted in a new and innovativespacecapsuledesign,whichwillfacilitatefuturevoyages. Ontheotherhand,theseadvancementsraise many questions. One of these questions involves the logistics involved in maintaining crew health and safety. NASA aims to further develop its ability to accommodate medical needs and provide preventive measures aboard the deep space capsule in future manned voyages.
As the ability to send astronauts on deep space voyages becomes more of a reality , the ability to keep astronauts safe andhealthybecomesmoreofapriority.Theeffects ofzerogravityonthehumanbodyforextendeddurationsis still an area in which many questions are unanswered.With this beingthe case,NASA must make sure that the medical capability is in place to serve the astronauts should the time arise. One of the current challenges that NASA is facing is how to make a differentiation between two medical workstations so that comparisons and differences can be highlighted when comparing designs.A series ofmedicalprocedures performed in each medicalworkstation would provideafoundationfordetermininghowtheastronautsmovearoundwithintheconfinedspace,howtheyaccessthe supplies within the workstation, and the ability to carry out a given procedure.
The Capstone Team at ODU has taken the given problem and broken it down into a single procedure that can be replicated across multiple designs. The Capstone Team has completed this process in order to generate data NASA can utilize to assist in differentiating between designs. First, it is important to note that any given procedure can be brokendownintoaseriesofatomictaskswhichcanthenbemeasuredthroughtheuseofperformancemeasures.Two different types of performance measures will be utilized in the design of the problem solution.
Static performance measures will be generated through the leveraging of knowledge from subject matter experts (SMEs). Through the use of simulation, multiple runs on a series of tasks provides the capability of being able to evaluate the dynamic performance measures associated with that set of tasks. In order to capture this data, markers will be used to denote a start and stop point within the simulation which will be directly associated with a dynamic performance measure. The Capstone Team has taken the challenge at hand and has designed a solution which will assistintheevaluationoftwomedicalworkstations.Figure1includesahigh-leveldesignofthesolutiontheCapstone Team will implement.
MODSIM World 2018
       2018 Paper No. 49 Page 2 of 7

Figure 1. High-Level Viewof Three Main Components of the System.
This paper addresses the Capstone Team’s solution for NASA: a high-level design of the solution, as well as a discussion of how the design components will function towards meeting the overarching goal of supporting NASA ExMC in regards totheevaluationofmedicalworkstations.Itdiscusseseachcomponentofthesolutionincludingthe inputs to the s ystem, the core s imulation module as well as the output repository which facilitates the computation and analysis ofthemedicalworkstation.Thefollowingsectionsdiscuss ourhigh-levelsystemarchitectureas wellas the technical approach to our solution and, specifically, the system’s use, the development of performance measures as well as the development process of performance measures. The following sections also discuss the two different types of performance measures and the association of performance metrics, as well as the evaluation and visualization of the performance metrics.
SYSTEM ARCHITECTURE
With regard to the system architecture of The Capstone Team’s solution, the simulation tool has been broken down i n t o t h r e e ma j o r c o mp o n e n t s : t h e i n p u t mo d u l e , s i mu l a t i o n mo d u l e , a n d t h e o u t p u t a n a l y s i s mo d u l e . T h e i n p u t t o o u r systemwill be a setofparameters providedbyNASA,whichincludethedesignofthemedicalworkstationandthe setofmedicaltoolsandtheirlocations.Thesimulation modulewilltaketheinformationthatwasprovidedasaninput, and - through the use of performance measures - generate output which will be used to create performance metrics. Performancemeasureshavebeenseparatedintotwodifferentcategories:staticanddynamic,andtheuseofsimulation allows for the Capstone Team to evaluate dynamic performance measures. The process for evaluating static p e rfo rma n c e me a s ure s a s we ll a s d y n amic p e rfo rma n c e me a s ure s will b e e xp la in e d in fu rt h e r d e t a il in t h e s e c t ions to come. The final module within our system architecture, the output analysis module, will take the raw data from the simulationmoduleandgenerateperformancemetrics. Then,throughtheuseoftheseperformancemetrics,theoutput analysis module will generate a visualization of the resulting data.
METHOD OF EVALUATING DYNAMIC PERFORMANCE MEASURES
Identifying Performance Measures
Figure 2 provides the process of developing performance measures. The process begins with developing an understanding of the system. Once completed, performance measures can be brainstormed to highlight areas where d i f f e r e n c e s i n w o r k s t a t i o n d e s i g n s m a y e x i s t . A f t e r c o m p l e t i n g a l i s t o f p e r f o r m a n c e m e a s u r e s , a p a n e l o f S M E s mu s t convene to discuss the validity of each performance measure. If the list is not approved, then it must be modified. Else,theprocesscancontinuesoinformationcanbegatheredfortheperformancemeasures.Thevaluesprovidedby the performance measures can help NASA determine differences in designs or determine if changes to themeasures are necessary.
2018 Paper No. 49 Page 3 of 7
MODSIM World 2018
 
Figure 2. Process of Developing Performance Measures.
NASA-LaRC is providing a representative scenario for treating cardiac arrest. By breaking down the scenario into “tasks” (i.e. goals to be reached for the procedure), and further down as actions, the scenario constitutes a process which falls under the modeling perspective of a process flowchart. This approach is popular in developing system m o d e l s t h a t f a l l u n d e r t h e d i s c r e t e e v e n t s i m u l a t i o n p a r a d i g m . T h e u s e o f p r o c e s s - b a s e d d i s c r e t e e v e n t s i m u l a t i o n e xi s t in toolssuchasArena(ChoiandKang,2013),whereprocessesconsistofprocessblocksthathavesequentialflowto other blocks. This is utilized when it is necessary to observe and understand how different processes interact over time. This allows for an improved method to identify events within the system.
These actions can be transformed into logic blocks to build together the process flowchart model. Events start upon the activation of processes and end when their corresponding processes end. Times to complete tasks can vary by introducingstochasticvaluesfortime.Thesetimes canbedefinedbytheenduserofthesimulation.Theendusercan as well introduce probabilities for certain conditions in the scenario.
By building the flowchart, we can identify areas where workstation designs may be different. Information such as time spent moving through the workstation, spending time away from the patient, etc. may be considered as informationnecessaryforNASA’sevaluations.Therefore,markers maybeplacedwithintheprocessflowchartmodel to state where information can be recorded. This information may then be sent as raw output data to be used for calculations for the dynamic performance measures’ metrics.
FromFigure3,thescenariohasbeendividedintofivetasks:1)MovingthePatienttotheWorkstation,2)Monitoring thePatient’sHeartRate,3)CheckingforThroatBlockage,4)CheckingforFluidinLungs,and5)ApplyingAEDand Conducting CPR. When all tasks have been completed the scenario has been completed.
Figure 3. High-Level Perspective of Process Flowchart Model.
Task Five (Figure 4) involves applying the AED on the patient to analyze the patient’s heart rh ythm. Unlike the previous two tasks,toolmodularity is present.The AEDhas multiple uses such as analyzing the patient’s heart rate along with applying shock. This is an example of the concept that tasks are associated with tools.
MODSIM World 2018
  2018 Paper No. 49 Page 4 of 7

Figure 4. Process Flowchart for Task 5: Completing CPR. Evaluating Static Performance Measures
Static performance measures focus on the features of medical workstations without the need of the observation of systembehaviorovertime.Thesemeasurementsdelveintoareassuchasthedimensionsoftheworkstationandhabitat, theinitialquantityofresources,etc.Duetotheinterdisciplinarynatureofthisproject,themethodofevaluatingstatic performance measures requires the convening and consultation of SMEs. Static performance measures are provided tothis panelofexperts,whomare responsibleforprovidingvaluesforeachmeasure.Theseexpertscanproducethe values bymethodssuchaslookingupvaluesfromtables,conductingcalculations,orevenprovidingeducatedguesses.
Evaluating Dynamic Performance Measures
As opposedtostaticperformancemeasures,dynamicperformancemeasures’valuesarecollectedthrough theongoing behavior of the system under study. In order to observe this behavior, a simulation is necessary. Example dynamic performance measures include time performed for tasks and constraint violations (e.g. time, spatial). Dynamic p e r f o r m a n c e m e a s u r e s a r e n o t a n i n p u t t o t h e s y s t e m . H o w e v e r , t h e y a r e a s s o c i a t e d w i t h r e p r e s e n t a t i v e t a s k s d e r iv e d f r o m s a m p l e s c e n a r i o s . T h e s e t a s k s a r e a m o n g t h e n u m b e r o f i n p u t s t o t h e s i m u l a t i o n . T h e t a s k s a r e c a r r i e d o u t w i t h in the simulation module which produces raw data in the form of time-stamped events as output. Time-stamped events are records of changes of the systemstate. Examples of events are “Start Task” and “End Task” which correspond to time duration of tasks. This output acts as the necessary input to the output analysis module which calculates metrics. These metrics are the values associated with dynamic performance measures. Some dynamic performance measures may have more than one metric. The metrics are then saved within an output file and stored separately fromthe static performance measure values.
SIMULATION MODULE
T h e s i m u l a t i o n m o d u l e t h a t p r o d u c e s t h e n e c e s s a r y d a t a f o r c a l c u l a t i n g m e t r i c s c o n s i s t s o f t h r e e c o m p o n e n t s : a s c r ip t , thesimulationsourcecode,whichcontainstheprocessblocksusedforbuildingtheprocessflowchart,andtheoutput r e p o s i t o r y . T h e s c r i p t i s i n h u m a n - r e a d a b l e f o r m a t a n d i s d e f i n e d b y t h e u s e r t h r o u g h t h e c o r r e s p o n d i n g i n p u t m o d u le . This script contains the initial system state, which includes information on the tools and resources available, the
2018 Paper No. 49 Page 5 of 7
MODSIM World 2018
 
positionandorientationoftheactors,andasequentiallistofactions.Theseactionsaresenttothesimulationtobuild a process block and execute it in order to change the state of the system. The commands’ parameters include information such as an actor executing a process, the destination point that an actor must move to, and what tool to use. After execution, the system state is sent to the output repository in the form of time stamped events.
OUTPUT ANALYSIS MODULE GRAPHICAL USER INTERFACE
The data that comes out of the simulation will be then be output as time-stamped events. Because of this, the output analysismodulewillneedtohavethecapabilityofparsingthedata,aswellasthemarkers thatwereputinplacein ordertogeneratemeaningfuldynamicperformancemeasures.Theoutputanalysis modulewillnot onlyutilize time- stamped events as an input but the static performance measures as well. Through the extraction of data from the markers and time-stamped events, along with the combination of static performance measures, the output analysis modulewill possessthecapabilityofcalculatingmeaningfulperformancemetrics.Theseperformancemetrics willbe usedtoprovidetheuserwithfeedbackregardingdifferentaspectsofthemedicalworkstation.Figure5is anexample ofhowdatawouldbeextractedbyusingmarkers.Theyellowstarsdenotedthestartingpointatwhichthesimulation begins to record data. A corresponding ending marker would also be present that denotes the position at which the simulation should stop recording in order to generate a given metric.
Figure 5. Flow Chart of the Starting Points to begin Metric Data Collection.
The user will then be able to easily manipulate the data through the use of a graphical user interface. It is from this GUI that visualizations of the data will be generated. For example, if the user was interested in the total amount of time thataseries oftaskstooktocomplete,thebreakdownofeachmetricthatencompassestotaltimecanbeseenand compared between workstation designs in Figure 6 as shown below.
MODSIM World 2018
 2018 Paper No. 49 Page 6 of 7

Figure 6. Graph of Metrics Encompassing the Total Time for a Series of Tasks. CONCLUS ION
The Capstone Team understands that NASA’s engineering process requires support for evaluating medical workstationdesigns.WhileNASA hasthecapabilityofreachingouttoSMEs toassistinevaluatingdesigns,astudy of the system’s behavior over time is necessary to gather information about dynamic performance measures. T h e r e f o r e , t h e C a p s t o n e T e a m h a s p r o v i d e d a p r o c e s s a n d s o l u t i o n t o a l l o w N A S A t o i m p r o v e t h e i r a b i l i t y t o e v a lu a t e the workstation design. The model provided is flexible – for it allows NASA to build representative scenarios with processes that can represent internal tasks. NASA can then pinpoint critical information that is needed for metrics belonging to dynamic performance measures.
ACKNOWLEDGEMENTS
The Capstone Team would like to thank Dr. Jim Leathrum and Dr. Roland Mielke from ODU’s Department of Modeling, Simulation, and Visualization Engineering for their guidance and support. The teamwould also like to thank Dr. Kara Latorella of ExMC at NASA-LaRC for providing this opportunity as well as serving as a point of contact and as a subject matter expert.
REFERENCES
Choi, B. K., & Kang, D. (2013). Modeling and Simulation of Discrete-Event Systems, Hoboken, NJ: John Wiley & Sons.
2018 Paper No. 49 Page 7 of 7
MODSIM World 2018
 