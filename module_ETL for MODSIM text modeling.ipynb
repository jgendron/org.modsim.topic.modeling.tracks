{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Purpose:\n",
    "Extract parameters about all MODSIM papers published from 2014 to 2018\n",
    "Transform parameters within a dataframe\n",
    "Load the text of the MODSIM papers into a working data set\n",
    "\n",
    "Inputs:\n",
    "The inputs for this procedure include:\n",
    "* A list of MODSIM websites containing the papers for parsing HTML with BeautifulSoup\n",
    "* Text files containing full text from each MODSIM Papers (2014 to 2018)\n",
    "  ** Downloaded PDF from MODSIM website using Google Chrono Sniffer extension\n",
    "  ** Converted to text using Mac OS Automator workflow\n",
    "  ** Assumes a file structure ./data/<year>/ exists for years 2014-2018\n",
    "\n",
    "Output:\n",
    "The results of this module is a folder called ./data/abstracts/ containing .txt files each with a custom label and containing abstracts extracted from MODSIM papers.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import *\n",
    "import re\n",
    "\n",
    "# Provide list of all sites containing MODSIM Papers 2014-2018\n",
    "sites = ['http://modsimworld.org/conference-papers/2014',\n",
    "         'http://modsimworld.org/conference-papers/2015',\n",
    "         'http://modsimworld.org/conference-papers/2016',\n",
    "         'http://modsimworld.org/conference-papers/2017',\n",
    "         'http://modsimworld.org/conference-papers/2018']\n",
    "# Create an empty list to capture webscrape results \n",
    "records = [] \n",
    "\n",
    "# Extract: get parameters of papers into a dataframe\n",
    "for site in sites:\n",
    "    page = requests.get(site)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    results = soup.find_all('table') # finds all tables on page, each is a track\n",
    "\n",
    "    for result in results:\n",
    "        for r in result.findAll('tr'):\n",
    "            if r.find('td') is not None:\n",
    "                track = result.find('th').text\n",
    "                filename = r.find('a')['href'][13:]\n",
    "                author = r.find('td').text\n",
    "                team = round((len(r.find('td').text) + randint(-2,2)),0) #admittedly a hack\n",
    "                title = r.find('span').text\n",
    "                year = r.find('a')['href'][8:12]\n",
    "                records.append((track,filename,author,team,title,year))\n",
    "\n",
    "df = pd.DataFrame(records, columns = ['track', 'filename', 'author_id', 'team','title', 'year'])\n",
    "\n",
    "# Transform: relabel tracks into one of four categories\n",
    "df['year'] = df['year'].apply(str)\n",
    "mapped_sub = {'track': {'Training and Education': 'TE',\n",
    "                        'Training': 'TE',\n",
    "                        'Education': 'TE',\n",
    "                        'Analytics and Decision Making': 'AT',\n",
    "                        'Analytics and Decision-Making': 'AT',\n",
    "                        'Science and Engineering': 'SE',\n",
    "                        'Visualization and Gamification': 'VG',\n",
    "                        'Entertainment, Sports, Media, & Visualization': 'VG',\n",
    "                        'Cyber Security': 'VG'}\n",
    "             }\n",
    "df_mod = df.replace(to_replace=mapped_sub)\n",
    "\n",
    "# Transform: convert .pdf filenames into .txt\n",
    "df_mod['filename'] = df_mod['filename'].str.replace('pdf', 'txt')\n",
    "\n",
    "# Transform: extract first occurence of last name as author tag\n",
    "# create three individual series for three types of matches\n",
    "a=df_mod['author_id'].str.extract(r'([a-zA-Z]+,)')\n",
    "b=df_mod['author_id'].str.extract(r'([a-zA-Z]+ and)')\n",
    "c=df_mod['author_id'].str.extract(r'([a-zA-Z]+$)')\n",
    "\n",
    "# combine the three temp series with precedence for already filled rows\n",
    "temp = a.combine_first(b).combine_first(c)\n",
    "# remove the separator flags \n",
    "temp[0] = temp[0].str.replace(',','') # a series function\n",
    "temp[0] = temp[0].str.replace(' and','')\n",
    "df_mod['author_id'] = temp[0]\n",
    "\n",
    "#Transform: convert team variable to string\n",
    "df_mod['team'] = df_mod['team'].apply(str)\n",
    "\n",
    "# Create doc labels in track-year-author format  \n",
    "df_mod['label'] = './data/abstracts/' + df_mod['track'] + '-' + \\\n",
    "                df_mod['year'] + '-' + df_mod['author_id'] + \\\n",
    "                '[' + df_mod['team']  + '].txt'\n",
    "\n",
    "\n",
    "# Create a zipped object of tuples (filename, label) to iterate through files\n",
    "tup = zip(df_mod['filename'],df_mod['label'])\n",
    "\n",
    "for file,label in tup:\n",
    "    #create filename to open text file of MODSIM paper\n",
    "    filename = './data/papers_text/' + label[20:24] + '/' + file\n",
    "    try:\n",
    "        f = open(filename, encoding='latin')\n",
    "        raw = f.read()\n",
    "    except ValueError:\n",
    "        print(f'X: {filename}')\n",
    "    \n",
    "    abstract = re.search('ABSTRACT\\n',raw)\n",
    "    if not abstract:\n",
    "        print(f'Need abstract tag: {filename}')\n",
    "    author = re.search('ABOUT THE', raw)\n",
    "    if not author:\n",
    "        print(f'Need author tag: {filename}')\n",
    "        \n",
    "    begin = re.search('ABSTRACT\\n', raw) #flag for beginning of abstract\n",
    "    stop = re.search('ABOUT THE', raw) #flag for stop of abstract\n",
    "    #ironic but we want the end of the begin flag and start of stop flag\n",
    "    abstract = raw[begin.end():stop.start()] #extracts the abstract\n",
    "    f.close()\n",
    "    print(f'Opening {file} and extracting abstract') #output to show progress\n",
    "    \n",
    "    #Write the extracted abstract to text file \n",
    "    text = open(label, \"w\")\n",
    "    text.write(abstract)\n",
    "    text.close()\n",
    "    print(f'Writing extracted abstract as file {label}\\n') #output to show progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
